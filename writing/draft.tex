% document layout
\documentclass{article}
\usepackage[margin=1.4in]{geometry}
\usepackage[utf8]{inputenc}

% packages
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mdwtab}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{listings}
\usepackage{float}

\floatstyle{boxed} 
\restylefloat{figure}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\renewcommand{\syntleft}{}
\renewcommand{\syntright}{}
\setlength{\grammarparsep}{10pt}
\setlength{\grammarindent}{10em}
\newcommand{\indalt}[1][2]{\\\hspace*{-1.2em}\textbar\quad}
\newcommand{\rname}[1]{\textsc{\footnotesize #1}}
\newcommand{\LNLD}{\text{LNL}_\text{D}}
\newcommand{\ok}{\textbf{ok}}
\newcommand{\pure}{\textbf{pure}}
\newcommand{\sort}{\textbf{sort}}
\newcommand{\type}{\textbf{type}}
\newcommand{\utype}{\overset{U}{:}}
\newcommand{\ltype}{\overset{L}{:}}
\newcommand{\stype}[1]{\overset{#1}{:}}
\newcommand{\step}{\leadsto}
\newcommand{\pstep}{\leadsto_p}

% title and author
\title{Dependent Linear Type Theory for Resource Aware Certified Programming}
\author{Qiancheng Fu}

% document body
\begin{document}
  \maketitle 
  \begin{abstract}
    TBD
  \end{abstract}

  \section{Introduction}
  In the field of certified programming, it is of paramount importance for the specification language to precisely characterize the behavior of programs. For this reason, dependent type theory enjoys great success as the type level language of specifications is exactly the same as the term level programming language, giving tremendous power and control to specification writing. The verification achievements\cite{compcert,deepspec,everest} carried out by proof assistants such as Coq\cite{coq} or F*\cite{fstar} is a testament how much dependent type theory has accomplished. 
  
  Dependent type theory is however, not without its flaws. Due to its origins as a logical foundation for mathematics\cite{martinlof,cc}, dependent type theory lacks facilities to reason about resource, a concept that is largely absent from mathematics but ever present in computer science. Objects in dependent type theory can be freely duplicated or deleted by appealing to the contraction and weakening rules, this goes against the conservation principle of resource. Users of dependent type theories are often required to laboriously embed memory models and program logics into type theory to effectively reason about resource\cite{bedrock}. As language designers, we hope to alleviate this shortcoming of dependent type theory.

  In the disparate world of substructural logic, Girard introduces Linear Logic in his seminal work\cite{girard}. Linear Logic restricts weakening and contraction rules of classical logic, giving rise to an elegant formal foundation for reasoning about resource. Wadler\cite{wadler1990,wadler1991} and Abramsky\cite{abramsky1993} notice the opportunities presented by Linear Logic for resource aware programming, pioneering the development of simple linear type theory as a programming language. Linear type theory enforces safe variable usage, which conservatively subsumes resource usage. This reduces the problem of resource reasoning to linear type checking. Languages based on linear type systems have shown the capacity to safely manipulate imperative data structures\cite{l3,ats}. The successful extraction of type theory from Linear Logic offers a tantalizing hint to overcoming the challenges of resource reasoning in dependent type theory: integrate linear types.

  The earliest work on integrating dependent type theory and linear type theory was carried out by Cervesato and Pfenning\cite{llf}, extending the Edinburgh LF with linear types. Xi extends DML dependent types with linear types in the ATS programming language\cite{ats}. Krishnaswami et al. develop $\LNLD$\cite{neel15} based on Benton's LNL\cite{benton1994} calculus for simple linear types, allowing term dependency on its non-linear fragment. The authors of $\LNLD$ demonstrate its capacity for certified imperative programming in the style of L3\cite{l3} and Hoare Type Theory\cite{htt}.  Luo et al. introduce the notion of essential linearity\cite{luo}, developing the first type theory that allows types to depend on linear terms. Atkey's QTT\cite{qtt}, based on initial ideas of McBride\cite{nothing}, neatly reduces dependency and linearity checking to checking constraints defined on semi-rings. Idris 2\cite{idris2} is a full featured programming language that implements QTT as its core type system.

  The lack of weakening and contraction rules for linear types present unique difficulties when integrating full spectrum dependent types, often making dependent linear types challenging or unsatisfactory for practical use. $\LNLD$ requires use of explicit modality maps F and G to alternate between its linear and non-linear fragment. Computation requiring back and forth applications of F and G quickly explode in complexity. Terms in Luo's type theory are not intrinsically linear, linearity is solely determined by annotations. The unfortunate side-effect of this design choice is that linear computations never return non-linear values, eliminating the common pattern of retrieving a non-linear values from a linear references. QTT faces the similar drawbacks to Luo due to linearity being determined by semi-ring annotations.
  
  We present a full spectrum dependent linear type theory that provides a more direct approach to enforce linearity, eschewing the use of modality operators. We believe that linearity is an intrinsic property that can be determined by the type of a term. To accomplish this, our type system uses two class of type sorts in the style of Krishnaswami, $L$ for linear and $U$ for non-linear. Due to the abandonment of modalities, we use two distinct functions types $(x : A) \rightarrow_s B$ for non-linear functions and $(x : A) \multimap_s B$ for linear functions. We formalize a call-by-value operational semantics and prove the type soundness of our system. To further demonstrate the applications of dependent linear types, we extend our type system with imperative programming features, leveraging both dependency and linearity for certified imperative programming. We augment our soundness theorem to account for these extensions, showing that imperative resources are properly managed. We have implemented a prototype of our language extended with other features for practicality and ergonomics.

  \section{Core Type Theory}
  In the efforts of integrating dependency and linearity, there are two predominant schools of thought: \textit{Types can only depended on non-linear terms} and \textit{Types can depend on all terms}. 
  
  Advocates of restricted dependency argue that the restriction is both intuitive and a necessity. A natural example of linear types depending on a non-linear terms is that of the length indexed random access array. Term dependency on array length statically prevents out-of-bounds array access whilst linearity ensures proper memory management. In the converse situation of types depending on linear terms, one immediately faces a dilemma: \textit{Do linear terms at the type level possess weakening and contraction?}.
  
  If one answers yes, then the linear terms at the type level are defacto non-linear. In this case, a language with restricted dependency can simulate linear dependency by depending on non-linear terms that reflect the shape of linear terms\cite{ldqt}, erasing the advantage of increased type level expressivity. All prior works featuring linear dependency fall into this category, for good reason: \textit{the alternative is worse}.
  
  If type level linear terms do not possess weakening and contraction, types with linear dependencies themselves are linear. This breaks the very notion of the typing judgment as even $\alpha$-equivalent terms are not allowed to possess the same type. Though the idea of such a type system is deeply interesting, the philosophical burden is prohibitive.
  
  Our language firmly falls in the former category. Besides the reasons listed above, restricted dependency gives a clear distinction between linear and non-linear terms, a property we believe will aid in the compilation to high performance code.
  
  \subsection{Syntax}
  The syntax of the core type theory is presented in Figure \ref{syntax}. Our type theory contains two sorts, $U$ and $L$ for denoting the sort of non-linear types and linear types respectively. An important fact to note is that our language possess the "Type-in-Type" axiom in the form of $\Gamma \vdash U \utype U$ which is well known to be logically unsound. We chose this design deliberately as we are willing to sacrifice logical soundness for increased expressivity and convenience. We forsee no issue in extending the core language with a hierarchy of sorts to enforce logical soundness.

  \begin{figure}[H]
    \caption{Syntax}
    \centering
    \begin{minipage}{0.8\linewidth}
    \begin{grammar}
      <$s, t$> ::= $U$ | $L$ \phantom{| $x$} \hspace*{8em} sorts

      <$m, n, A, B, C$> ::= $U$ | $L$ | $x$  \hspace*{8em} expressions
      \indalt $(x : A) \rightarrow_s B$ | $A \rightarrow_s B$
      \indalt $(x : A) \multimap_s B$ | $A \multimap_s B$
      \indalt $\lambda x. n$ | $m\ n$

      <$v$> ::= $U$ | $L$ | $x$ \hspace*{8em} values
      \indalt $(x : A) \rightarrow_s B$ | $A \rightarrow_s B$
      \indalt $(x : A) \multimap_s B$ | $A \multimap_s B$
      \indalt $\lambda x. n$
    \end{grammar}
    \end{minipage}
    \label{syntax}
  \end{figure}

  A clear departure of our language from standard presentations of type theory is the presence of four function types: $(x : A) \rightarrow_s B$, $A \rightarrow_s B$, $(x : A) \multimap_s B$, $A \multimap_s B$. The reason for these variants is the decoupling of function linearity from the linearity of function domain and co-domain. Instead, the linearity of functions is determined by the linearity of the closure it forms. For example, a function with linear input and output type can itself be non-linear if its free variables have non-linear type, indicating this function can be applied repeatedly without contraction of linear variables. In practice, these function types can be consolidated to just $(x : A) \rightarrow_s B$ and $(x : A) \multimap_s B$ by viewing $A \rightarrow_s B$ and $A \multimap_s B$ as their non-binding special cases. For the sake of clarity, we leave them as four.

  \subsection{Context and Structural Judgments}
  The context of our language employs a mixed linear/non-linear representation introduced by Luo\cite{luo}. Variables in the context are annotated to indicate whether they are linear or non-linear. A non-linear variable is annotated as $\Gamma, x \utype A$, whereas a linear variable is annotated as $\Gamma, x \ltype A$. 
  
  We define a $merge$ relation to combine two mixed contexts $\Gamma_1$ and $\Gamma_2$ by performing contraction on shared non-linear variables. For linear variables, the $merge$ relation is defined if and only if each variable occurs uniquely in one context and not the other. The definition of $merge$ allows contraction for non-linear variables whilst forbidding it for linear ones.

  An auxiliary judgment $\pure$ is defined to assert that a context $\Gamma$ do not contain linear variables. In other words, all variables found in a pure context are of the form $\Gamma, x \utype A$. A restriction function $\overline{\Gamma}$ is defined that removes all linear variables from context $\Gamma$, the result of restriction is a pure subset of the original context.
  
  \begin{figure}[H]
    \caption{Structural Judgments}
    \begin{mathpar}
      \inferrule
      { }
      { \epsilon \ \ok }
      \rname{Ok-$\epsilon$}

      \inferrule
      { \Gamma\ \ok \\ 
        \overline{\Gamma} \vdash A \utype U }
      { \Gamma, x \utype A\ \ok }
      \rname{Ok-U}

      \inferrule
      { \Gamma\ \ok \\ 
        \overline{\Gamma} \vdash A \utype L }
      { \Gamma, x \ltype A\ \ok } 
      \rname{Ok-L}
      \\

      \inferrule
      { }
      { \epsilon\ \pure }
      \rname{Pure-$\epsilon$}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U }
      { \Gamma, x \utype A\ \pure }
      \rname{Pure-U}
      \\

      \inferrule
      { }
      { merge\ \epsilon\ \epsilon\ \epsilon }
      \rname{Merge-$\epsilon$}

      \inferrule
      { merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { merge\ (\Gamma_1, x \utype A)
             \ (\Gamma_2, x \utype A)
             \ (\Gamma, x \utype A) }
      \rname{Merge-U}

      \inferrule
      { merge\ \Gamma_1\ \Gamma_2\ \Gamma \\
        x \notin \Gamma_2 }
      { merge\ (\Gamma_1, x \ltype A)
             \ \Gamma_2
             \ (\Gamma, x \ltype A) }
      \rname{Merge-L1}

      \inferrule
      { merge\ \Gamma_1\ \Gamma_2\ \Gamma \\
        x \notin \Gamma_1 }
      { merge\ \Gamma_1
             \ (\Gamma_2, x \ltype A)
             \ (\Gamma, x \ltype A) }
      \rname{Merge-L2} 
    \end{mathpar}
    \begin{align*}
      \overline{\epsilon} = \epsilon
      \hspace*{4em}
      \overline{\Gamma, x \utype A} = \overline{\Gamma}, x \utype A 
      \hspace*{4em}
      \overline{\Gamma, x \ltype A} = \overline{\Gamma}
    \end{align*}
    \label{structural}
  \end{figure}

  \subsection{Type Formation} \label{tyformation}
  Typing judgments in our language take on the form $\Gamma \vdash m \stype{s} A$, $s$ is an indexing sort that is either $U$ or $L$. Intuitively, this judgment states that expression $m$ has type $A$ and sort $s$ under context $\Gamma$. An expression of sort $L$ is linear, and sort $U$ is non-linear. Surprisingly, duplication of non-linear expression is not immediately allowed, only non-linear \textit{values} can be safely duplicated. We will discuss this subtlety later in more detail.
  
  Type formation rules are presented in Figure \ref{type}. Rules worth discussing in detail are the \rname{L-Axiom} and the rules for constructing various function types. For \rname{L-Axiom}, the sort of all linear types $L$ itself is of non-linear sort $U$. This means that a linear type can be freely used, avoiding the philosophical trappings discussed earlier.

  The function types $(x : A) \rightarrow_s B$ and $A \rightarrow_s B$ represent non-linear functions, where the subscript $s$ is the sort of co-domain $B$. Terms of these types contain no linear free variables, thus can be applied repeatedly without duplication of linear resources. The difference between the two is that $(x : A) \rightarrow_s B$ allows co-domain $B$ to depended on input $x$ of non-linear domain $A$. For $A \rightarrow_s B$, the domain $A$ is linear so $B$ is not allowed to depend on the function input.

  The variants $(x : A) \multimap_s B$ and $A \multimap_s B$ represent linear functions. Terms of these types may contain linear free variables, thus cannot be applied repeated without duplication of linear variables. Similar to the non-linear versions, the difference between $(x : A) \multimap_s B$ and $A \multimap_s B$ lies in the allowance of dependency on function input for non-linear domain types.

  \begin{figure}[H]
    \caption{Type Formation} 
    \begin{mathpar}
      \inferrule
      { \Gamma\ \pure }
      { \Gamma \vdash U \utype U } 
      \rname{U-Axiom}

      \inferrule
      { \Gamma\ \pure }
      { \Gamma \vdash L \utype U } 
      \rname{L-Axiom}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B \utype s }
      { \Gamma \vdash (x : A) \rightarrow_s B \utype U } 
      \rname{U-Prod}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype L \\ 
        \Gamma \vdash B \utype s }
      { \Gamma \vdash A \rightarrow_s B \utype U } 
      \rname{Arrow}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B\ \utype s }
      { \Gamma \vdash (x : A) \multimap_s B \utype L } 
      \rname{L-Prod}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype L \\ 
        \Gamma \vdash B \utype s }
      { \Gamma \vdash A \multimap_s B \utype L } 
      \rname{Lolli}
    \end{mathpar}
    \label{type}
  \end{figure}

  \subsection{Term Formation}
  In classical dependent type theories such as Martin L\"{o}f Type Theory or Calculus of Constructions, strong normalization and confluence ensure that term normalization is agnostic to reduction strategy. Furthermore, the preservation theorem shows that reduction preserves the typing judgment of well-typed terms. The management of substructural contexts for dependent linear types complicates the direct transplant of these theorems. In the application rules $\rname{U-App-1}$ and $\rname{L-App-1}$, the argument $n$ is a non-linear expression that could contain free variables. If a call-by-name reduction strategy is used, substitution of $n$ into the function body may cause duplication of these variables. Some existing literature ban non-linear arguments from containing linear free variables. We find this approach to be overly restrictive as it excludes the pattern of freely using retrieved data (non-linear) from references (linear) ubiquitous in imperative programs. Instead, we adjust the operational semantics to favor call-by-value reduction strategy. Our value soundness theorem guarantee non-linear values to contain only non-linear free variables. Thus, substitution will no longer duplicate linear variables found in argument expressions.

  Furthermore, in the \rname{U-App-1} and \rname{L-App-1} rules, the input expression $n$ is not directly substituted into the dependent co-domain $B$ as this may introduce linear variables into types. Instead, a lambda abstract is formed around $B$ and applied to $n$. This delays $\beta$-reduction until $n$ can be resolved into value-form.

  \begin{figure}[H]
    \caption{Term Formation}
    \begin{mathpar}
      \inferrule
      { \Gamma\ \pure}
      { \Gamma, x \utype A \vdash x \utype A } 
      \rname{U-Var}

      \inferrule
      { \Gamma\ \pure }
      { \Gamma, x \ltype A \vdash x \ltype A } 
      \rname{L-Var}

      \inferrule
      { \Gamma \vdash m \stype{s} A \\ A \equiv B }
      { \Gamma \vdash m \stype{s} B } 
      \rname{Conv}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash (x : A) \rightarrow_s B \utype U \\ 
        \Gamma, x \utype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \utype (x : A) \rightarrow_s B }
      \rname{U-$\lambda_1$}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \rightarrow_s B \utype U \\
        \Gamma, x \ltype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \utype A \rightarrow_s B }
      \rname{U-$\lambda_2$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash (x : A) \multimap_s B \utype L \\ 
        \Gamma, x \utype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \ltype (x : A) \multimap_s B }
      \rname{L-$\lambda_1$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash A \multimap_s B \utype L \\ 
        \Gamma, x \ltype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \ltype A \multimap_s B }
      \rname{L-$\lambda_2$}
      \\

      \inferrule
      { \Gamma_1 \vdash m \utype (x : A) \rightarrow_s B \\
        \Gamma_2 \vdash n \utype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} (\lambda x.B)\ n }
      \rname{U-App-1}
      \\

      \inferrule
      { \Gamma_1 \vdash m \utype A \rightarrow_s B \\
        \Gamma_2 \vdash n \ltype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} B }
      \rname{U-App-2}
      \\

      \inferrule
      { \Gamma_1 \vdash m \ltype (x : A) \multimap_s B \\
        \Gamma_2 \vdash n \utype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} (\lambda x.B)\ n }
      \rname{L-App-1}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \multimap_s B \\
        \Gamma_2 \vdash n \ltype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} B }
      \rname{L-App-2}
    \end{mathpar}
    \label{term}
  \end{figure}

  \subsection{Reduction and Equality}
  Figure \ref{single} presents the call-by-value operational semantics that we have eluded to. The rules defining the single step relation $\step$ are completely standard.

  For full spectrum dependently typed languages, terms can appear at the type level. A definitional equality judgment is required to identify types beyond simple $\alpha$-equivalence. This is usually accomplished by normalization and comparing normal forms. Due to the complications brought on by linearity outlined in \ref{tyformation}, standard normalization techniques cannot be directly applied. Unfortunately, the single step relation $\step$ defined previously is not sufficient either as binders block evaluation. Following the footsteps of the Trellys project\cite{trellys}, we define a call-by-value parallel step relation $\pstep$ that evaluates under binders. We use the transitive reflexive closure of $\pstep$ to define definitional equality.

  \begin{figure}[H]
    \caption{Single Step Reduction}
    \begin{mathpar}
      \inferrule
      { }
      { (\lambda x.n)\ v \step [v/x]n }
      \rname{S-U-$\beta$}

      \inferrule
      { }
      { (\lambda x.n)\ v \step [v/x]n }
      \rname{S-L-$\beta$}

      \inferrule
      { m \step m' }
      { m\ n \step m'\ n }
      \rname{S-App-L}

      \inferrule
      { n \step n' }
      { v\ n \step v\ n' }
      \rname{S-App-R}
    \end{mathpar}
    \label{single}
  \end{figure}

  \begin{figure}[H]
    \caption{Equality and Parallel Reduction}
    \begin{mathpar}
      \inferrule
      { m_1 \pstep^* n \\ m_2 \pstep^* n }
      { m_1 \equiv m_2 : A }
      \rname{Join}

      \inferrule
      { }
      { x \pstep x }
      \rname{P-Var}

      \inferrule
      { }
      { U \pstep U }
      \rname{P-U}

      \inferrule
      { }
      { L \pstep L }
      \rname{P-L}

      \inferrule
      { n \pstep n' }
      { \lambda x.n \pstep \lambda x.n' }
      \rname{P-$\lambda$}

      \inferrule
      { n \pstep n' }
      { \lambda x.n \pstep \lambda x.n' }
      \rname{P-$\lambda$}

      \inferrule
      { m \pstep m' \\ n \pstep n' }
      { m\ n \pstep m'\ n' }
      \rname{P-App}

      \inferrule
      { n \pstep n' \\ v \pstep v' }
      { (\lambda x.n)\ v \pstep [v'/x]n' }
      \rname{P-U-$\beta$}

      \inferrule
      { n \pstep n' \\ v \pstep v' }
      { (\lambda x.n)\ v \pstep [v'/x]n' }
      \rname{P-L-$\beta$}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { (x : A) \rightarrow_s B \pstep (x : A') \rightarrow_s B' }
      \rname{P-U-Prod}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { A \rightarrow_s B \pstep A' \rightarrow_s B' }
      \rname{P-Arrow}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { (x : A) \multimap_s B \pstep (x : A') \multimap_s B' }
      \rname{P-L-Prod}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { A \multimap_s B \pstep A' \multimap_s B' }
      \rname{P-Lolli}
    \end{mathpar}
    \label{parallel}
  \end{figure}

  \subsection{Meta Theory}
  We have proven the type soundness of our language in the form of \textit{progress} and \textit{preservation} theorems. The proofs have been formalized in Coq with help from the Autosubst\cite{autosubst} library.

  \subsubsection{Step and Parallel Step}

  The following lemmas and proofs are entirely standard. The restriction to value-form arguments for $\beta$-reduction does not pose any complications.

  \begin{lemma}
    Single step reduction implies parallel step reduction. If $m \step m'$, then $m \pstep m'$.
  \end{lemma}

  \begin{lemma}
    Parallel reduction satisfies the diamond property. If $m \pstep m_1$ and $m \pstep m_2$ then there exists $m'$ such that $m_1 \pstep m'$ and $m_2 \pstep m'$.
  \end{lemma}

  \begin{corollary}
    The transitive reflexive closure of parallel reduction is confluent. If $m \pstep^* m_1$ and $m \pstep^* m_2$ then there exists $m'$ such that $m_1 \pstep^* m'$ and $m_2 \pstep^* m'$.
  \end{corollary}

  \begin{corollary}
    The definitional equality relation is an equivalence relation.
  \end{corollary}

  \subsubsection{Substitution}
  Though the \textit{substitution} lemma is generally considered a boring and bureaucratic theorem, it is surprisingly hard to design linear typed languages where the \textit{substitution} lemma is admissible. Much of this difficulty arises during the substitution of non-linear expressions. Perhaps the most famous example detailing the issues of substitution is due to Wadler\cite{substitute}. Since computation arises as a consequence of substitution, it is paramount to get it right.

  \begin{lemma}
    Value soundness. If $\Gamma \vdash v \utype A$ then $\Gamma\ \pure$.
  \end{lemma}

  \begin{lemma}
    Substitution. For $\Gamma_1, x \stype{s} A \vdash m \stype{t} B$ and $\Gamma_2 \vdash v \stype{s} A$, if there exists $\Gamma$ such that $merge\ \Gamma_1\ \Gamma_2\ \Gamma$ is defined, then $\Gamma \vdash [v/x]m \stype{t} [v/x]B$.
  \end{lemma}

  \begin{theorem}
    Partial Weakening. If $\Gamma \vdash m \stype{s} A$ then $\Gamma, x \utype B \vdash m \stype{s} A$ is derivable.
  \end{theorem}

  \begin{theorem}
    Progress. For $\epsilon \vdash m \stype{s} A$, either $m$ is a value or there exists $n$ such that $m \step n$.
  \end{theorem}

  \begin{theorem}
    Preservation. For $\Gamma \vdash m \stype{s} A$, if $m \pstep n$ then $\Gamma \vdash n \stype{s} A$.
  \end{theorem}

  \subsection{Data Types}

  \subsection{Future Work}
  All of the theorems we have developed so far are purely syntactic in nature. But the natural correspondence between linear types and call-by-value semantics seem to hint at a deeper connection. Indeed, past works\cite{cbvsemantics} have provided insight for the simply typed case. We would like to extend these results our dependent linear type theory.

  \subsection{Conclusion}

\bibliographystyle{acm}
\bibliography{ref}

\end{document}