\documentclass[sigplan,screen,review,anonymous]{acmart}

\usepackage[utf8]{inputenc}

% packages
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mdwtab}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{listings}
\usepackage{float}
\usepackage{tikz-cd}
\usepackage{enumitem}
\usepackage{minted}

\setlist[itemize]{leftmargin=1.6em}
\renewcommand{\syntleft}{}
\renewcommand{\syntright}{}
\setlength{\grammarparsep}{7pt}
\setlength{\grammarindent}{7em}
\newcommand{\indalt}[1][2]{\\\hspace*{-1.2em}\textbar\quad}
\newcommand{\rname}[1]{\textsc{\footnotesize #1}}
\newcommand{\pure}[1]{|#1|}
\newcommand{\refl}{\text{refl}}
\newcommand{\letin}[3]{\ $\text{let }#1\text{ := }#2\text{ in }#3$\ }
\newcommand{\ind}[1]{\text{Ind}_{#1}}
\newcommand{\constr}{\text{Constr}}
\newcommand{\case}{\text{Case}}
\newcommand{\dcase}{\text{DCase}}
\newcommand{\fix}{\text{Fix }}
\newcommand{\sep}{\text{ | }}
\newcommand{\unit}{\texttt{unit}}
\newcommand{\new}{\texttt{new}}
\newcommand{\free}{\texttt{free}}
\newcommand{\get}{\texttt{get}}
\newcommand{\set}{\texttt{set}}
\newcommand{\session}{\texttt{session}}
\newcommand{\channel}{\texttt{channel}}
\newcommand{\open}{\texttt{open}}
\newcommand{\close}{\texttt{close}}
\newcommand{\send}{\texttt{send}}
\newcommand{\recv}{\texttt{recv}}
\newcommand{\SEND}{\texttt{SEND}}
\newcommand{\RECV}{\texttt{RECV}}
\newcommand{\END}{\texttt{END}}
\newcommand{\utype}{:_{\scriptscriptstyle U}}
\newcommand{\ltype}{:_{\scriptscriptstyle L}}
\newcommand{\stype}[1]{:_#1}
\newcommand{\step}{\leadsto}
\newcommand{\red}{\leadsto^*}
\newcommand{\pstep}{\leadsto_p}
\newcommand{\mrg}[3]{merge\ {#1}\ {#2}\ {#3}}
\newcommand{\erase}[1]{\llbracket #1 \rrbracket}
\newcommand{\lift}[1]{\llparenthesis #1 \rrparenthesis}
\newcommand{\lrangle}[1]{\langle #1 \rangle}
\newcommand{\SigmaL}{\Sigma_{\scriptscriptstyle L}}
\newcommand{\ucons}{constructor_{\scriptscriptstyle U}}
\newcommand{\lcons}{constructor_{\scriptscriptstyle L}}
\newcommand{\scons}{constructor_{s}}
\newcommand{\inl}{\text{inl}}
\newcommand{\inr}{\text{inr}}
\newcommand{\arrv}{\texttt{ArrVec}}

\title{The Calculus of Linear Constructions}
\author{Qiancheng Fu}
\affiliation{
  \institution{Boston University}
  \city{Boston}
  \state{MA}
  \country{USA}
}
\email{qcfu@bu.edu}

\keywords{Dependent types, linear types, inductive types, Calculus of Constructions}

\begin{document}
\begin{abstract}
  The Calculus of Linear Constructions (CLC) is an extension of the Calculus of Constructions (CC) with linear types. Specifically, CLC extends the predicative CC$\omega$ with a hierarchy of linear universes that precisely controls the weakening and contraction of its term level inhabitants. We study the meta-theory of CLC, showing that it is a sound logical framework for reasoning about resource. We further extend CLC with rules for defining inductive linear types in the style of CIC, forming the Calculus of Inductive Linear Constructions (CILC). Through examples, we demonstrate that CILC facilitates correct by construction imperative programming and lightweight protocol enforcement. We have formalized and proven correct all major results in the Coq Proof Assistant.
\end{abstract}
\maketitle

\section{Introduction}
The Calculus of Constructions (CC) is a dependent type theory introduced by Coquand and Huet in their landmark work \cite{cc}. In CC, types can depend on terms, allowing one to write precise specifications as types. Today, CC and its extensions CIC \cite{cic} and ECC \cite{ecc} lie at the core of popular proof assistants such as Coq \cite{coq}, Agda \cite{agda}, Lean \cite{lean} and others. These theorem provers have found great success in the fields of software verification and constructive mathematics.

However, due to its origins as a logical framework for constructive mathematics, it can be inconvenient for CC to encode and reason about resource. Users of proof assistants based on CC often need to embed external logics such as Separation Logic to provide domain-specific reasoning principles for dealing with resource. We propose an alternative solution: extend CC with linear types.

This paper presents a new linear dependent type system --- the Calculus of Linear Constructions (CLC). CLC extends the predicative CC$\omega$ with linear types. CC$\omega$ itself is an extension of CC with a cumulative hierarchy of type universes. We add an extra universe sort $L$ of linear types with cumulativity parallel to the sort $U$ of non-linear types. This ultimately cumulates in the \textit{linearity} theorem, stating that every resource is used exactly once.

Preexisting approaches to integrating linear types and dependent types often relied on the ! exponential or separate typing judgments for linear and non-linear types. The universe sorts of CLC are enough to completely distinguish between linear and non-linear types within a single typing judgment. As a result, CLC falls much closer to its CC roots than prior works in both syntax and semantics.

We further extend CLC with rules for defining inductive linear types in the style of CIC, forming the Calculus of Inductive Linear Constructions (CILC). Standard Linear Logic connectives such as $\otimes$ and $\oplus$ are definable using this generalized mechanism in a straightforward way. Connectives that mix linear and non-linear types can be constructed just as easily using CILC.

Through examples in Section \ref{examples}, we show some applications of CILC such as construction of safe random access array from the first principles, protocol enforcement through inductively defined session types and in-place update of data structures using continuations.

We have formalized all major results in Coq and implemented a prototype in OCaml. Additional examples of applications such as provable effect laws and quantitative reasoning are included with our implementation.

\vspace{4pt}
\noindent \textbf{\textit{Contributions}}:
Our contributions can be summarized as follows.
\begin{itemize}
  \item First, we describe the Calculus of Linear Constructions, an extension to the Calculus of Constructions with linear types, enabling direct and precise reasoning about resource.
  \item Second, we study the meta-theory of CLC, showing that it exhibits many desirable properties such as confluence, subject reduction and logical consistency.
  \item Furthermore, we extend CLC with rules to define inductive linear types, forming the Calculus of Inductive Linear Constructions (CILC). This is the first complete presentation of a generalized mechanism for defining inductive linear types.
  \item All major results have been proven correct in the Coq. Our development is the first machine checked formalization of a linear dependent type theory. We have also implemented a prototype of CILC in OCaml.
\end{itemize}

\section{The Language of CLC}
\subsection{Syntax}
\begin{figure}[h]
  \caption{Syntax of CLC}
  \begin{grammar}
    <$i$> ::= 0 | 1 | 2 ... \phantom{* |} \hspace*{3em} universe levels

    <$s, t$> ::= $U$ | $L$ \phantom{| $x$} \hspace*{4.6em} sorts

    <$m, n, A, B, M$> ::= $U_i$ | $L_i$ | $x$ \hspace*{4.2em} expressions
    \indalt $(x :_s A) \rightarrow B$
    \indalt $(x :_s A) \multimap B$
    \indalt $\lambda x :_s A. n$
    \indalt $m\ n$
  \end{grammar}
  \Description{}
  \label{syntax1}
\end{figure}

The syntax of the core type theory is presented in Figure \ref{syntax1}. Our type theory contains two sorts of universes $U$ and $L$. We use the meta variable $i$ to quantify over universe levels $0, 1, 2, ...$. $U_i$ and $L_i$ are the universes at level $i$ of non-linear and linear types respectively.
\begin{figure}[h]
  \caption{Correspondence of CLC types and MELL implications}
  \Description{}
  \begin{align}
    (\_ \utype A) \rightarrow B \quad & \Leftrightarrow \quad !(!A \multimap B) \\
    (\_ \ltype A) \rightarrow B \quad & \Leftrightarrow \quad !(A \multimap B)  \\
    (\_ \utype A) \multimap B \quad   & \Leftrightarrow \quad !A \multimap B    \\
    (\_ \ltype A) \multimap B \quad   & \Leftrightarrow \quad A \multimap B
  \end{align}
  \label{correspondence}
\end{figure}

A clear departure of our language from standard presentations of both linear type theory and dependent type theory is the presence of two function types: $(x :_s A) \rightarrow B$ and $(x :_s A) \multimap B$. The reason for these function types is that we have built the ! exponential of linear logic implicitly into universe sorts. The sort annotation $s$ here records the universe sort of the function domain. The behavior of ! is difficult to account for even in simple linear type theories. Subtle issues arise if !! is not canonically isomorphic to !, which may invalidate the substitution lemma \cite{substitute}. By integrating the exponential directly into universe sorts, we have limited ! to only be canonically usable. This allows us to derive the substitution lemma and construct a direct modeling of CLC in CC$\omega$ without requiring any additional machinery for manipulating exponential.

Figure \ref{correspondence} illustrates the correspondence between CLC functions and Multiplicative Exponential Linear Logic (MELL) implications. MELL lacks counterparts for the cases (1), (3) if the co-domain $B$ is dependent on arguments of domain $A$. We will discuss function type formation in Section \ref{tyformation} in greater detail.

Algorithmic type checking techniques allow users to omit writing sort indices for many situations in practice. Our implementation employs bi-directional type checking and users rarely interact with sort indices in the surface syntax.

\subsection{Universes and Cumulativity}
CLC features two sorts of universes $U$ and $L$ with level indices $0, 1, 2, \cdots$. $U_i$ and $L_i$ are the predicative universes of non-linear types and linear types respectively. The main mechanism that CLC uses to distinguish between linear and non-linear types is by checking the universes to which they belong. Basically, terms with types that occur within $U_i$ are unrestricted in their usage. Terms with types that occur within $L_i$ are restricted to being used exactly once.

In order to lift terms from lower universes to higher ones, there exists cumulativity between universe levels of the same sort. We define cumulativity as follows.

\begin{definition}
  The cumulativity relation ($\preceq$) is the smallest binary relation over terms such that
  \begin{enumerate}
    \item $\preceq$ is a partial order with respect to equality.
          \begin{enumerate}
            \item If $A \equiv B$, then $A \preceq B$.
            \item If $A \preceq B$ and $B \preceq A$, then $A \equiv B$.
            \item If $A \preceq B$ and $B \preceq C$, then $A \preceq B$.
          \end{enumerate}
    \item $U_0 \preceq U_1 \preceq U_2 \preceq \cdots$
    \item $L_0 \preceq L_1 \preceq L_2 \preceq \cdots$
    \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, \\ then
          $(x \stype{s} A_1) \rightarrow B_1 \preceq (x \stype{s} A_2) \rightarrow B_2$
    \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, \\ then
          $(x \stype{s} A_1) \multimap B_1 \preceq (x \stype{s} A_2) \multimap B_2$
  \end{enumerate}
\end{definition}

Figure \ref{universe} illustrates the structure of our universe hierarchy. Each linear universe $L_i$ has $U_{i+1}$ as its type, allowing functions to freely quantify over linear \textit{types}. However, $L_i$ cumulates to $L_{i+1}$. These two parallel threads of cumulativity prevent linear types from being transported to the non-linear universes and subsequently losing track of linearity.

\begin{figure}[h]
  \caption{The Universe Hierarchy}
  \vspace{1em}
  \centering
  \begin{tikzcd}
    U_0 \arrow[r, ":"', "\preceq", dash]
    & U_1 \arrow[r, ":"', "\preceq", dash]
    & U_2 \arrow[r, ":"', "\preceq", dash]
    & \cdots \\
    L_0 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash]
    & L_1 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash]
    & L_2 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash]
    & \cdots
  \end{tikzcd}
  \label{universe}
  \Description{}
\end{figure}

\subsection{Context and Structural Judgments}
The context of our language employs a mixed linear/non-linear representation in the style of Luo\cite{luo}. Variables in the context are annotated to indicate whether they are linear or non-linear. A non-linear variable is annotated as $\Gamma, x \utype A$, whereas a linear variable is annotated as $\Gamma, x \ltype A$.

Next, we define a $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ relation that merges two mixed contexts $\Gamma_1$, and $\Gamma_2$ into $\Gamma$, by performing contraction on shared non-linear variables. For linear variables, the $merge$ relation is defined if and only if each variable occurs uniquely in one context and not the other. This definition of $merge$ is what allows contraction for unrestricted variables whilst forbidding it for restricted ones.

An auxiliary judgment $\pure{\Gamma}$ is defined to assert that a context $\Gamma$ does not contain linear variables. In other words, all variables found in $\pure{\Gamma}$ are annotated of the form $x \utype A$. The full rules for structural judgments are presented in Figure \ref{structural}.

\begin{figure}[h]
  \caption{Structural Judgments}
  \begin{mathpar}
    \inferrule
    { }
    { \epsilon \vdash }
    \rname{Wf-$\epsilon$}

    \inferrule
    { \Gamma\ \vdash \\
      \overline{\Gamma} \vdash A : U_i }
    { \Gamma, x \utype A \vdash }
    \rname{Wf-U}

    \inferrule
    { \Gamma\ \vdash \\
      \overline{\Gamma} \vdash A : L_i }
    { \Gamma, x \ltype A\ \vdash }
    \rname{Wf-L}

    \inferrule
    { }
    { \pure{\epsilon} }
    \rname{Pure-$\epsilon$}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : U_i }
    { \pure{\Gamma, x \utype A} }
    \rname{Pure-U}

    \inferrule
    { }
    { \mrg{\epsilon}{\epsilon}{\epsilon} }
    \rname{Merge-$\epsilon$}

    \inferrule
    { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
    { \mrg{(\Gamma_1, x \utype A)}
      {(\Gamma_2, x \utype A)}
      {(\Gamma, x \utype A)} }
    \rname{Merge-U}

    \inferrule
    { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
      x \notin \Gamma_2 }
    { \mrg{(\Gamma_1, x \ltype A)}
      {\Gamma_2}
      {(\Gamma, x \ltype A)} }
    \rname{Merge-L1}

    \inferrule
    { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
      x \notin \Gamma_1 }
    { \mrg{\Gamma_1}
      {(\Gamma_2, x \ltype A)}
      {(\Gamma, x \ltype A)} }
    \rname{Merge-L2}
  \end{mathpar}
  \label{structural}
  \Description{}
\end{figure}

\begin{definition}
  The context restriction function $\overline{\Gamma}$ is defined as a recursive filter over $\Gamma$ as follows. All linear variables are removed from context $\Gamma$. The result of context restriction is the non-linear subset of the original context.
  \begin{align*}
    \overline{\epsilon} = \epsilon
    \hspace*{4em}
    \overline{\Gamma, x \utype A} = \overline{\Gamma}, x \utype A
    \hspace*{4em}
    \overline{\Gamma, x \ltype A} = \overline{\Gamma}
  \end{align*}
\end{definition}

\subsection{Typing Judgment}
Typing judgments in CLC take on the form of $\Gamma \vdash m : A$. Intuitively, this judgment states that the term $m$ is an inhabitant of type $A$, with free variables typed in $\Gamma$.

\begin{definition} We formally define the terminology \textit{non-linear}, \textit{linear}, \textit{unrestricted} and \textit{restricted}.
  \begin{enumerate}
    \item A \textit{type} $A$ is \textit{non-linear} under context $\Gamma$ if $\Gamma \vdash A : U_i$.
    \item A \textit{type} $A$ is \textit{linear} under context $\Gamma$ if $\Gamma \vdash A : L_k$.
    \item A \textit{term} $m$ is \textit{unrestricted} under context $\Gamma$ if there exists non-linear type $A$ such that $\Gamma \vdash m : A$. An unrestricted term may be used any number of times.
    \item A \textit{term} $m$ is \textit{restricted} under context $\Gamma$ if there exists linear type $A$ such that $\Gamma \vdash m : A$. A restricted term must be used exactly once.
  \end{enumerate}
\end{definition}

\subsection{Type Formation} \label{tyformation}
The rules for forming types are presented in Figure \ref{type}. In CLC, we forbid types from depending on linear terms similarly to \cite{llf,neel15} for the same reason of avoiding philosophical troubles.

The axiom rules \rname{U-Axiom} and \rname{L-Axiom} are similar to standard CC$\omega$, the main difference being the extra side-condition of judgment $\pure{\Gamma}$. In most presentations of dependent type theories without linear types, the universe axioms are derivable under any well-formed context $\Gamma$. Variables not pertaining to actual proofs could be introduced this way, thus giving rise to the weakening rule. To support linear types, we must restrict weakening to non-linear variables. This justifies the restriction of $\Gamma$ to contain only non-linear variables for \rname{U-Axiom} and \rname{L-Axiom}. From \rname{L-Axiom} we can see that the universe of linear types $L_i$ is an inhabitant of $U_{i+1}$. This is inspired by Krishnaswami et al.'s treatment of linear universes \cite{neel15}, where linear \textit{types} themselves can be used unrestrictedly.

\begin{figure}[h]
  \caption{Type Formation}
  \begin{mathpar}
    \inferrule
    { \pure{\Gamma} }
    { \Gamma \vdash s_i : U_{i+1} }
    \rname{Sort-Axiom}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : U_i \\
      \Gamma, x \utype A \vdash B : s_i }
    { \Gamma \vdash (x \utype A) \rightarrow B : U_i }
    \rname{U$\rightarrow$}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : L_i \\
      \Gamma \vdash B : s_i \\
      x \notin \Gamma }
    { \Gamma \vdash (x \ltype A) \rightarrow B : U_i }
    \rname{L$\rightarrow$}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : U_i \\
      \Gamma, x \utype A \vdash B : s_i }
    { \Gamma \vdash (x \utype A) \multimap B : L_i }
    \rname{U$\multimap$}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : L_i \\
      \Gamma \vdash B : s_i \\
      x \notin \Gamma }
    { \Gamma \vdash (x \ltype A) \multimap B : L_i }
    \rname{L$\multimap$}
  \end{mathpar}
  \label{type}
  \Description{}
\end{figure}

The \rname{U$\rightarrow$} rule is used for forming non-linear function types with non-linear domains. This is evident from the judgment $\Gamma \vdash A : U_i$. Due to the fact that $A$ is in the non-linear universe $U_i$, terms of type $A$ have unrestricted usage. The non-linearity of domain $A$ allows $B$ to depend on terms of type $A$, as seen in judgment $\Gamma, x \utype A \vdash B : s_i$. The domain $B$ itself may be linear of non-linear, since $B$'s universe $s_k$ can vary between $U_i$ and $L_i$. From the resulting judgment $\Gamma \vdash (x \utype A) \rightarrow B : U_i$, we see that the overall type is a non-linear type. The term level $\lambda$-abstractions of these types can be used unrestrictedly.

The \rname{L$\rightarrow$} rule is used for forming non-linear function types with linear domains. From the judgment $\Gamma \vdash A : L_i$, we see that $A$ is a linear type, and terms of type $A$ have restricted usage. Because of this, we forbid co-domain $B$ from depending on terms of type $A$, evidently in the judgment $\Gamma \vdash B : s_i$. Like \rname{U$\rightarrow$}, co-domain $B$ itself may be linear or non-linear, since $B$'s universe $s_i$ can vary between $U_i$ and $L_i$. The final resulting judgment is $\Gamma \vdash (x \ltype A) \rightarrow B : U_i$. Here, $x$ is a hypocritical unbinding variable whose only purpose is to preserve syntax uniformity. Again, the overall resulting type is non-linear, so the term level $\lambda$-abstractions of these types can be used unrestrictedly.

The \rname{U$\multimap$}, \rname{L$\multimap$} rules are similar to \rname{U$\rightarrow$}, \rname{L$\rightarrow$} in spirit. The dependency considerations for domain $A$ and co-domain $B$ are exactly the same. The main difference between \rname{U$\multimap$}, \rname{L$\multimap$} and \rname{U$\rightarrow$}, \rname{L$\rightarrow$} is the universe sort of the resulting type. The sorts of the function types formed by \rname{U$\multimap$}, \rname{L$\multimap$} are $L$, meaning they are linear function types. The term level $\lambda$-abstractions of these types must be used exactly once.

\subsection{Term Formation} \label{teformation}
The rules for term formation are presented in Figure~\ref{term}.

\begin{figure}[h]
  \caption{Term Formation}
  \begin{mathpar}
    \inferrule
    { \pure{\Gamma_1, \Gamma_2} }
    { \Gamma_1, x \utype A, \Gamma_2 \vdash x : A }
    \rname{U-Var}

    \inferrule
    { \pure{\Gamma_1, \Gamma_2} }
    { \Gamma_1, x \ltype A, \Gamma_2 \vdash x : A }
    \rname{L-Var}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash (x \stype{s} A) \rightarrow B : t_i \\
      \Gamma, x \stype{s} A \vdash n : B }
    { \Gamma \vdash \lambda x \stype{s} A . n : (x \stype{s} A) \rightarrow B }
    \rname{$\lambda$$\rightarrow$}

    \inferrule
    { \overline{\Gamma} \vdash (x \stype{s} A) \multimap B : t_i \\
      \Gamma, x \stype{s} A \vdash n : B }
    { \Gamma \vdash \lambda x \stype{s} A . n : (x \stype{s} A) \multimap B }
    \rname{$\lambda$$\multimap$}

    \inferrule
    { \Gamma_1 \vdash m : (x \utype A) \rightarrow B \\
      \pure{\Gamma_2} \\
      \Gamma_2 \vdash n : A \\
      \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
    { \Gamma \vdash m\ n : B[n/x] }
    \rname{App-U$\rightarrow$}

    \inferrule
    { \Gamma_1 \vdash m : (x \ltype A) \rightarrow B \\
      \Gamma_2 \vdash n : A \\
      \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
    { \Gamma \vdash m\ n : B[n/x] }
    \rname{App-L$\rightarrow$}

    \inferrule
    { \Gamma_1 \vdash m : (x \utype A) \multimap B \\
      \pure{\Gamma_2} \\
      \Gamma_2 \vdash n : A \\
      \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
    { \Gamma \vdash m\ n : B[n/x] }
    \rname{App-U$\multimap$}

    \inferrule
    { \Gamma_1 \vdash m : (x \ltype A) \multimap B \\
      \Gamma_2 \vdash n : A \\
      \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
    { \Gamma \vdash m\ n : B[n/x] }
    \rname{App-L$\multimap$}

    \inferrule
    { \Gamma \vdash m : A \\
      \overline{\Gamma} \vdash B : s_i \\ A \preceq B }
    { \Gamma \vdash m : B }
    \rname{Conversion}
  \end{mathpar}
  \label{term}
  \Description{}
\end{figure}

The rules \rname{U-Var} and \rname{L-Var} are used for typing free variables. The \rname{U-Var} rule asserts that free variable $x$ occurs within the context $\Gamma_1, x \utype A, \Gamma_2$ with a non-linear type $A$. The \rname{L-Var} rule asserts that free variable $x$ occurs within the context $\Gamma_1, x \ltype A, \Gamma_2$ with linear type $A$. For both rules, the side condition $\pure{\Gamma_1, \Gamma_2}$ forbids irrelevant variables of linear types from occurring within the context. This prevents another vector of weakening variables with linear type.

In \rname{$\lambda$$\rightarrow$}, the function type has the form $(x \stype{s} A) \rightarrow B$. Abstractions of this type can be applied an unrestricted number of times, hence cannot depend on free variables with restricted usage without possibly duplicating them. This consideration is realized by the side condition $\pure{\Gamma}$, asserting all variables in context $\Gamma$ are unrestricted. Next, the body of the abstraction $n$ is typed as $\Gamma, x \stype{s} A \vdash n : B$, where $s$ is the sort of $A$. Finally, the resulting judgment $\Gamma \vdash \lambda x.n : (x \stype{s} A) \rightarrow B$ asserts that the $\lambda$-abstraction can be used unrestrictedly.

In contrast to \rname{$\lambda$$\rightarrow$}, the \rname{$\lambda$$\multimap$} rule is used for forming abstractions that must be used exactly once. Due to the fact that these abstractions must be used once, they are allowed access to restricted variables within context $\Gamma$, evidently in the judgment $\Gamma, x \stype{s} A \vdash n : B$ and lack of side condition $\pure{\Gamma}$. However, in judgment $\overline{\Gamma} \vdash (x \stype{s} A) \multimap B : L_k$ the context must be filtered, because types are not allowed to depend on restricted variables. The final resulting judgment $\Gamma \vdash \lambda x.n : (x \stype{s} A) \multimap B$ asserts that the $\lambda$-abstraction must be used exactly once.

For \rname{App-U$\rightarrow$}, domain $A$ is a non-linear type, as seen by its annotation in $(x \utype A) \rightarrow B$. Intuitively, this tells us that $x$ may be used an arbitrary number of times within the body of $m$. Thus, the supplied argument $n$ must not depend on restricted variables in context $\Gamma_2$. Otherwise, substitution may put multiple copies of $n$ into $m$ during $\beta$-reduction, duplicating variables that should have been restricted. This justifies the side condition of $\pure{\Gamma_2}$. The contexts $\Gamma_1$ and $\Gamma_2$ are finally merged together into $\Gamma$ by the relation $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, contracting all unrestricted variables shared between $\Gamma_1$ and $\Gamma_2$.

Now for \rname{App-L$\rightarrow$}, domain $A$ is a linear type, as seen by its annotation in $(x \ltype A) \rightarrow B$. Intuitively, this tells us that $x$ must be used once within the body of $m$. During $\beta$-reduction, substitution will only put a single copy of $n$ into the body of $m$, so $n$ can depend on restricted variables within $\Gamma_2$ without fear of duplicating them. This justifies the lack of side condition $\pure{\Gamma_2}$. The contexts $\Gamma_1$ and $\Gamma_2$ are finally merged together into $\Gamma$ by the relation $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, contracting all unrestricted variables shared between $\Gamma_1$ and $\Gamma_2$.

The rules \rname{App-U$\multimap$}, \rname{App-L$\multimap$} follow the same considerations as \rname{App-U$\rightarrow$}, \rname{App-L$\rightarrow$}. Additional conditions are not required for these two rules to be sound.

Finally, the \rname{Conversion} rule allows judgment $\Gamma \vdash m : A$ to convert to judgment $\Gamma \vdash m : B$ if $B$ is a valid type in context $\overline{\Gamma}$. Futhermore, $A$ must be a subtype of $B$ satisfying the relation $A \preceq B$. This rule gives rise to large eliminations (compute types from terms), as computations embedded at the type level can reduce to canonical types.

\subsection{Equality and Reduction} \label{reduction}
The operational semantics and $\beta$-equality of CLC terms are presented in Figure \ref{red}, all of which are entirely standard.

As we have discussed previously, the elimination of the explicit ! exponential allows CLC to maintain the standard operational semantics of CC$\omega$, whose $\beta$-reductions are very well behaved.

\begin{figure}[h]
  \caption{Equality and Reduction}
  \begin{mathpar}
    \inferrule
    { m_1 \step^* n \\ m_2 \step^* n }
    { m_1 \equiv m_2 : A }
    \rname{Join}

    \inferrule
    {  }
    { (\lambda x \stype{s}A.m)\ n \step m[n/x] }
    \rname{Step-$\beta$}

    \inferrule
    { A \step A' }
    { \lambda x \stype{s}A.m \step \lambda x \stype{s}A' .m }
    \rname{Step-$\lambda$L}

    \inferrule
    { m \step m' }
    { \lambda x \stype{s}A.m \step \lambda x \stype{s}A.m' }
    \rname{Step-$\lambda$R}

    \inferrule
    { A \step A' }
    { (x \stype{s} A) \rightarrow B \step (x \stype{s} A') \rightarrow B }
    \rname{Step-L$\rightarrow$}

    \inferrule
    { B \step B' }
    { (x \stype{s} A) \rightarrow B \step (x \stype{s} A) \rightarrow B' }
    \rname{Step-R$\rightarrow$}

    \inferrule
    { A \step A' }
    { (x \stype{s} A) \multimap B \step (x \stype{s} A') \multimap B }
    \rname{Step-L$\multimap$}

    \inferrule
    { B \step B' }
    { (x \stype{s} A) \multimap B \step (x \stype{s} A) \multimap B' }
    \rname{Step-R$\multimap$}

    \inferrule
    { m \step m' }
    { m\ n \step m'\ n }
    \rname{Step-AppL}

    \inferrule
    { n \step n' }
    { m\ n \step m\ n' }
    \rname{Step-AppR}
  \end{mathpar}
  \label{red}
  \Description{}
\end{figure}

\subsection{Meta Theory} \label{meta}
In this section, we focus our discussion on the properties of CLC. First, we show the type soundness of CLC through the \textit{subject reduction} theorem. Next, through the \textit{linearity} theorem we illustrate how CLC can effectively control usage of resource. Furthermore, we demonstrate that the \textit{promotion} and \textit{dereliction} rules can be encoded as $\eta$-expansions. Finally, we construct a reduction preserving erasure function that maps well-typed CLC terms to well-typed CC$\omega$ terms, proving that CLC is strongly normalizing.

All proofs have been formalized in Coq with help from the Autosubst \cite{autosubst} library. The Coq development is publicly available on the author's Github repository. To the best of our knowledge, this is the first machine checked formalization of a linear dependently type theory. We give a hand written version of the proof in an accompanying technical report.

\subsubsection{Reduction and Confluence}

The proof of confluence is entirely standard using parallel reduction technique \cite{takahashi}. The presence of linear types does not pose any complications as reductions are untyped.

\begin{theorem}
  The transitive reflexive closure of reduction is confluent. If $m \step^* m_1$ and $m \step^* m_2$ then there exists $m'$ such that $m_1 \step^* m'$ and $m_2 \step^* m'$.
\end{theorem}

\subsubsection{Weakening} \label{weakening}
CLC restricts the weakening rule for variables of linear types. However, weakening variables of non-linear types remain admissible.

\begin{theorem}
  Weakening. If $\Gamma \vdash m : A$ is a valid judgment, then for any $x \notin \Gamma$, the judgment $\Gamma, x \utype B \vdash m : A$ is derivable.
\end{theorem}

\subsubsection{Substitution} \label{subst}
Although the substitution lemma is regarded as a boring and bureaucratic result, it is surprisingly hard to design linear typed languages where the substitution lemma is admissible. Much of the difficulty arises during the substitution of arguments containing ! exponential. Perhaps the most famous work detailing the issues of substitution is due to Wadler \cite{substitute}. He defines intricate syntax and semantics for the unboxing of ! terms, solving the lack of substitute in Abramsky's term calculus.

Our design of integrating ! into universe sorts removes the need for ! manipulating syntax and semantics. The following substitution theorems are directly proved by induction on typing derivation.

\begin{theorem}\label{nlsubst}
  Non-linear Substitution. For $\Gamma_1, x \utype A \vdash m : B$ and $\Gamma_2 \vdash n : A$, if $\pure{\Gamma_2}$ and $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ are valid for some $\Gamma$, then $\Gamma \vdash m[n/x] : B[n/x]$.
\end{theorem}

\begin{theorem}\label{lsubst}
  Linear Substitution. For $\Gamma_1, x \ltype A \vdash m : B$ and $\Gamma_2 \vdash n : A$, if $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ is valid for some $\Gamma$, then $\Gamma \vdash m[n/x] : B[n/x]$.
\end{theorem}

Notice in Theorem \ref{nlsubst} of non-linear substitutions, there exists an extra condition $\pure{\Gamma_2}$ which Theorem \ref{lsubst} of linear substitutions lacks. This condition ensures that linear variables do not occur within the substituted term, thus cannot be duplicated by substitution.

\subsubsection{Type Soundness}
In order to prove subject reduction, we first prove the validity theorem. The main purpose of validity is to lower types down to the term level, enabling the application of various inversion lemmas.

\begin{theorem}
  Validity. For any context $\Gamma$, term $m$, type $A$, and sort $s$, if $\Gamma \vdash m : A$ is a valid judgment, then there exist some sort $s$ and level $i$ such that $\overline{\Gamma} \vdash A : s_i$.
  \label{validity}
\end{theorem}

With weakening, substitution, validity and various inversion lemmas proven, subject reduction can now be proved by induction on typing derivation.

\begin{theorem}
  Subject Reduction. For $\Gamma \vdash m : A$, if $m \step n$ then $\Gamma \vdash n : A$.
\end{theorem}

\subsubsection{Linearity}
At this point, we have proven that CLC is type sound. However, we still need to prove that the removal of weakening and contraction for restricted variables yields tangible impact on the structure of terms. For this purpose, we define a binding aware recursive function $occurs(x, m)$ that counts the number of times variable $x$ appears within term $m$. The linearity theorem asserts that restricted variables are used exactly once within a term, subsuming safe resource usage.

\begin{theorem}
  Linearity. If $\Gamma \vdash m : A$ is a valid judgment, for any $(x \ltype B) \in \Gamma$, there is $occurs(x, m) = 1$.
\end{theorem}

\subsubsection{Promotion and Dereliction}
Linear types of CLC are not obtained through packing and unpacking !, so there are no explicit rules for \textit{promotion} and \textit{dereliction} of Linear Logic. Arbitrary computations existing at the type level also muddle the association between which types can be promoted or derelicted to which. Nevertheless, \textit{promotion} and \textit{dereliction} for canonical types are derivable as theorems through $\eta$-expansion.

\begin{theorem}
  Promotion. If $\Gamma \vdash m : (x \stype{s} A) \multimap B$ and $\pure{\Gamma}$ are valid judgments, then there exists $n$ such that $\Gamma \vdash n : (x \stype{s} A) \rightarrow B$ is derivable.
\end{theorem}

\begin{theorem}
  Dereliction. If $\Gamma \vdash m : (x \stype{s} A) \rightarrow B$ is a valid judgment, then there exists $n$ such that $\Gamma \vdash n : (x \stype{s} A) \multimap B$ is derivable.
\end{theorem}

\subsubsection{Strong Normalization}
The strong normalization theorem of CLC is proven by construction of a typing and reduction preserving erasure function from CLC to CC$\omega$. We assume familiarity with CC$\omega$ syntax here and define the erasure function as follows.

\begin{definition}
  \begin{align*}
    \erase{x}                             & = x                                     \\
    \erase{U_i}                           & = Type_i                                \\
    \erase{L_i}                           & = Type_i                                \\
    \erase{(x \stype{s} A) \rightarrow B} & = (x : \erase{A}) \rightarrow \erase{B} \\
    \erase{(x \stype{s} A) \multimap B}   & = (x : \erase{A}) \rightarrow \erase{B} \\
    \erase{\lambda x\stype{s}A.n}         & = \lambda x : \erase{A}.\erase{n}       \\
    \erase{m\ n}                          & = \erase{m}\ \erase{n}
  \end{align*}
\end{definition}

With slight overloading of notation we define erasure for CLC contexts recursively.

\begin{definition}
  \begin{align*}
    \erase{\epsilon}              & = \epsilon                      \\
    \erase{\Gamma, x \stype{s} A} & = \erase{\Gamma}, x : \erase{A}
  \end{align*}
\end{definition}

For the following theorems, we refer to the reductions in CLC as $\step_{\scriptscriptstyle \text{CLC}}$, and the reductions in CC$\omega$ as $\step_{\scriptscriptstyle \text{CC$\omega$}}$.

\begin{theorem} \label{preserve}
  Reduction Erasure. For any CLC terms $m$ and $n$, if there is $m \step_{\scriptscriptstyle \text{CLC}} n$, then there is $\erase{m} \step_{\scriptscriptstyle \text{CC$\omega$}} \erase{n}$.
\end{theorem}

\begin{theorem} \label{embedding}
  Embedding. If $\Gamma \vdash m \stype{s} A$ is a valid judgment in CLC, then $\erase{\Gamma} \vdash \erase{m} : \erase{A}$ is a valid judgment in CC$\omega$.
\end{theorem}

If there exists some well-typed CLC term with an infinite sequence of reductions, erasure will embed this term into a well typed CC$\omega$ term along with its infinite sequence of reductions by virtue of theorems \ref{preserve} and \ref{embedding}. This is contradictory to the strong normalization property of CC$\omega$ proven through the Girard-Tait method \cite{ecc}, so this hypothetical term does not exist in CLC.

\begin{theorem}
  Well-typed CLC terms are strongly normalizing.
\end{theorem}

\subsubsection{Compatibility}
To show that CLC is compatible with the predicative CC$\omega$, we construct a function that annotates CC$\omega$ terms with sort $U$, lifting them into the non-linear fragment of CLC.

\begin{definition}
  \begin{align*}
    \lift{x}                     & = x                                        \\
    \lift{Type_i}                & = U_i                                      \\
    \lift{(x : A) \rightarrow B} & = (x \utype \lift{A}) \rightarrow \lift{B} \\
    \lift{\lambda x : A.n}       & = \lambda x\utype\lift{A}.\lift{n}         \\
    \lift{m\ n}                  & = \lift{m}\ \lift{n}
  \end{align*}
\end{definition}

With slight overloading of notation, we define lifting for CC$\omega$ recursively.
\begin{definition}
  \begin{align*}
    \lift{\epsilon}      & = \epsilon                         \\
    \lift{\Gamma, x : A} & = \lift{\Gamma}, x \utype \lift{A}
  \end{align*}
\end{definition}

The following theorems are proved following a similar procedure to proving the soundness of erasure.
\begin{theorem}
  Lift preserves reduction. For any CC$\omega$ term $m$ and $n$, if there is $m \step_{\scriptscriptstyle \text{CC}\omega} n$, then there is $\lift{m} \step_{\scriptscriptstyle \text{CLC}} \lift{n}$.
\end{theorem}

\begin{theorem} \label{lift}
  Lifting. If $\Gamma \vdash m : A$ is a valid judgment in CC$\omega$, then $\lift{\Gamma} \vdash \lift{m} : \lift{A}$ is a valid judgment in CLC.
\end{theorem}

The lifting theorem shows that all valid CC$\omega$ terms are valid CLC terms if the domains of function types are annotated with sort $U$. In practice, these annotations can often be omitted if algorithmic type checking is able to infer them from context.

\section{The Extension to CILC}
Although the core CLC language is extremely expressive, formally shown by Theorem \ref{lift} to be at least as expressive as the predicative CC$\omega$, the complexity of Church-style encodings to do so will quickly become unmanageable. To address this, we extend CLC with rules for defining inductive linear types in the style of CIC.

We have formalized CILC in our Coq development and proven its soundness.

\subsection{Syntax of CILC}
\begin{figure}[h]
  \caption{Syntax}
  \begin{grammar}
    <$C,I,P,Q,f$> ::= ... \hspace*{10em} expressions
    \indalt $\ind{s}(X : A)\{C_1 \sep ... \sep C_k\}$
    \indalt $\constr(k, I)$
    \indalt $\case(m, Q)\{f_1 \sep ... \sep f_k \}$
    \indalt $\dcase(m, Q)\{f_1 \sep ... \sep f_k \}$
    \indalt $\fix f : A := m$
  \end{grammar}
  \Description{}
  \label{syntax2}
\end{figure}

As shown in Figure \ref{syntax2}, CILC extends CIC with syntax for the introduction and elimination of inductive types. Ind is used during the formation of new inductive types, and Constr is used for introducing their constructors. Case and DCase are non-dependent and dependent case eliminators respectively. CIC-style primitive recursion has been factored out of case eliminators in favor of a Coq-style Fix construct. The flexibility of an independent Fix construct allows for a cleaner formalization of inductive linear type elimination.

\subsection{Arity}
For type $A$ and sort $s$, the judgment $arity(A, s)$ is inductively defined over the structure of $A$ as depicted in Figure \ref{arity}.

\begin{figure}[h]
  \caption{Arity}
  \begin{mathpar}
    \inferrule
    { }
    { arity(s_i,s) }
    \rname{A-Sort}

    \inferrule
    { arity(A, s) }
    { arity((x \utype M) \rightarrow A, s)}
    \rname{A$\rightarrow$}
  \end{mathpar}
  \Description{}
  \label{arity}
\end{figure}

\begin{definition}
  For some arity type $A$ and sort $s'$, the term $A\lrangle{s'}$ is inductively defined over the structure of $A$ as follows.
  \begin{align*}
    ((x \utype M) \rightarrow A)\lrangle{s'} & = (x \utype M) \rightarrow A\lrangle{s'} \\
    (s)\lrangle{s'}                          & = s'
  \end{align*}
\end{definition}

\begin{definition}
  For some arity type $A$, term $I$ and sort $s'$, the term $A\{I, s'\}$ is inductively defined over the structure of $A$ as follows.
  \begin{align*}
    ((x \utype M) \rightarrow A)\lrangle{I, s'} & = (x \utype M) \rightarrow A\lrangle{(I\ x), s'} \\
    (s)\lrangle{I, s'}                          & = (\_ \utype I) \rightarrow s'
  \end{align*}
\end{definition}

\subsection{Strict Positivity}
For type $P$ and variable $X$, the judgment $postive(P, X)$ is inductively defined over the structure of $P$ as depicted in Figure \ref{positive}.

We say that $X$ occurs strictly positive in $P$ if the judgment $postive(P,X)$ is valid.

\begin{figure}[h]
  \caption{Strict Positivity}
  \begin{mathpar}
    \inferrule
    { (\forall i = 1...k) \\ X \notin m_i }
    { positive((X\ m_1...m_k), X) }
    \rname{Pos-X}

    \inferrule
    { X \notin M \\ positive(P, X)}
    { positive((x \stype{s} M) \rightarrow P, X) }
    \rname{Pos$\rightarrow$}

    \inferrule
    { X \notin M \\ positive(P, X) }
    { positive((x \stype{s} M) \multimap P, X) }
    \rname{Pos$\multimap$}
  \end{mathpar}
  \Description{}
  \label{positive}
\end{figure}

\subsection{Non-Linear Constructor}
For type $C$ and variable $X$, the judgment $\ucons(C, X)$ is inductively defined over the structure of $C$ as shown in Figure \ref{nlconstr}.

Non-linear constructors are used for constructing non-linear objects that may be freely used. These constructors may not be applied to restricted terms as this may cause duplication.

\begin{figure}[h]
  \caption{Non-linear Constructor}
  \begin{mathpar}
    \inferrule
    { (\forall i = 1...k) \\ X \notin m_i }
    { \ucons((X\ m_i...m_k), X) }
    \rname{U-Constr-X}

    \inferrule
    { positive(P, X) \\ \ucons(C, X) }
    { \ucons((\_ \utype P) \rightarrow C, X)}
    \rname{U-Constr-pos}

    \inferrule
    { X \notin M \\ \ucons(C, X) }
    { \ucons((x \utype M) \rightarrow C, X)}
    \rname{U-Constr$\rightarrow$}
  \end{mathpar}
  \Description{}
  \label{nlconstr}
\end{figure}

\subsection{Linear Constructor}
For type $C$ and variable $X$, the judgment $\lcons(C, X)$ is inductively defined over the structure of $C$ as shown in Figure \ref{lconstr}.

Linear constructors are used for constructing linear objects that must be used once. These constructors may be applied to linear terms as restricted usage prevents duplication and enforces single usage.

An unapplied linear constructor is a non-linear entity as they can be created freely ``out of thin air". However, once a linear constructor has been partially applied to a linear term, its linearity is ``activated'' in rules \rname{L-Constr-Pos-2} and \rname{L-Constr-2$\rightarrow$}, essentially forcing the rest of its arguments to be fully applied. This is to prevent partially applied constructors from duplicating its linear arguments.

\begin{figure}[h]
  \caption{Linear Constructor}
  \begin{mathpar}
    \inferrule
    { (\forall i = 1...k) \\ X \notin m_i }
    { \lcons((X\ m_i...m_k), X) }
    \rname{L-Constr-X}

    \inferrule
    { positive(P, X) \\ \lcons(C, X) }
    { \lcons((\_ \utype P) \rightarrow C, X)}
    \rname{L-Constr-Pos-1}

    \inferrule
    { X \notin M \\ \lcons(C, X) }
    { \lcons((x \utype M) \rightarrow C, X)}
    \rname{L-Constr-1$\rightarrow$}

    \inferrule
    { positive(P, X) \\ activation(C, X) }
    { \lcons((\_ \ltype P) \rightarrow C, X)}
    \rname{L-Constr-Pos-2}

    \inferrule
    { X \notin M \\ activation(C, X) }
    { \lcons((x \ltype M) \rightarrow C, X)}
    \rname{L-Constr-2$\rightarrow$}
  \end{mathpar}
  \Description{}
  \label{lconstr}
\end{figure}

For type $C$ and variable $X$, the judgment $activation(C, X)$ is inductively defined over the structure of $C$ as shown in Figure \ref{activation}. Intuitively, $activation(C,X)$ ensures the linearity of $C$.

\begin{figure}[h]
  \caption{Activation}
  \begin{mathpar}
    \inferrule
    { (\forall i = 1...k) \\ X \notin m_i }
    { activation((X\ m_i...m_k), X) }
    \rname{Act-X}

    \inferrule
    { positive(P, X) \\ activation(C, X) }
    { activation((\_ \stype P) \multimap C, X)}
    \rname{Act-Pos}

    \inferrule
    { X \notin M \\ activation(C, X) }
    { activation((x \stype M) \multimap C, X)}
    \rname{Act$\multimap$}
  \end{mathpar}
  \Description{}
  \label{activation}
\end{figure}

\subsection{Introduction Rules}
The formation of new inductive types and their constructors are presented in Figure \ref{ind}.

\begin{figure}[h]
  \caption{Inductive Type Formation}
  \begin{mathpar}
    \inferrule
    { (\forall j = 1...n) \\ arity(A, s) \\ \scons(C_j, X) \\\\
      \pure{\Gamma} \\
      \Gamma \vdash A : U_i \\
      \Gamma, X \utype A \vdash C_j : t_i }
    { \Gamma \vdash \ind{s}(X : A)\{C_1|...|C_k\} : A }
    \rname{Ind}

    \inferrule
    { 1 \leq i \leq k \\\\
    \pure{\Gamma} \\
    I := \ind{s}(X : A)\{C_1|...|C_k\} \\
    \Gamma \vdash I :A }
    { \Gamma \vdash \constr(i, I) : C_i[I/X] }
    \rname{Constr}
  \end{mathpar}
  \Description{}
  \label{ind}
\end{figure}

\subsection{Non-Dependent Case}

\begin{definition}
  For constructor type $C$ and variables $X$ and $Q$, the term $C\{X, Q\}$ is inductively defined over the structure of $C$ as follows.
  \begin{align*}
    ((\_ \stype{s} P) \rightarrow C)\{X, Q\} & = (\_ \stype{s} P) \multimap C\{X, Q\} \\
    ((\_ \stype{s} P) \multimap C)\{X, Q\}   & = (\_ \stype{s} P) \multimap C\{X, Q\} \\
    ((x \stype{s} M) \rightarrow C)\{X, Q\}  & = (x \stype{s} P) \multimap C\{X, Q\}  \\
    ((x \stype{s} M) \multimap C)\{X, Q\}    & = (x \stype{s} P) \multimap C\{X, Q\}  \\
    (X\ m_1...m_k)\{X, Q\}                   & = (Q\ m_1...m_k)
  \end{align*}
  We define the notation $C[I, P] := C\{X, Q\}[I/X, P/Q]$.
\end{definition}

The rule for non-dependent case elimination is presented in Figure \ref{case}. This elimination rule is non-dependent because the motive $Q$ may not depend on the discriminated term $m$ itself.

\begin{figure}[h]
  \caption{Non-dependent Case Elimination}
  \begin{mathpar}
    \inferrule
    { (\forall i = 1...k_1) \\
    \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
    arity(A, s) \\\\
    I := \ind{s}(X : A)\{C_1|...|C_{k_1}\} \\
    \overline{\Gamma_2} \vdash Q : A\lrangle{s'} \\\\
    \Gamma_1 \vdash m : (I\ a_1...a_{k_2}) \\
    \Gamma_2 \vdash f_i : C_i[I, Q] }
    { \Gamma \vdash \case(m, Q)\{f_1|...|f_{k_1}\} : (Q\ a_1...a_{k_2}) }
    \rname{Case}
  \end{mathpar}
  \Description{}
  \label{case}
\end{figure}

\subsection{Dependent Case}

\begin{definition}
  For some non-linear constructor type $C$ and type variables $X$, $Q$ and $c$, the term $C\{X, Q, c\}$ is inductively defined over the structure of $C$ as follows.
  \begin{align*}
    ((\_ \utype P) \rightarrow C)\{X, Q, c\} & = (p \utype P) \multimap C\{X, Q, (c\ p)\} \\
    ((x \utype M) \rightarrow C)\{X, Q, c\}  & = (x \utype M) \multimap C\{X, Q, (c\ x)\} \\
    (X\ m_1...m_n)\{X, Q, c\}                & = (Q\ m_1...m_n\ c)
  \end{align*}
  We define the notation $C[I, P, t] := C\{X, Q, c\}[I/X, P/Q, t/c]$.
\end{definition}

Dependent elimination of non-linear inductive objects is presented in Figure \ref{dcase}. This elimination rule is dependent because the motive $Q$ may depend on the discriminated term $m$. For this very reason, $m$ is not allowed to have linear type as doing so may transport restricted variable into types.

\begin{figure}[h]
  \caption{Dependent Case Elimination}
  \begin{mathpar}
    \inferrule
    { \pure{\Gamma_1} \\
    (\forall i = 1...n) \\
    \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
    arity(A, U_i) \\\\
    I := \ind{U}(X : A)\{C_1|...|C_n\} \\
    \overline{\Gamma_2} \vdash Q : A\lrangle{I, s'} \\\\
    \Gamma_1 \vdash m : (I\ a_1...a_n) \\
    \Gamma_2 \vdash f_i : C_i[I, Q, Constr(i, I)] }
    { \Gamma \vdash \dcase(m, Q)\{f_1|...|f_n\} : (Q\ a_1...a_n\ m) }
    \rname{DCase}
  \end{mathpar}
  \Description{}
  \label{dcase}
\end{figure}

\subsection{Fixpoint}
The typing rule of fix-points presented in Figure \ref{fix} is mostly standard. A syntactic guard condition is utilized to conservatively ensure termination. The fix-point term must have non-linear type in a pure context, because recursive calls may cause duplicated usage of restricted variables.

\begin{figure}[h]
  \caption{Fixpoint}
  \begin{mathpar}
    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : U_i \\
      \Gamma, f \utype A \vdash m : A \\
      \text{guard condition} }
    { \Gamma \vdash \fix f : A := m : A }
    \rname{fix}
  \end{mathpar}
  \Description{}
  \label{fix}
\end{figure}

\subsection{Extended Reduction}
As the reduction semantics for the extended language is standard \cite{cic}, we only present the most interesting $\iota$-reduction cases.

\begin{figure}[h]
  \caption{$\iota$-Reductions}
  \begin{mathpar}
    \inferrule
    { }
    { \case((\constr(i, I)\ a_1...a_n),Q)\{f_1|...f_k\} \\\\
      \leadsto (f_i\ a_1...a_k) }
    \rname{Step-Case-$\iota$}

    \inferrule
    { }
    { \dcase((\constr(i, I)\ a_1...a_k),Q)\{f_1|...f_k\} \\\\
      \leadsto (f_i\ a_1...a_k) }
    \rname{Step-DCase-$\iota$}

    \inferrule
    { }
    { \fix f : A := m \leadsto m[(\fix f : A := m)/f] }
    \rname{Step-Fix-$\iota$}
  \end{mathpar}
  \Description{}
  \label{stepfix}
\end{figure}

\subsection{Non-Linear Connectives}
Non-linear inductive types have been extensively studied since their inception. We will omit discussion of non-linear inductive types here as all inductive definitions in the predicative fragment of CIC are available in CILC.

\subsection{Linear Connectives}
In Figure \ref{lconnectives}, we demonstrate how the $\otimes$ and $\oplus$ connectives of linear logic could be defined in CILC as inductive linear types. For any term with inductive linear type, linearity will ultimately force the term to be eliminated by a Case expression.

\begin{figure}[h]
  \caption{Inductively Defined Linear Connectives}
  \begin{align*}
    \_\otimes\_ :=\
     & \ind{L}(X : (A \utype L_i) \rightarrow (B \utype L_i) \rightarrow L_i)\{      \\
     & \sep\ (A \utype L_i) \rightarrow (B \utype L_i)                               \\
     & \qquad \rightarrow (\_ \ltype A)  \multimap (\_ \ltype B) \multimap (X\ A\ B) \\
     & \}
    \\
    \lrangle{\_,\_} := \
     & \constr(1, \otimes)
    \\\\
    \_\oplus\_ := \
     & \ind{L}(X : (A \utype L_i) \rightarrow (B \utype L_i) \rightarrow L_i)\{      \\
     & \sep \ (A \utype L_i) \rightarrow (B \utype L_i)
    \rightarrow (\_ \ltype A)  \multimap (X\ A\ B)                                   \\
     & \sep \ (A \utype L_i) \rightarrow (B \utype L_i)
    \rightarrow (\_ \ltype B)  \multimap (X\ A\ B)                                   \\
     & \}
    \\
    \inl(\_) := \
     & \constr(1, \oplus)
    \\
    \inr(\_) := \
     & \constr(2, \oplus)
  \end{align*}
  \Description{}
  \label{lconnectives}
\end{figure}

\subsection{Mixed Connectives}
In Figure \ref{mconnectives}, we introduce a $\SigmaL$ connective. $\SigmaL$ is similar to the standard $\Sigma$ type where the type of the second component is dependent on the value of the first component. The key difference between these two type constructors is that $\Sigma$'s second component is non-linear, whereas $\SigmaL$'s second component is linear.

\begin{figure}[h]
  \caption{Mixed Connective}
  \begin{align*}
    \SigmaL := \
     & \ind{L}(X : (A \utype U_i) \rightarrow
    (B \utype (\_ \utype A) \rightarrow L_i) \rightarrow L_i)\{ \\
     & \sep \ (A \utype U_i) \rightarrow
    (B \utype (\_ \utype A) \rightarrow L_i)                    \\
     & \qquad \rightarrow (m \utype A) \rightarrow
    (\_ \ltype B\ m) \multimap (X\ A\ B)                        \\
     & \}
    \\
    [\_,\_] :=\
     & \constr(1, \SigmaL)
  \end{align*}
  \Description{}
  \label{mconnectives}
\end{figure}

\section{Examples}\label{examples}
In this section we will demonstrate some applications of CILC in practice. When it is clear from context whether a type is linear or non-linear, we will omit writing sort annotations on function types. We also use Coq style concrete syntax from our implementation for the sake of readability. The full code for each example is available with our implementation.

\subsection{Stateful Reasoning}
We first postulate five state axioms. These axioms could be viewed as an interface to a trusted memory allocator. Using these axioms, we will build safe random access arrays from the ground up.
\begin{definition}
  State axioms.
  \begin{itemize}
    \item $\mapsto\ : \mathbb{N} \rightarrow (A : U) \rightarrow L$ \\
          The $\mapsto$ is an infix linear type constructor. It fulfills a role similar to L3's \cite{l3} memory access capability, or Separation Logic's \cite{reynolds02} points-to assertion. Intuitively, a capability $(l \mapsto A)$ is a proof that a term of non-linear type $A$ is currently stored at address $l$.
    \item $\textbf{new} : (A : U) \rightarrow A \rightarrow \SigmaL l:\mathbb{N}.(l \mapsto A)$ \\
          $\new$ is a function that allocates a new memory cell for a term non-linear type $A$ and initializes the cell with its argument. This returns an address $l$ paired with a capability $(l \mapsto A)$.
    \item $\textbf{free} : (A : U) \rightarrow (l:\mathbb{N}) \rightarrow (l \mapsto A) \rightarrow \unit$ \\
          $\free$ is a function that de-allocates the memory cell at location $l$ which is currently in use. The capability $(l \mapsto A)$ is consumed so the memory cell can no longer be accessed.
    \item $\textbf{get} : (A : U) \rightarrow (l : \mathbb{N}) \rightarrow (l \mapsto A) \rightarrow \SigmaL \_: A. (l \mapsto A)$ \\
          $\get$ is a function that retrieves the term stored at address $l$ when given a proof $(l \mapsto A)$ there is indeed a term of type $A$ currently stored there. The type of $\get$'s output is the rather complicated $\SigmaL \_: A. (l \mapsto A)$. This not only returns the term stored at $l$, but also a proof $(l \mapsto A)$ that the memory state has not changed and may be accessed again.
    \item $\textbf{set} : (A\ B : U) \rightarrow (l : \mathbb{N}) \rightarrow B \rightarrow (l \mapsto A) \rightarrow (l \mapsto B)$ \\
          $\set$ has the most complicated type of all the axioms presented here. Intuitively, if address $l$ is allocated and storing some term of type $A$, $\set$ may put a term type $B$ into the the store at address $l$, overwriting the original term. This is the so called "strong update" operation. The consumption of $(l \mapsto A)$ and return of $(l \mapsto B)$ accurately characterize this update process.
  \end{itemize}
\end{definition}
Due to the fact that $(l \mapsto A)$ is an abstract linear type, proofs of this type can not be duplicated and may only be consumed by other state axioms. This is the same non-sharing principle that empowers Separation Logic. Unlike Separation Logic, $(l \mapsto A)$ itself is a first-class object in CILC, meaning that it can be the result of computations (large eliminations), input to computations and storage in data structures, etc.

A random access array is a contiguous region of memory that can be accessed by an address pointing to the start of this region and an offset. In Figure \ref{arrv}, we declare a linear inductive $\arrv$ to track the memory used by the array. $\arrv$ is parameterized by the type $A$ of elements stored in the array and the address $l$ of the initial element. $\arrv$ also takes an additional argument of type $\mathbb{N}$ indicating the length of the array.

\begin{figure}[h]
  \caption{Proof of Arrays}
  \begin{minted}[escapeinside=??,mathescape=true]{coq}
Inductive ArrVec (A : U) (l : ?$\mathbb{N}$?) : ?$\mathbb{N}$? ?$\rightarrow$? L :=
| Nil : ArrVec A l 0
| Cons : (n : ?$\mathbb{N}$?) ?$\rightarrow$? ((l + n) ?$\mapsto$? A) ?$\rightarrow$? 
    ArrVec A l n ?$\rightarrow$? ArrVec A l (S n).
  \end{minted}
  \label{arrv}
  \Description{}
\end{figure}

Notice that for the $\texttt{Cons}$ constructor, each time a proof of $(l + n \mapsto A)$ is used to extend the current $\arrv$, the next application of $\texttt{Cons}$ expects a proof of $(l + S\ n \mapsto A)$. So for some type $A$ and natural numbers $l, n$, a term of type $\arrv\ A\ l\ n$ is a proof that a contiguous region of memory starting from address $l$ can be accessed by any offset less than $n$. Arrays can now be characterized as an address $l$ paired with an array proof $\arrv\ A\ l\ n$ as shown in Figure \ref{array}.

\begin{figure}[h]
  \caption{Arrays}
  \begin{minted}[escapeinside=??,mathescape=true]{coq}
Definition Array (A : U) (n : ?$\mathbb{N}$?) : L := 
  ?$\SigmaL$? l : ?$\mathbb{N}$?.ArrVec A l n.
  \end{minted}
  \label{array}
  \Description{}
\end{figure}

To manipulate arrays, we construct a recursive helper function whose signature is shown in Figure \ref{trav}. When given an array proof $\arrv\ A\ l\ n$, an offset $m$ and proof $pf$ such that $m < n$, $\texttt{nth}$ will return a capability $(l + m \mapsto A)$ along with a function $(l + m \mapsto A) \multimap \arrv\ A\ l\ n$. The capability $(l + m \mapsto A)$ grants the ability to manipulate the store at offset $m$ using the state axioms. The function $(l + m \mapsto A) \multimap \arrv\ A\ l\ n$ is constructed using the rest of the capabilities in $\arrv\ A\ l\ n$ that are not at offset $m$. Intuitively, $(l + m \mapsto A) \multimap \arrv\ A\ l\ n$ is the original array proof with a missing capability at offset $m$ which can be restored by applying capability $(l + m \mapsto A)$.

\begin{figure}[H]
  \caption{ArrVec Traversal}
  \begin{minted}[escapeinside=??,mathescape=true]{coq}
Fixpoint nth 
  (A : U) 
  (l m n : ?$\mathbb{N}$?) 
  (pf : m < n) 
  (v : ArrVec A l n) 
: (l + m ?$\mapsto$? A) ?$\otimes$? ((l + m ?$\mapsto$? A) ?$\multimap$? ArrVec A l n).
  \end{minted}
  \label{trav}
  \Description{}
\end{figure}

An indexing function can now be constructed as a wrapper for $\texttt{nth}$ with its signature shown in Figure \ref{index}. Given an array $\texttt{Array}\ A\ n$, an offset $m$ and proof that $m < n$, $\texttt{nth}$ can be used to extract the capability at offset $m$, allowing $\get$ to retrieve the stored value. Finally, the array proof is restored and returned alongside the indexing result. This definition of $\texttt{index}$ is safe because the proof $m < n$ ensures that offsets used for indexing are always within bounds.

\begin{figure}[h]
  \caption{Array Indexing}
  \begin{minted}[escapeinside=??,mathescape=true]{coq}
Definition index
  (A : U)
  (m n : ?$\mathbb{N}$?)
  (pf : m < n)
  (a : Array A n) 
: ?$\SigmaL$? _ : A. Array A n.
  \end{minted}
  \label{index}
  \Description{}
\end{figure}

From our experiments with proof erasure, we observe that erasing the proof arguments of $\texttt{index}$ in a reasonable way can result in a single call to $\get$. This indicates that the arrays described here can be compiled for constant time access.

\subsection{Protocol Enforcement}
The inclusion of dependent types and linear types in CILC makes it extremely expressive when encoding communication protocols. By indexing each channel with a protocol, CILC can enforce communication on a channel to strictly adhere to its specified protocol.

In Figure \ref{session}, we declare an inductive \texttt{session} type for specifying protocols. Intuitively, the \texttt{session}  forms a stack of possible operations executed in a protocol. The $\SEND$ constructor takes in a non-linear type $A$ and a session $ss$ as its argument, indicating that after sending a message of type $A$, the protocol progresses to stage $ss$. Likewise, the $\RECV$ constructor takes in a non-linear type $A$ and a session $ss$ as its argument, indicating that after receiving a message of type $A$, the protocol progresses to stage $ss$. Finally, the $\END$ constructor indicates that the protocol has finished and communication is over.

\begin{figure}[h]
  \caption{Inductive Session Type}
  \begin{minted}[escapeinside=??,mathescape=true]{coq}
Inductive session : U :=
| SEND : U ?$\rightarrow$? session ?$\rightarrow$? session
| RECV : U ?$\rightarrow$? session ?$\rightarrow$? session
| END : session.
  \end{minted}
  \label{session}
  \Description{}
\end{figure}

In Definition \ref{comm}, we postulate five axioms for communication using the $\session$ type. These axioms could be viewed as an interface to trusted communication libraries.

\begin{definition}
  Communication axioms.
  \begin{itemize}
    \item $\textbf{channel} : \session \rightarrow L$ \\
          The $\channel$ axiom is a type constructor. It is used to form the types of communication channels that obey the protocol specified by its session.
    \item $\textbf{open} : (ss : \session) \rightarrow \channel\ ss$ \\
          When given a protocol, $\open$ creates a channel indexed by this protocol.
    \item $\textbf{close} : \channel\ \END \rightarrow \unit$ \\
          Once all communications specified on a given channel have finished, $\close$ will close and reclaim the channel.
    \item $\textbf{send} : (A : U) \rightarrow A \rightarrow (ss : \session) \rightarrow$ \\
          \phantom{send : (A :)}
          $\channel\ (\SEND\ A\ ss) \rightarrow \channel\ ss$ \\
          After a channel has reached the point in its protocol where a message of type $A$ should be sent, $\send$ may send a term of type $A$ on this channel, causing the channel to progress to the next stage of its protocol.
    \item $\textbf{recv} : (A : U) \rightarrow (ss : \session) \rightarrow $ \\
          \phantom{recv : (A :)}
          $\channel\ (\RECV\ A\ ss) \rightarrow F \_:A.\channel\ ss$
          After a channel has reached the point in its protocol where a message of type $A$ should be received, $\recv$ may receive such a term of type $A$ from the channel, causing the channel to progress to the next stage of its protocol.
  \end{itemize}
  \label{comm}
\end{definition}

The important detail to notice here is that each channel created by $\open$ is of linear type $(\channel\ ss)$ where $ss$ is some arbitrary protocol, hence must be used exactly once. However, the $\send$ and $\recv$ operations return channels after consuming them, progressing their protocols one stage forward. Coupled with the fact that the $\close$ operation is only able to close channels whose protocols have ended, this forces channels to communicate strictly by their specified protocols.

\subsection{Mutable Data}
Figure \ref{list} presents a CPS append function for linear lists. In the \texttt{cons} case, the constructor is opened, exposing its data element \texttt{h} and tail list \texttt{t}. Instead of de-allocating the memory of \texttt{cons}, it is bound to the variable \texttt{_cons_} of linear type $A \multimap list\ A \multimap list\ A$. Each \texttt{_cons_} is applied exactly once to reconstruct a list using the memory of the original, thus mutating the original list in-place. Also notice that the continuation $k$ is of linear type $(list\ A \multimap list\ A)$, indicating that $k$ must be applied exactly once. Using linear types for continuations is surprisingly accurate as control-flow itself cannot be freely duplicated nor discarded.

\begin{figure}[h]
  \caption{Linear Lists}
  \begin{minted}[escapeinside=??,mathescape=true]{coq}
Inductive list (A : U) : L :=
| nil : list A
| cons : A ?$\rightarrow$? list A ?$\rightarrow$? list A.

Fixpoint append (A : U) : list A ?$\multimap$? 
  list A ?$\multimap$? (list A ?$\multimap$? list A) ?$\multimap$? list A 
:=
  fun ls1 ls2 k ?$\Rightarrow$?
    match ls1 with
    | nil ?$\Rightarrow$? k ls2
    | (cons h t) as _cons_ ?$\Rightarrow$?
      append _ t ls2 
        (fun res ?$\Rightarrow$? k (_cons_ h res))
    end.
  \end{minted}
  \label{list}
  \Description{}
\end{figure}

\section{Related Work}
Linear types are a class of type systems inspired by Girard's substructural Linear Logic \cite{girard}. Girard notices that the weakening and contraction rules of Classical Logic when restricted carefully, give rise to a new logical foundation for reasoning about resource. Wadler \cite{wadler1990,wadler1991} then applies an analogous restriction to variable usage in simple type theory, leading to the development of linear type theory where terms respect resource. A term calculus for linear type theory is realized by Abramsky \cite{abramsky1993}. Benton \cite{benton1994} investigates the ramifications of the ! exponential in linear term calculi, decomposing it to adjoint connectives $F$ and $G$ that map between linear and non-linear judgments. Programming languages \cite{l3,ats,linear-haskell} featuring linear types have also been implemented, allowing programmers to write resource safe software in practical applications.

Over the years, work has been done to enrich linear type theories with dependent types. Cervesato and Pfenning extend the Edinburgh Logical Framework with linear types \cite{lf,llf}, being the first to demonstrate that dependent types and linear types can coexist within a type theory. V\'{a}k\'{a}r \cite{vakar14} presents a linear dependent type theory, with syntax and semantics drawing inspiration from DILL \cite{dill}.  Krishnaswami et al. present a dependent linear type theory \cite{neel15} based on Benton's earlier work on mixed linear and non-linear calculus, demonstrating the ability to internalize imperative programming in the style of Hoare Type Theory \cite{htt}. Luo et al. \cite{luo} introduce the property of essential linearity and a mixed linear/non-linear context, describing the first type theory that allows types to depend on linear terms. Based on initial ideas of McBride \cite{nothing}, Atkey's Quantitative Type Theory (QTT) \cite{qtt} uses semi-ring annotations to track variable occurrence, simulating irrelevance and linear and affine types within a unified framework. The Idris 2 programming language \cite{idris2} implements QTT as its core type system.

\section{Future Work}
In early versions of CLC, an impredicative $Prop$ universe sat at the bottom of the universe hierarchy. This has since been removed due to the additional difficulty of working with $Prop$ in the soundness proof of CILC. We believe that these difficulties are not intrinsic and $Prop$ could be added back with careful proof work.

We aim to fully verify the typechecking algorithm employed by the current implementation. The unification algorithm used for implicit argument resolution is extremely ad-hoc. As the problem of unification for linear types has not been thoroughly studied, we hope to improve this situation as well.

\bibliographystyle{acm}
\bibliography{../ref}

\clearpage
\appendix
\appendixname

\section{Syntax of CLC}
\begin{figure}[H]
  \begin{grammar}
    <$i$> ::= 0 | 1 | 2 ... \phantom{* |} \hspace*{2.4em} universe levels

    <$s, t$> ::= $U$ | $L$ \phantom{| $x$} \hspace*{4.6em} sorts

    <$m, n, A, B, M$> ::= $U_i$ | $L_i$ | $x$ \hspace*{4em} expressions
    \indalt $(x :_s A) \rightarrow B$
    \indalt $(x :_s A) \multimap B$
    \indalt $\lambda x :_s A. n$
    \indalt $m\ n$
  \end{grammar}
  \Description{}
\end{figure}

\section{Reduction and Equality of CLC}
\begin{figure}[H]
  \begin{mathpar}
    \inferrule
    { m_1 \red n \\ m_2 \red n }
    { m_1 \equiv m_2 : A }
    \rname{Join}

    \inferrule
    {  }
    { (\lambda x \stype{s}A.m)\ n \step m[n/x] }
    \rname{Step-$\beta$}

    \inferrule
    { A \step A' }
    { \lambda x \stype{s}A.m \step \lambda x \stype{s}A' .m }
    \rname{Step-$\lambda$L}

    \inferrule
    { m \step m' }
    { \lambda x \stype{s}A.m \step \lambda x \stype{s}A.m' }
    \rname{Step-$\lambda$R}

    \inferrule
    { A \step A' }
    { (x \stype{s} A) \rightarrow B \step (x \stype{s} A') \rightarrow B }
    \rname{Step-L$\rightarrow$}

    \inferrule
    { B \step B' }
    { (x \stype{s} A) \rightarrow B \step (x \stype{s} A) \rightarrow B' }
    \rname{Step-R$\rightarrow$}

    \inferrule
    { A \step A' }
    { (x \stype{s} A) \multimap B \step (x \stype{s} A') \multimap B }
    \rname{Step-L$\multimap$}

    \inferrule
    { B \step B' }
    { (x \stype{s} A) \multimap B \step (x \stype{s} A) \multimap B' }
    \rname{Step-R$\multimap$}

    \inferrule
    { m \step m' }
    { m\ n \step m'\ n }
    \rname{Step-AppL}

    \inferrule
    { n \step n' }
    { m\ n \step m\ n' }
    \rname{Step-AppR}
  \end{mathpar}
  \Description{}
\end{figure}

\section{Confluence of CLC}

\subsection{Parallel Reduction}
To prove the confluence property of CLC, we employ the standard technique utilizing parallel reductions.

\begin{figure}[H]
  \begin{mathpar}
    \inferrule
    { }
    { x \pstep x }
    \rname{PStep-Var}

    \inferrule
    { }
    { s_i \pstep s_i }
    \rname{PStep-Sort}

    \inferrule
    { A \pstep A' \\ m \pstep m' }
    { \lambda x \stype{s} A.m \pstep \lambda x \stype{s} A'.m' }
    \rname{PStep-$\lambda$}

    \inferrule
    { m \pstep m' \\ n \pstep n' }
    { m\ n \pstep m'\ n' }
    \rname{PStep-App}

    \inferrule
    { m \pstep m' \\ n \pstep n'}
    { (\lambda x \stype{s} A.m)\ n \pstep m'[n'/x] }
    \rname{PStep-$\beta$}

    \inferrule
    { A \pstep A' \\ B \pstep B' }
    { (x \stype{s} A) \rightarrow B \pstep (x \stype{s} A') \rightarrow B' }
    \rname{PStep$\rightarrow$}

    \inferrule
    { A \pstep A' \\ B \pstep B' }
    { (x \stype{s} A) \multimap B \pstep (x \stype{s} A') \multimap B' }
    \rname{PStep$\multimap$}
  \end{mathpar}
  \label{pred}
  \Description{}
\end{figure}

\subsection{Reduction Lemmas}
Here, we prove some simple lemmas concerning $\step$, $\red$ and substitution.

\begin{definition}
  For a term $m$ and a map $\sigma$ from variables to terms, let $m[\sigma]$ be the term obtained by applying $\sigma$ uniformly to all free variables in $m$.
\end{definition}

\begin{definition}
  For maps $\sigma, \tau$ from variables to terms, we say that $\sigma$ reduces to $\tau$ if for any variable $x$ there exists a reduction $(\sigma\ x) \red (\tau\ x)$. We write $\sigma \red \tau$ when it is clear from context that $\sigma, \tau$ are maps and not terms.
\end{definition}

\begin{lemma}\label{stepsubst}
  For terms $m, n$ and a map $\sigma$ from variables to terms, if there exist a step $m \step n$, then there exists a step $m[\sigma] \step n[\sigma]$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \step n$.
\end{proof}

\begin{lemma}\label{redapp}
  For terms $m_1, m_2, n_1, n_2$, if these exists reductions $m_1 \red m_2$ and $n_1 \red n_2$, then there exists reduction $(m_1\ n_1) \red (m_2\ n_2)$.
\end{lemma}
\begin{proof}
  By transitivity of $\red$ and applying rules \rname{Step-AppL}, \rname{Step-AppR}.
\end{proof}

\begin{lemma}\label{redlam}
  For terms $A_1, A_2, m_1, m_2$ and sort $s$, if there exists reductions $A_1 \red A_2$ and $m_1 \red m_2$, then there exists reduction $\lambda x \stype{s}A_1.m_1 \red \lambda x \stype{s}A_2.m_2$.
\end{lemma}
\begin{proof}
  By transitivity of $\red$ and applying rules \rname{Step-$\lambda$L}, \rname{Step-$\lambda$R}.
\end{proof}

\begin{lemma}\label{redarrow}
  For terms $A_1, A_2, B_1, B_2$ and sort $s$, if there exists reductions $A_1 \red A_2$ and $B_1 \red B_2$, then there exists reduction $(x \stype{s}A_1) \rightarrow B_1 \red (x \stype{s} A_2) \rightarrow B_2$.
\end{lemma}
\begin{proof}
  By transitivity of $\red$ and applying rules \rname{Step-L$\rightarrow$}, \rname{Step-R$\rightarrow$}.
\end{proof}

\begin{lemma}\label{redlolli}
  For terms $A_1, A_2, B_1, B_2$ and sort $s$, if there exists reductions $A_1 \red A_2$ and $B_1 \red B_2$, then there exists reduction $(x \stype{s}A_1) \multimap B_1 \red (x \stype{s} A_2) \multimap B_2$.
\end{lemma}
\begin{proof}
  By transitivity of $\red$ and applying rules \rname{Step-L$\multimap$}, \rname{Step-R$\multimap$}.
\end{proof}

\begin{lemma}\label{redsubst}
  For terms $m, n$ and a map $\sigma$ from variables to terms, if there exist a reduction $m \red n$, then there exists a reduction $m[\sigma] \red n[\sigma]$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\red$, the transitivity of $\red$ and Lemma \ref{stepsubst}.
\end{proof}

\begin{lemma}\label{redcompat}
  For maps $\sigma, \tau$ from variables to terms, if there is a map reduction $\sigma \red \tau$, then for any term $m$ these is a reduction $m[\sigma] \red m[\tau]$.
\end{lemma}
\begin{proof}
  By induction on the structure of $m$, applying Lemmas \ref{redapp}, \ref{redlam}, \ref{redarrow}, \ref{redlolli}.
\end{proof}

\subsection{Equality Lemmas}
Here, we prove some simple lemmas concerning $\red$, $\equiv$ and substitution.

\begin{definition}
  For maps $\sigma, \tau$ from variables to terms, we say that $\sigma$ is equal to $\tau$ if for any variable $x$ there exists an equality $(\sigma\ x) \equiv (\tau\ x)$. We write $\sigma \equiv \tau$ when it is clear from context that $\sigma, \tau$ are maps and not terms.
\end{definition}

\begin{lemma}\label{convhom}
  For any map $f$ from terms to terms, if for any terms $m, n$ such that $m \step n$ implies $f\ m \equiv f\ n$, then for any terms $m, n$ equality $m \equiv n$ implies $f\ m \equiv f\ n$.
\end{lemma}
\begin{proof}
  By the properties of the transitive reflexive closure $\red$ and that $\equiv$ is an equivalence relation.
\end{proof}

\begin{lemma}\label{convapp}
  For terms $m_1, m_2, n_1, n_2$, if there exist equalities $m_1 \equiv m_2$ and $n_1 \equiv n_2$, then there exists equality $(m_1\ n_1) \equiv (m_2\ n_2)$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and applying rules \rname{Join}, \rname{Step-AppL}, \rname{Step-AppR}.
\end{proof}

\begin{lemma}\label{convlam}
  For terms $A_1, A_2, m_1, m_2$ and sort $s$, if there exist equalities $A_1 \equiv A_2$ and $m_1 \equiv m_2$, then there exists equality $\lambda x \stype{s} A_1.m_1 \equiv \lambda x \stype{s} A_2.m_2$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and applying rules \rname{Join}, \rname{Step-$\lambda$L}, \rname{Step-$\lambda$R}.
\end{proof}

\begin{lemma}\label{convarrow}
  For terms $A_1, A_2, B_1, B_2$ and sort $s$, if there exist equalities $A_1 \equiv A_2$ and $B_1 \equiv B_2$, then there exists equality $(x \stype{s} A_1) \rightarrow B_1 \equiv (x \stype{s} A_2) \rightarrow B_2$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and applying rules \rname{Join}, \rname{Step-L$\rightarrow$}, \rname{Step-R$\rightarrow$}.
\end{proof}

\begin{lemma}\label{convlolli}
  For terms $A_1, A_2, B_1, B_2$ and sort $s$, if there exist equalities $A_1 \equiv A_2$ and $B_1 \equiv B_2$, then there exists equality $(x \stype{s} A_1) \multimap B_1 \equiv (x \stype{s} A_2) \multimap B_2$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and applying rules \rname{Join}, \rname{Step-L$\multimap$}, \rname{Step-R$\multimap$}.
\end{proof}

\begin{lemma}\label{convsubst}
  For terms $m, n$ and map $\sigma$ from variables to terms, if there is equality $m \equiv n$, then there is equality $m[\sigma] \equiv n[\sigma]$.
\end{lemma}
\begin{proof}
  By Lemmas \ref{convhom} and \ref{stepsubst}.
\end{proof}

\begin{lemma}\label{convcompat}
  For maps $\sigma, \tau$ from variables to terms and term $m$, if these is map equality $\sigma \equiv \tau$, then there is equality $m[\sigma] \equiv m[\tau]$.
\end{lemma}
\begin{proof}
  By induction on the structure of $m$, applying Lemmas \ref{convapp}, \ref{convlam}, \ref{convarrow}, \ref{convlolli}.
\end{proof}

\begin{lemma}
  For terms $m_1, m_2, n$, if there is equality $m_1 \equiv m_2$, then there is equality $n[m_1/x] \equiv n[m_2/x]$ for any variable $x \in FV(n)$.
\end{lemma}
\begin{proof}
  This is a special case of Lemma \ref{convcompat} where $\sigma$ maps $x$ to $m_1$ and $\tau$ maps $x$ to $m_2$.
\end{proof}

\subsection{Parallel Reduction Lemmas}

\begin{definition}\label{psstep}
  For maps $\sigma, \tau$ from variables to terms, we say $\sigma$ parallel reduces to $\tau$ if for any variable $x$ there exists a parallel reduction $(\sigma\ x) \pstep (\tau\ x)$. We write $\sigma \pstep \tau$ when it is clear from context that $\sigma, \tau$ are maps and not terms.
\end{definition}

\begin{lemma}\label{psteprefl}
  For any term $m$, there exists a reflexive parallel reduction $m \pstep m$.
\end{lemma}
\begin{proof}
  By induction on the structure of $m$.
\end{proof}

\begin{lemma}
  For any map $\sigma$ from variables to terms, there exists a reflexive parallel map reduction $\sigma \pstep \sigma$.
\end{lemma}
\begin{proof}
  By Definition \ref{psstep} and Lemma \ref{psteprefl}.
\end{proof}

\begin{lemma}\label{steppstep}
  For any terms $m, n$, if there exists step $m \step n$, then there exists a parallel reduction $m \pstep n$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \step n$ and Lemma \ref{psteprefl}.
\end{proof}

\begin{lemma}\label{pstepred}
  For terms $m, n$, if there exists parallel reduction $m \pstep n$, then there exists a reduction $m \red n$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \pstep n$, utilizing the transitive property of $\red$ and Lemmas \ref{redapp}, \ref{redlam}, \ref{redarrow}, \ref{redlolli}, \ref{redsubst}, \ref{redcompat}.
\end{proof}

\begin{lemma}
  For terms $m, n$ and map $\sigma$ from variables to terms, if there exists parallel reduction $m \pstep n$, there exists parallel reduction $m[\sigma] \pstep n[\sigma]$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \pstep n$ and Lemma \ref{psteprefl}.
\end{proof}

\begin{lemma}\label{pstepcompat}
  For terms $m, n$ and maps $\sigma, \tau$ from variables to terms, if there exist parallel reduction $m \pstep n$ and parallel map reduction $\sigma \pstep \tau$, there exists parallel reduction $m[\sigma] \pstep n[\tau]$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \pstep n$.
\end{proof}

\begin{lemma}
  For terms $m_1, m_2, n$, if there is parallel reduction $m_1 \pstep m_2$, then there is parallel reduction $n[m_1/x] \pstep n[m_2/x]$ for any variable $x \in FV(n)$.
\end{lemma}
\begin{proof}
  By Lemma \ref{psteprefl}, this is a special case of Lemma \ref{pstepcompat} where $\sigma$ maps $x$ to $m_1$ and $\tau$ maps $x$ to $m_2$.
\end{proof}

\subsection{Confluence Theorem}
We first show that $\pstep$ satisfies the diamond property. Using the diamond property, we ultimately prove the confluence theorem.

\begin{lemma}\label{diamond}
  CLC term reduction has the diamond property. For terms $m, m_1, m_2$, if there are parallel reductions $m \pstep m_1$ and $m \pstep m_2$, then there exists term $m'$ such that $m_1 \pstep m'$ and $m_2 \pstep m'$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \pstep m_1$. Each case in the induction specializes $m$ appearing in $m \pstep m_2$, allowing one to invert its derivation in a syntax directed way and then to apply the induction hypothesis. The difficult cases are due to \rname{PStep-$\beta$} as it concerns substitution, so Lemma \ref{pstepcompat} is used to push these cases through.
\end{proof}

\begin{lemma}\label{strip}
  Strip lemma. For terms $m, m_1, m_2$, if there are parallel reductions $m \pstep m_1$ and $m \red m_2$, then there exists term $m'$ such that $m_1 \red m'$ and $m_2 \pstep m'$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \pstep m_1$, utilizing transitivity of $\red$ and Lemmas \ref{steppstep}, \ref{pstepred}, \ref{diamond}.
\end{proof}

\begin{theorem}
  CLC term reduction is confluent. For terms $m, m_1, m_2$, if there are reductions $m \red m_1$ and $m \red m_2$, then there exists term $m'$ such that $m_1 \red m'$ and $m_2 \red m'$.
\end{theorem}
\begin{proof}
  By induction on the derivation of $m \red m_1$, utilizing transitivity of $\red$ and Lemmas \ref{steppstep}, \ref{pstepred}, \ref{strip}.
\end{proof}

\subsection{Corollaries of Confluence}
The following results are all corollaries of confluence, proven using a combination of induction, transitivity and confluence. These corollaries allow us to refute false reductions and equalities in future proofs.

\begin{corollary}\label{redsortinv}
  For a universe $s_i$ and term $m$, if there is reduction $s_i \red m$, then $m = s_i$.
\end{corollary}

\begin{corollary}\label{redvarinv}
  For variable $x$ and term $m$, if there is reduction $x \red m$, then $m = x$.
\end{corollary}

\begin{corollary}\label{redarrowinv}
  For terms $A, B, m$ and sort $s$, if there is reduction $(x \stype{s} A) \rightarrow B \red m$, then there exist $A'$ and $B'$ such that there are reductions $A \red A'$, $B \red B'$ and $m = (x \stype{s} A') \rightarrow B'$.
\end{corollary}

\begin{corollary}\label{redlolliinv}
  For terms $A, B, m$ and sort $s$, if there is reduction $(x \stype{s} A) \multimap B \red m$, then there exist $A'$ and $B'$ such that there are reductions $A \red A'$, $B \red B'$ and $m = (x \stype{s} A') \multimap B'$.
\end{corollary}

\begin{corollary}\label{redlaminv}
  For terms $A, m, n$ and sort $s$, if there is reduction $\lambda x \stype{s} A.m \red n$, then there exist $A'$ and $m'$ such that there are reductions $A \red A'$, $m \red m'$ and $n = \lambda x \stype{s} A'.m'$.
\end{corollary}

\begin{corollary}\label{sortinj}
  For sorts $s, t$ and levels $i, j$, if there is equality $s_i \equiv t_j$, then there are $s = t$ and $i = j$.
\end{corollary}

\begin{corollary}\label{arrowinj}
  For terms $A_1, A_2, B_1, B_2$ and sorts $s, t$, if there is equality $(x \stype{s} A_1) \rightarrow B_1 \equiv (x \stype{t} A_2) \rightarrow B_2$, then there are equalities $A_1 \equiv A_2$, $B_1 \equiv B_2$ and $s = t$.
\end{corollary}

\begin{corollary}\label{lolliinj}
  For terms $A_1, A_2, B_1, B_2$ and sorts $s, t$, if there is equality $(x \stype{s} A_1) \multimap B_1 \equiv (x \stype{t} A_2) \multimap B_2$, then there are equalities $A_1 \equiv A_2$, $B_1 \equiv B_2$ and $s = t$.
\end{corollary}

\section{Context of CLC}
Contexts of CLC are of the form $x_1 \stype{s1} A_1, x_2 \stype{s2} A_2, ... x_k \stype{sk} A_k$ where each free variable $x_i$ is assigned a type $A_i$ and sort $s_i$. Contexts will be referred to by meta variables $\Gamma$ and $\Delta$.

\begin{figure}[h]
  \begin{mathpar}
    \inferrule
    { }
    { \epsilon \vdash }
    \rname{Wf-$\epsilon$}

    \inferrule
    { \Gamma\ \vdash \\
      \overline{\Gamma} \vdash A : U_i }
    { \Gamma, x \utype A \vdash }
    \rname{Wf-U}

    \inferrule
    { \Gamma\ \vdash \\
      \overline{\Gamma} \vdash A : L_i }
    { \Gamma, x \ltype A\ \vdash }
    \rname{Wf-L}
    \\

    \inferrule
    { }
    { \pure{\epsilon} }
    \rname{Pure-$\epsilon$}

    \inferrule
    { \pure{\Gamma} \\
      \Gamma \vdash A : U_i }
    { \pure{\Gamma, x \utype A} }
    \rname{Pure-U}
    \\

    \inferrule
    { }
    { \mrg{\epsilon}{\epsilon}{\epsilon} }
    \rname{Merge-$\epsilon$}

    \inferrule
    { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
    { \mrg{(\Gamma_1, x \utype A)}
      {(\Gamma_2, x \utype A)}
      {(\Gamma, x \utype A)} }
    \rname{Merge-U}
    \\

    \inferrule
    { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
      x \notin \Gamma_2 }
    { \mrg{(\Gamma_1, x \ltype A)}
      {\Gamma_2}
      {(\Gamma, x \ltype A)} }
    \rname{Merge-L1}

    \inferrule
    { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
      x \notin \Gamma_1 }
    { \mrg{\Gamma_1}
      {(\Gamma_2, x \ltype A)}
      {(\Gamma, x \ltype A)} }
    \rname{Merge-L2}
  \end{mathpar}
  \label{struct}
  \Description{}
\end{figure}

\subsection{Merge Lemmas}\label{mergeprop}
Since weakening and contraction rules will not be allowed on restricted variables, it is necessary to have lemmas that enable the manipulation of contexts.

\begin{lemma}\label{mergesym}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there is $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, then there is $\mrg{\Gamma_2}{\Gamma_1}{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergepure}
  For any context $\Gamma$, if there is $\pure{\Gamma}$, then there is $\mrg{\Gamma}{\Gamma}{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\pure{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergere1}
  For any context $\Gamma$, there is $\mrg{\overline{\Gamma}}{\Gamma}{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{mergere2}
  For any context $\Gamma$, there is $\mrg{\Gamma}{\overline{\Gamma}}{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{mergepureinv}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there are $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\pure{\Gamma}$, then there are $\pure{\Gamma_1}$ and $\pure{\Gamma_2}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergepure1}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$ , if there are $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\pure{\Gamma_1}$, then there is $\Gamma = \Gamma_2$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergepure2}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$ , if there are $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\pure{\Gamma_2}$, then there is $\Gamma = \Gamma_1$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergepurepure}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there are $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, $\pure{\Gamma_1}$ and $\pure{\Gamma_2}$, then there is $\pure{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergepureeq}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there are $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, $\pure{\Gamma_1}$ and $\pure{\Gamma_2}$, then there is $\Gamma_1 = \Gamma_2$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergerere}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there is $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, then there are $\overline{\Gamma_1} = \overline{\Gamma}$ and $\overline{\Gamma_2} = \overline{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{mergererere}
  For any context $\Gamma$, there is $\mrg{\overline{\Gamma}}{\overline{\Gamma}}{\overline{\Gamma}}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\subsection{Restriction and Purity Lemmas}

\begin{lemma}\label{rere}
  For any context $\Gamma$, there is $\overline{\Gamma} = \overline{\overline{\Gamma}}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{purere}
  For any context $\Gamma$, if there is $\pure{\Gamma}$, then there is $\Gamma = \overline{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{repure}
  For any context $\Gamma$ , there is $\pure{\overline{\Gamma}}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{hasure}
  For any context $\Gamma$, variable $x$ and type $A$, if there is $x \utype A \in \Gamma$, then there is $x \utype A \in \overline{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $x \utype A \in \Gamma$.
\end{proof}

\begin{lemma}\label{haslre}
  For any context $\Gamma$, variable $x$ and type $A$, there is $x \ltype A \notin \overline{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{mergesplit1}
  For contexts $\Gamma_1, \Gamma_2, \Gamma, \Delta_1, \Delta_2$, if $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\mrg{\Delta_1}{\Delta_2}{\Gamma_1}$ are valid, then there exists $\Delta$ such that $\mrg{\Delta_1}{\Gamma_2}{\Delta}$ and $\mrg{\Delta}{\Delta_2}{\Gamma}$ are valid.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}
  For contexts $\Gamma_1, \Gamma_2, \Gamma, \Delta_1, \Delta_2$, if $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\mrg{\Delta_1}{\Delta_2}{\Gamma_1}$ are valid, then there exists $\Delta$ such that $\mrg{\Delta_2}{\Gamma_2}{\Delta}$ and $\mrg{\Delta_1}{\Delta}{\Gamma}$ are valid.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\section{Subtyping of CLC}\label{subtyping}

The cumulativity relation ($\preceq$) is the smallest binary relation over terms such that
\begin{enumerate}
  \item $\preceq$ is a partial order with respect to equality.
        \begin{enumerate}
          \item If $A \equiv B$, then $A \preceq B$.
          \item If $A \preceq B$ and $B \preceq A$, then $A \equiv B$.
          \item If $A \preceq B$ and $B \preceq C$, then $A \preceq B$.
        \end{enumerate}
  \item $U_0 \preceq U_1 \preceq U_2 \preceq \cdots$
  \item $L_0 \preceq L_1 \preceq L_2 \preceq \cdots$
  \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, \\ then
        $(x \stype{s} A_1) \rightarrow B_1 \preceq (x \stype{s} A_2) \rightarrow B_2$
  \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, \\ then
        $(x \stype{s} A_1) \multimap B_1 \preceq (x \stype{s} A_2) \multimap B_2$
\end{enumerate}

\noindent
Here, we give an inductive definition of the cumulativity relation ($\preceq$) that is suitable for writing proofs.

\begin{mathpar}
  \inferrule
  { }
  { A \prec A }
  \rname{$\prec$-Refl}

  \inferrule
  { i_1 \leq i_2 }
  { s_{i_1} \prec s_{i_2} }
  \rname{$\prec$-Sort}

  \inferrule
  { B_1 \prec B_2 }
  { (x \stype{s} A) \rightarrow B_1 \prec (x \stype{s} A) \rightarrow B_2 }
  \rname{$\prec$$\rightarrow$}

  \inferrule
  { B_1 \prec B_2 }
  { (x \stype{s} A) \multimap B_1 \prec (x \stype{s} A) \multimap B_2 }
  \rname{$\prec$$\multimap$}

  \inferrule
  { A' \prec B' \\ A \equiv A' \\ B \equiv B' }
  { A \preceq B }
  \rname{$\prec$-$\preceq$}
\end{mathpar}

\subsection{Subtyping Lemmas}

\begin{lemma}\label{sub1sub}
  For terms $A, B$, if there is $A \prec B$, then there is $A \preceq B$.
\end{lemma}
\begin{proof}
  By \rname{$\prec$-$\preceq$} and the reflexivity of equality $\equiv$.
\end{proof}

\begin{lemma}\label{sub1conv}
  For terms $A, B, C$, if there are $A \prec B$ and $B \equiv C$, then there is $A \preceq C$.
\end{lemma}
\begin{proof}
  By \rname{$\prec$-$\preceq$} and the transitivity of equality $\equiv$.
\end{proof}

\begin{lemma}\label{convsub1}
  For terms $A, B, C$, if there are $A \equiv B$ and $B \prec C$, then there is $A \preceq C$.
\end{lemma}
\begin{proof}
  By \rname{$\prec$-$\preceq$} and the transitivity of equality $\equiv$.
\end{proof}

\begin{lemma}\label{convsub}
  For terms $A, B$, if there is $A \equiv B$, then there is $A \preceq B$.
\end{lemma}
\begin{proof}
  By Lemma \ref{convsub1} and \rname{$\prec$-Refl}.
\end{proof}

\begin{lemma}\label{subrefl}
  For term $A$, there is $A \preceq A$.
\end{lemma}
\begin{proof}
  By Lemma \ref{sub1sub} and \rname{$\prec$-Refl}.
\end{proof}

\begin{lemma}\label{subprop}
  For natural numbers $i, j$ and sort $s$ such that $i \leq j$, there is $s_i \preceq s_j$.
\end{lemma}
\begin{proof}
  By Lemma \ref{sub1sub} and \rname{$\prec$-Sort}.
\end{proof}

\begin{lemma}\label{sub1trans}
  For terms $A, B, C, D$, if there are $A \prec B$, $B \equiv C$ and $C \prec D$, then there is $A \preceq D$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $A \prec B$, definition of $\prec$ and Lemmas \ref{sub1sub}, \ref{sub1conv}, \ref{convsub1}.
\end{proof}

\begin{lemma}
  For terms $A, B, C$, if there are $A \preceq B$ and $B \preceq C$, then there is $A \preceq C$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$, rule \rname{$\prec$-$\preceq$} and Lemma \ref{sub1trans}.
\end{proof}

\begin{lemma}
  For sorts $s, t$ and natural numbers $i, j$, if there is $s_i \preceq t_j$, then there are $s = t$ and $i \leq j$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and Corollary \ref{sortinj}.
\end{proof}

\begin{lemma}
  For terms $A_1, A_2, B_1, B_2$ and sorts $s, t$, if there is $(x \stype{s} A_1) \rightarrow B_1 \preceq (x \stype{t} A_2) \rightarrow B_2$, then there are $A_1 \equiv A_2$, $B_1 \preceq B_2$ and $s = t$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and Corollary \ref{arrowinj}.
\end{proof}

\begin{lemma}
  For terms $A_1, A_2, B_1, B_2$ and sorts $s, t$, if there is $(x \stype{s} A_1) \multimap B_1 \preceq (x \stype{t} A_2) \multimap B_2$, then there are $A_1 \equiv A_2$, $B_1 \preceq B_2$ and $s = t$.
\end{lemma}
\begin{proof}
  By transitivity of $\equiv$ and Corollary \ref{lolliinj}.
\end{proof}

\begin{lemma}\label{sub1subst}
  For terms $A, B$  and map $\sigma$ from variables to terms, if there is $A \prec B$, then there is $A[\sigma] \prec B[\sigma]$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $A \prec B$ and the definition of $\prec$.
\end{proof}

\begin{lemma}
  For terms $A, B$ and map $\sigma$ from variables to terms, if there is $A \preceq B$, then there is $A[\sigma] \preceq B[\sigma]$.
\end{lemma}
\begin{proof}
  By rule \rname{$\prec$-$\preceq$} and Lemmas \ref{convsubst}, \ref{sub1subst}.
\end{proof}

\section{Typing of CLC}

The following rules define well-formed contexts.
\begin{mathpar}
  \inferrule
  { }
  { \epsilon \vdash }
  \rname{$\epsilon$-Ok}

  \inferrule
  { \Gamma \vdash \\
    \overline{\Gamma} \vdash A : U_i }
  { \Gamma, x \utype A \vdash }
  \rname{U-Ok}

  \inferrule
  { \Gamma \vdash \\
    \overline{\Gamma} \vdash A : L_i }
  { \Gamma, x \ltype A \vdash }
  \rname{L-Ok}
\end{mathpar}

\noindent
The typing rules of CLC are presented below.
\begin{mathpar}
  \inferrule
  { \pure{\Gamma} }
  { \Gamma \vdash s_i : U_{i+1} }
  \rname{Sort-Axiom}

  \inferrule
  { \pure{\Gamma} \\
    \Gamma \vdash A : U_i \\
    \Gamma, x \utype A \vdash B : s_i }
  { \Gamma \vdash (x \utype A) \rightarrow B : U_i }
  \rname{U$\rightarrow$}

  \inferrule
  { \pure{\Gamma} \\
    \Gamma \vdash A : L_i \\
    \Gamma \vdash B : s_i \\
    x \notin \Gamma }
  { \Gamma \vdash (x \ltype A) \rightarrow B : U_i }
  \rname{L$\rightarrow$}

  \inferrule
  { \pure{\Gamma} \\
    \Gamma \vdash A : U_i \\
    \Gamma, x \utype A \vdash B : s_i }
  { \Gamma \vdash (x \utype A) \multimap B : L_i }
  \rname{U$\multimap$}

  \inferrule
  { \pure{\Gamma} \\
    \Gamma \vdash A : L_i \\
    \Gamma \vdash B : s_i \\
    x \notin \Gamma }
  { \Gamma \vdash (x \ltype A) \multimap B : L_i }
  \rname{L$\multimap$}

  \inferrule
  { \pure{\Gamma_1, \Gamma_2} }
  { \Gamma_1, x \utype A, \Gamma_2 \vdash x : A }
  \rname{U-Var}

  \inferrule
  { \pure{\Gamma_1, \Gamma_2} }
  { \Gamma_1, x \ltype A, \Gamma_2 \vdash x : A }
  \rname{L-Var}

  \inferrule
  { \pure{\Gamma} \\
    \Gamma \vdash (x \stype{s} A) \rightarrow B : t_i \\
    \Gamma, x \stype{s} A \vdash n : B }
  { \Gamma \vdash \lambda x \stype{s} A . n : (x \stype{s} A) \rightarrow B }
  \rname{$\lambda$$\rightarrow$}

  \inferrule
  { \overline{\Gamma} \vdash (x \stype{s} A) \multimap B : t_i \\
    \Gamma, x \stype{s} A \vdash n : B }
  { \Gamma \vdash \lambda x \stype{s} A . n : (x \stype{s} A) \multimap B }
  \rname{$\lambda$$\multimap$}

  \inferrule
  { \Gamma_1 \vdash m : (x \utype A) \rightarrow B \\
    \pure{\Gamma_2} \\
    \Gamma_2 \vdash n : A \\
    \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
  { \Gamma \vdash m\ n : B[n/x] }
  \rname{App-U$\rightarrow$}

  \inferrule
  { \Gamma_1 \vdash m : (x \ltype A) \rightarrow B \\
    \Gamma_2 \vdash n : A \\
    \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
  { \Gamma \vdash m\ n : B[n/x] }
  \rname{App-L$\rightarrow$}
\end{mathpar}

\begin{mathpar}
  \inferrule
  { \Gamma_1 \vdash m : (x \utype A) \multimap B \\
    \pure{\Gamma_2} \\
    \Gamma_2 \vdash n : A \\
    \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
  { \Gamma \vdash m\ n : B[n/x] }
  \rname{App-U$\multimap$}

  \inferrule
  { \Gamma_1 \vdash m : (x \ltype A) \multimap B \\
    \Gamma_2 \vdash n : A \\
    \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
  { \Gamma \vdash m\ n : B[n/x] }
  \rname{App-L$\multimap$}

  \inferrule
  { \Gamma \vdash m : A \\
    \overline{\Gamma} \vdash B : s_i \\ A \preceq B }
  { \Gamma \vdash m : B }
  \rname{Conversion}
\end{mathpar}

\section{Inversion Lemmas of CLC}

\begin{lemma}\label{uarrowinv}
  For any context $\Gamma$ and terms $A, B, s$, if there is $\Gamma \vdash (x \utype A) \rightarrow B : s$, then there exist sort $t$ and natural number $i$ such that $\Gamma \vdash A : U_i$ and $\Gamma, x \utype A \vdash B : t_i$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash (x \utype A) \rightarrow B : s$.
\end{proof}

\begin{lemma}\label{larrowinv}
  For any context $\Gamma$ and terms $A, B, s$, if there is $\Gamma \vdash (x \ltype A)\rightarrow B : s$, then there exist sort $t$ and natural number $i$ such that $\Gamma \vdash A : L_i$ and $\Gamma \vdash B : t_i$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash (x \ltype A) \rightarrow B : s$.
\end{proof}

\begin{lemma}\label{ulolliinv}
  For any context $\Gamma$ and terms $A, B, s$, if there is $\Gamma \vdash (x \utype A) \multimap B : s$, then there exist sort $t$ and natural number $i$ such that $\Gamma \vdash A : U_i$ and $\Gamma, x \utype A \vdash B : t_i$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash (x \utype A) \multimap B : s$.
\end{proof}

\begin{lemma}\label{llolliinv}
  For any context $\Gamma$ and terms $A, B, s$, if there is $\Gamma \vdash (x \ltype A)\multimap B : s$, then there exist sort $t$ and natural number $i$ such that $\Gamma \vdash A : L_i$ and $\Gamma \vdash B : t_i$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash (x \ltype A) \multimap B : s$.
\end{proof}

\begin{lemma}\label{arrowlaminvx}
  For any context $\Gamma$, terms $A, n, C$ and sort $s$, if there is $\Gamma \vdash \lambda x \stype{s} A . n : C$, then for all terms $A', B$, sorts $s', t$ and natural number $i$ such that $C \preceq (x \stype{s'} A') \rightarrow B$ and $\overline{\Gamma, x \stype{s'} A'} \vdash B : t_i$, there is $\Gamma, x \stype{s'} A' \vdash n : B$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash \lambda x \stype{s} A . n : C$ and Lemmas \ref{uarrowinv}, \ref{larrowinv}.
\end{proof}

\begin{lemma}\label{lollilaminvx}
  For any context $\Gamma$, terms $A, n, C$ and sort $s$, if there is $\Gamma \vdash \lambda x \stype{s} A . n : C$, then for all terms $A', B$, sorts $s', t$ and natural number $i$ such that $C \preceq (x \stype{s'} A') \multimap B$ and $\overline{\Gamma, x \stype{s'} A'} \vdash B : t_i$, there is $\Gamma, x \stype{s'} A' \vdash n : B$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash \lambda x \stype{s} A . n : C$ and Lemmas \ref{ulolliinv}, \ref{llolliinv}.
\end{proof}

\begin{lemma}\label{arrowlaminv}
  For any context $\Gamma$, terms $A, A', B, n$, sorts $s, s', t$ and natural number $i$, if there are $\overline{\Gamma} \vdash (x \stype{s'} A') \rightarrow B : t_i$ and $\Gamma \vdash \lambda x \stype{s} A . n : (x \stype{s'} A') \rightarrow B$, then there is $\Gamma, x \stype{s'} A' \vdash n : B$.
\end{lemma}
\begin{proof}
  Direct consequence of Lemmas \ref{uarrowinv}, \ref{larrowinv} and \ref{arrowlaminvx}.
\end{proof}

\begin{lemma}\label{lollilaminv}
  For any context $\Gamma$, terms $A, A', B, n$, sorts $s, s', t$ and natural number $i$, if there are $\overline{\Gamma} \vdash (x \stype{s'} A') \multimap B : t_i$ and $\Gamma \vdash \lambda x \stype{s} A . n : (x \stype{s'} A') \multimap B$, then there is $\Gamma, x \stype{s'} A' \vdash n : B$.
\end{lemma}
\begin{proof}
  Direct consequence of Lemmas \ref{ulolliinv}, \ref{llolliinv} and \ref{lollilaminvx}.
\end{proof}

\section{Weakening Lemmas of CLC}

Weakening for non-linear types is admissible in CLC. To prove this, we first define an $agreeR$ relation between two contexts $\Gamma, \Gamma'$ and a mapping $\xi$ from variables to variables.

\begin{mathpar}
  \inferrule
  { }
  { agreeR\ \xi\ \epsilon\ \epsilon }
  \rname{agreeR-$\epsilon$}

  \inferrule
  { agreeR\ \xi\ \Gamma\ \Gamma' \\
    x \notin FV(\Gamma) \cup FV(\Gamma') }
  { agreeR\ (\xi \cup (x, x))\ (\Gamma, x \utype A) (\Gamma', x \utype A[\xi]) }
  \rname{agreeR-U}

  \inferrule
  { agreeR\ \xi\ \Gamma\ \Gamma' \\
    x \notin FV(\Gamma) \cup FV(\Gamma') }
  { agreeR\ (\xi \cup (x, x))\ (\Gamma, x \ltype A) (\Gamma', x \ltype A[\xi]) }
  \rname{agreeR-L}

  \inferrule
  { agreeR\ \xi\ \Gamma\ \Gamma' \\
    x \notin FV(\Gamma) \cup FV(\Gamma') }
  { agreeR\ \xi\ \Gamma\ (\Gamma', x \utype A) }
  \rname{agreeR-wk}
\end{mathpar}

\subsection{Properties of agreeR}\label{agreeRprop}

\begin{lemma}\label{agreerenrefl}
  For any context $\Gamma$ and the identity map $id$ from variables to variables, $agreeR\ id\ \Gamma\ \Gamma$ is always true.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$ and the definition of $agreeR$.
\end{proof}

\begin{lemma}\label{agreerenpure}
  For contexts $\Gamma, \Gamma'$ and mapping $\xi$, if there are $agreeR\ \xi\ \Gamma\ \Gamma'$ and $\pure{\Gamma}$, then there is $\pure{\Gamma'}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $agreeR\ \xi\ \Gamma\ \Gamma'$.
\end{proof}

\begin{lemma}\label{agreerenrere}
  For contexts $\Gamma, \Gamma'$ and mapping $\xi$, if there is $agreeR\ \xi\ \Gamma\ \Gamma'$, then there is $agreeR\ \xi\ \pure{\Gamma}\ \pure{\Gamma'}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $agreeR\ \xi\ \Gamma\ \Gamma'$.
\end{proof}

\subsection{Weakening Theorem}

\begin{lemma}\label{mergeagreereninv}
  For contexts $\Gamma, \Gamma', \Gamma_1, \Gamma_2$ and mapping $\xi$, if there are $agreeR\ \xi\ \Gamma\ \Gamma'$ and $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, then there exist $\Gamma_1'$ and $\Gamma_2'$ such that there are $\mrg{\Gamma_1'}{\Gamma_2'}{\Gamma'}$, $agreeR\ \xi\ \Gamma_1\ \Gamma_1'$ and $agreeR\ \xi\ \Gamma_2\ \Gamma_2'$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $agreeR\ \xi\ \Gamma\ \Gamma'$ and lemmas in Section \ref{agreeRprop}.
\end{proof}

\begin{lemma}\label{renaming}
  For context $\Gamma, \Gamma'$, terms $m, A$ and mapping $\xi$, if there are $\Gamma \vdash m : A$ and $agreeR\ \xi\ \Gamma\ \Gamma'$, then there is $\Gamma' \vdash m[\xi] : A[\xi]$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash m : A$. We shall only discuss the application case in detail, as the other cases are proven by application of the induction hypothesis and the lemmas in Section \ref{agreeRprop}.
  \begin{itemize}
    \item For the \rname{App-U$\rightarrow$} case, Lemma \ref{mergeagreereninv} is applied to split the context $\Gamma$ into two contexts $\Gamma_1'$ and $\Gamma_2'$ such that there are $\mrg{\Gamma_1'}{\Gamma_2'}{\Gamma'}$, $agreeR\ \xi\ \Gamma_1\ \Gamma_1'$ and $agreeR\ \xi\ \Gamma_2\ \Gamma_2'$. From $\pure{\Gamma_2}$ and Lemma \ref{agreerenpure} we know that there is $\pure{\Gamma_2'}$. At this point, the induction hypothesis allows us to apply \rname{App-U$\rightarrow$} to prove the goal.
    \item For the \rname{App-L$\rightarrow$} case, Lemma \ref{mergeagreereninv} is applied to split the context $\Gamma$ into two contexts $\Gamma_1'$ and $\Gamma_2'$ such that there are $\mrg{\Gamma_1'}{\Gamma_2'}{\Gamma'}$, $agreeR\ \xi\ \Gamma_1\ \Gamma_1'$ and $agreeR\ \xi\ \Gamma_2\ \Gamma_2'$. At this point, the induction hypothesis allows us to apply \rname{App-L$\rightarrow$} to prove the goal.
    \item For the \rname{App-U$\multimap$} case, Lemma \ref{mergeagreereninv} is applied to split the context $\Gamma$ into two contexts $\Gamma_1'$ and $\Gamma_2'$ such that there are $\mrg{\Gamma_1'}{\Gamma_2'}{\Gamma'}$, $agreeR\ \xi\ \Gamma_1\ \Gamma_1'$ and $agreeR\ \xi\ \Gamma_2\ \Gamma_2'$. From $\pure{\Gamma_2}$ and Lemma \ref{agreerenpure} we know that there is $\pure{\Gamma_2'}$. At this point, the induction hypothesis allows us to apply \rname{App-U$\multimap$} to prove the goal.
    \item For the \rname{App-L$\multimap$} case, Lemma \ref{mergeagreereninv} is applied to split the context $\Gamma$ into two contexts $\Gamma_1'$ and $\Gamma_2'$ such that there are $\mrg{\Gamma_1'}{\Gamma_2'}{\Gamma'}$, $agreeR\ \xi\ \Gamma_1\ \Gamma_1'$ and $agreeR\ \xi\ \Gamma_2\ \Gamma_2'$. At this point, the induction hypothesis allows us to apply \rname{App-L$\multimap$} to prove the goal.
  \end{itemize}
\end{proof}

\begin{theorem}
  Weakening is admissible for CLC variables of non-linear type. For context $\Gamma$ and terms $m, A, B$, if there is $\Gamma \vdash m : A$, then there is $\Gamma, x \utype B \vdash m : A$.
\end{theorem}
\begin{proof}
  Using \rname{agreeR-wk} and Lemma \ref{agreerenrefl} a proof of the relation $agreeR\ id\ \Gamma\ (\Gamma, x \utype B)$ can be constructed. Then by Lemma \ref{renaming}, the theorem can be proven.
\end{proof}

\section{Substitution Lemmas of CLC}

Similarly to the proof of weakening, we first define an $agreeS$ relation between two contexts $\Gamma, \Delta$ and a mapping $\sigma$ from variables to terms.

\begin{mathpar}
  \inferrule
  { }
  { agreeS\ \sigma\ \epsilon\ \epsilon }
  \rname{agreeS-$\epsilon$}

  \inferrule
  { agreeS\ \sigma\ \Delta\ \Gamma \\
    x \notin FV(\Delta) \cup FV(\Gamma) }
  { agreeS\ (\sigma \cup (x, x))\ (\Delta, x \utype A[\sigma])\ (\Gamma, x \utype A) }
  \rname{agreeS-U}

  \inferrule
  { agreeS\ \sigma\ \Delta\ \Gamma \\
    x \notin FV(\Delta) \cup FV(\Gamma) }
  { agreeS\ (\sigma \cup (x, x))\ (\Delta, x \ltype A[\sigma])\ (\Gamma, x \ltype A) }
  \rname{agreeS-L}

  \inferrule
  { x \notin FV(\Delta) \cup FV(\Gamma) \\\\
    agreeS\ \sigma\ \Delta\ \Gamma \\
    \overline{\Delta} \vdash n : A[\sigma] }
  { agreeS\ (\sigma \cup (x, n))\ \Delta\ (\Gamma, x \utype A) }
  \rname{agreeS-wkU}

  \inferrule
  { x \notin FV(\Delta) \cup FV(\Gamma) \\
    \mrg{\Delta_1}{\Delta_2}{\Delta} \\\\
    agreeS\ \sigma\ \Delta_1\ \Gamma \\
    \Delta_2 \vdash n : A[\sigma] }
  { agreeS\ (\sigma \cup (x, n))\ \Delta\ (\Gamma, x \ltype A) }
  \rname{agreeS-wkL}
\end{mathpar}

\begin{mathpar}
  \inferrule
  { agreeS\ \sigma\ \Delta\ (\Gamma, x \utype A) \\\\
    A \preceq B \\
    \overline{\Delta} \vdash B[\sigma] : U_i }
  { agreeS\ \sigma\ \Delta\ (\Gamma, x \utype B) }
  \rname{agreeS-convU}

  \inferrule
  { A \preceq B \\
    agreeS\ \sigma\ \Delta\ (\Gamma, x \ltype A) \\\\
    \overline{\Delta} \vdash B[\sigma] : L_i \\
    \overline{\Gamma} \vdash B : L_i }
  { agreeS\ \sigma\ \Delta\ (\Gamma, x \ltype B) }
  \rname{agreeS-convL}
\end{mathpar}

\subsection{Properties of agreeS}\label{agreeSprop}

\begin{lemma}\label{agreesubstrefl}
  For any context $\Gamma$ and identity mapping id, there is $agreeS\ id\ \Gamma\ \Gamma$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}\label{agreesubstrere}
  For contexts $\Delta, \Gamma$ and mapping $\sigma$, if there is $agreeS\ \sigma\ \Delta\ \Gamma$, then there is $agreeS\ \sigma\ \overline{\Delta}\ \overline{\Gamma}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $agreeS\ \sigma\ \Delta\ \Gamma$.
\end{proof}

\subsection{Substitution Lemma}

\begin{lemma}\label{mergeagreesubstinv}
  For contexts $\Delta, \Gamma, \Gamma_1, \Gamma_2$ and mapping $\sigma$, if there are $agreeS\ \sigma\ \Delta\ \Gamma$ and $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, then there exist contexts $\Delta_1, \Delta_2$ such that there are $\mrg{\Delta_1}{\Delta_2}{\Delta}$, $agreeS\ \sigma\ \Delta_1\ \Gamma_1$ and $agreeS\ \sigma\ \Delta_2\ \Gamma_2$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $agreeS\ \sigma\ \Delta\ \Gamma$ and lemmas in Section \ref{agreeSprop}.
\end{proof}

\begin{lemma}
  Generalized Substitution Lemma. For context $\Gamma, \Delta$, terms $m, A$ and mapping $\sigma$, if there are $\Gamma \vdash m : A$ and $agreeS\ \sigma\ \Delta\ \Gamma$, then there is $\Delta \vdash m[\sigma] : A[\sigma]$.
\end{lemma}
\begin{proof}
  The proof proceeds by induction on the derivation of $\Gamma \vdash m : A$. Similarly to the proof of Lemma \ref{renaming}, the interesting cases are the application cases where Lemma \ref{mergeagreesubstinv} must be utilized to split the $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ judgments for use in the induction hypothesis.
\end{proof}

\subsection{Corollaries of Substitution}

\begin{corollary}\label{substitutionu}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$ and terms $A, B, m, n$, if there are $\Gamma_1, x \utype A \vdash m : B$, $\pure{\Gamma_2}$, $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\Gamma_2 \vdash n : A$, then there is $\Gamma \vdash m[n/x]: B[n/x]$.
\end{corollary}

\begin{corollary}\label{substitutionl}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$ and terms $A, B, m, n$, if there are $\Gamma_1, x \ltype A \vdash m : B$, $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\Gamma_2 \vdash n : A$, then there is $\Gamma \vdash m[n/x]: B[n/x]$.
\end{corollary}

\begin{corollary}\label{contextconvu}
  For context $\Gamma$, terms $m, A, B, C$ and natural number $i$, if there are $B \equiv A$, $\overline{\Gamma} \vdash A : U_i$ and $\Gamma, x \utype A \vdash m : C$, then there is $\Gamma, x \utype B \vdash m : C$.
\end{corollary}

\begin{corollary}\label{contextconvl}
  For context $\Gamma$, terms $m, A, B, C$ and natural number $i$, if there are $B \equiv A$, $\overline{\Gamma} \vdash A : L_i$ and $\Gamma, x \ltype A \vdash m : C$, then there is $\Gamma, x \ltype B \vdash m : C$.
\end{corollary}

\section{Typing Validity of CLC}

In this section, we prove that the types of all CLC terms are themselves well-sorted.

\begin{lemma}\label{mergecontextokinv}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there are $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\Gamma \vdash$, then there are $\Gamma_1 \vdash$ and $\Gamma_2 \vdash$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and the properties of $merge$ discussed in Section \ref{mergeprop}.
\end{proof}

\begin{theorem}\label{valid}
  The validity of typing theorem. For any context $\Gamma$ and terms $m, A$, if there are $\Gamma \vdash$ and $\Gamma \vdash m : A$, then there exist sort $s$ and natural number $i$ such that $\overline{\Gamma} \vdash A : s_i$.
\end{theorem}

\section{Subject Reduction of CLC}

\begin{theorem}
  For any context $\Gamma$ and terms $m, n, A$, if $\Gamma \vdash$ and $\Gamma \vdash m : A$ and $m \step n$, then there is $\Gamma \vdash n : A$.
\end{theorem}
\begin{proof}
  The proof proceeds by induction on the derivation of $\Gamma \vdash m : A$. The interesting cases are the application cases which we shall discuss in detail.
  \begin{itemize}
    \item For the \rname{App-U$\rightarrow$} case, from assumptions $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\pure{\Gamma_2}$ and Lemmas \ref{mergepure2}, \ref{mergerere}, we can conclude that $\overline{\Gamma_1} = \overline{\Gamma}$ and $\overline{\Gamma_2} = \overline{\Gamma}$. Applying Lemma \ref{mergecontextokinv} to assumptions $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\Gamma \vdash$ obtains $\Gamma_1 \vdash$ and $\Gamma_2 \vdash$. Now by the induction hypothesis, we can conclude there exist sorts $s, t$ and natural numbers $i, j$ such that there are $\overline{\Gamma_1} \vdash (x \utype A) \rightarrow B : s_i$ and $\overline{\Gamma_2} \vdash A : t_j$. Applying Lemma \ref{uarrowinv} to assumption $\overline{\Gamma_1} \vdash (x \utype A) \rightarrow B : s_i$ allows us to derive $\overline{\Gamma_1} \vdash A : U_{i'}$ and $\overline{\Gamma_1}, x \utype A \vdash B : s'_{j'}$ where $s'$ is a sort and $i', j'$ are natural numbers. The goal can finally be proven by applying the substitution Lemma \ref{substitutionu} on assumptions $\Gamma_2 \vdash n : A$ and $\overline{\Gamma_1}, x \utype A \vdash B : s'_{j'}$.
    \item For the \rname{App-L$\rightarrow$} case, from assumption $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and Lemmas \ref{mergerere}, we can conclude that $\overline{\Gamma_1} = \overline{\Gamma}$ and $\overline{\Gamma_2} = \overline{\Gamma}$. Applying Lemma \ref{mergecontextokinv} to assumptions $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $\Gamma \vdash$ obtains $\Gamma_1 \vdash$ and $\Gamma_2 \vdash$. Now by the induction hypothesis, we can conclude that there exists sorts $s, t$ and natural numbers $i, j$ such that there are $\overline{\Gamma_1} \vdash (x \ltype A) \rightarrow B : s_i$ and $\overline{\Gamma_2} \vdash A : t_j$. Applying Lemma \ref{larrowinv} to assumption $\overline{\Gamma_1} \vdash (x \ltype A) \rightarrow B : s_i$ allows us to derive $\overline{\Gamma_1} \vdash A : L_{i'}$ and $\overline{\Gamma_1} \vdash B : s'_{j'}$. Due to the fact that variable $x$ is not a free variable in $B$, the substitution occurring in goal $\exists s \in sort, i \in \mathbb{N}, \overline{\Gamma} \vdash B[n/x] : s_i$ is trivial, thus the judgment $\overline{\Gamma_1} \vdash B : s'_{j'}$ that we have proven shows the existence of the goal.
    \item For the \rname{App-U$\multimap$} case, the proof is similar to the \rname{App-U$\rightarrow$} case; the only difference is that the inversion lemmas used correspond to $\multimap$ instead of $\rightarrow$.
    \item For the \rname{App-L$\multimap$} case, the proof is similar to the \rname{App-L$\rightarrow$} case; the only difference is that the inversion lemmas used correspond to $\multimap$ instead of $\rightarrow$.
  \end{itemize}
\end{proof}

\section{Linearity Theorems of CLC}

\subsection{Linearity}

We introduce a meta-function $occurs$ that counts the number of times a given variable occurs in a term.

\begin{align*}
  occurs(x, y)                               & =
  \begin{dcases}
    1 & x =_\alpha y    \\
    0 & x \neq_\alpha y
  \end{dcases}                                                \\
  occurs(x, s_i)                             & = 0                           \\
  occurs(x, ((y \stype{s} A) \rightarrow B)) & = occurs(x, A) + occurs(x, B) \\
  occurs(x, ((y \stype{s} A) \multimap B))   & = occurs(x, A) + occurs(x, B) \\
  occurs(x, (\lambda x \stype{s} A.n))       & = occurs(x, A) + occurs(x, n) \\
  occurs(x, (m\ n))                          & = occurs(x, m) + occurs(x, n)
\end{align*}

\begin{lemma}\label{islmergeinv}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there is $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, then for any variable with linear type $x \in \Gamma$ there are $x \in \Gamma_1$ and $x \notin \Gamma_2$ or $x \in \Gamma_2$ and $x \notin \Gamma_1$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}
  For contexts $\Gamma_1, \Gamma_2, \Gamma$, if there is $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, then for any variable $x \notin \Gamma$ there are $x \notin \Gamma_1$ and $x \notin \Gamma_2$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$.
\end{proof}

\begin{lemma}\label{narity}
  For context $\Gamma$, terms $m, A$, if there is $\Gamma \vdash m : A$, then for any variable $x \notin \Gamma$ there is $occurs(x, m) = 0$
\end{lemma}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash m : A$.
\end{proof}

\begin{theorem}\label{linearity}
  Linearity. For context $\Gamma$, terms $m, A$, if there is $\Gamma \vdash m : A$, then for any variable with linear type $x \in \Gamma$ there is $occurs(x, m) = 1$.
\end{theorem}
\begin{proof}
  The proof proceeds by induction on the derivation of $\Gamma \vdash m : A$, we will discuss the application cases in detail.
  \begin{itemize}
    \item For case \rname{App-U$\rightarrow$}, by assumptions $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ and $(x \ltype A) \in \Gamma$ and Lemma \ref{islmergeinv} we can conclude that $x \in \Gamma_1$ and $x \notin \Gamma_2$ or $x \in \Gamma_2$ and $x \notin \Gamma_1$. In both cases, applying the induction hypothesis and Lemma \ref{narity} proves the goal.
    \item For case \rname{App-L$\rightarrow$}, the proof is the same as \rname{App-U$\rightarrow$}.
    \item For case \rname{App-U$\multimap$}, the proof is the same as \rname{App-U$\rightarrow$}.
    \item For case \rname{App-L$\multimap$}, the proof is the same as \rname{App-U$\rightarrow$}.
  \end{itemize}
\end{proof}

\subsection{Promotion}
\begin{theorem}\label{promotion}
  Promotion. For context $\Gamma$, terms $m, A, B$ and sort $s$, if there are $\pure{\Gamma}$, $\Gamma \vdash$ and $\Gamma \vdash m : (x \stype{s} A) \multimap B$, then there exists term $n$ such that $\Gamma \vdash n : (x \stype{s} A) \rightarrow B$.
\end{theorem}
\begin{proof}
  Set $n = \lambda x \stype{s} A. (m\ x)$. The proof proceeds by case analysis on the sort $s$.
  \begin{itemize}
    \item If $s = U$, then we may apply Theorem \ref{valid} to assumption $\Gamma \vdash m : (x \utype A) \multimap B$ to show that there exist sort $t$ and natural number $i$ such that there is $\overline{\Gamma} \vdash (x \utype A) \multimap B : t_i$. Now applying Lemma \ref{ulolliinv} to $\overline{\Gamma} \vdash (x \utype A) \multimap B : t_i$ shows that there exist sort $t'$ and natural number $i'$ such that $\overline{\Gamma} \vdash A : U_{i'}$ and $\overline{\Gamma}, x \utype A \vdash B : t'_{i'}$. Now by \rname{U$\rightarrow$} and Lemma \ref{purere} the goal is proven.
    \item If $s = L$, then we may apply Theorem \ref{valid} to assumption $\Gamma \vdash m : (x \ltype A) \multimap B$ to show that there exist sort $t$ and natural number $i$ such that $\overline{\Gamma} \vdash (x \ltype A) \multimap B : t_i$. Now applying Lemma \ref{llolliinv} to $\overline{\Gamma} \vdash (x \ltype A) \multimap B : t_i$ shows that there exist sort $t'$ and natural number $i'$ such that $\overline{\Gamma} \vdash A : U_{i'}$ and $\overline{\Gamma} \vdash B : t'_{i'}$. Now by \rname{L$\rightarrow$} and Lemma \ref{purere} the goal is proven.
  \end{itemize}
\end{proof}

\subsection{Dereliction}

\begin{theorem}
  Dereliction. For context $\Gamma$, terms $m, A, B$ and sort $s$, if there are $\Gamma \vdash$ and $\Gamma \vdash m : (x \stype{s} A) \rightarrow B$, then there exists term $n$ such that $\Gamma \vdash n : (x \stype{s} A) \multimap B$.
\end{theorem}
\begin{proof}
  Set $n = \lambda x \stype{s} A . (m\ x)$. The proof proceeds by case analysis on the sort $s$.
  \begin{itemize}
    \item If $s = U$, then we may apply Theorem \ref{valid} to $\Gamma \vdash m : (x \utype A) \rightarrow B$ showing that there exist sort $t$ and natural number $i$ such that there is $\overline{\Gamma} \vdash (x \utype A) \rightarrow B : t_i$. Now applying Lemma \ref{uarrowinv} to $\overline{\Gamma} \vdash (x \utype A)\rightarrow B : t_i$ shows that there exist sort $t'$ and natural number $i'$ such that $\overline{\Gamma} \vdash A : U_{i'}$ and $\overline{\Gamma}, x \utype A \vdash B : t'_{i'}$. By \rname{U$\multimap$} and Lemma \ref{repure} we can prove $\overline{\Gamma} \vdash (x \utype A) \multimap B : L_{i'}$. By rule \rname{$\lambda$$\multimap$}, the rest of the goal can be proven in a straightforward manner.
    \item If $s = L$, then we may apply Theorem \ref{valid} to $\Gamma \vdash m : (x \ltype A) \rightarrow B$ showing that there exist sort $t$ and natural number $i$ such that there is $\overline{\Gamma} \vdash (x \ltype A) \rightarrow B : t_i$. Now applying Lemma \ref{larrowinv} to $\overline{\Gamma} \vdash (x \ltype A)\rightarrow B : t_i$ shows that there exist sort $t'$ and natural number $i'$ such that $\overline{\Gamma} \vdash A : U_{i'}$ and $\overline{\Gamma} \vdash B : t'_{i'}$. By \rname{L$\multimap$} and Lemma \ref{repure} we can prove $\overline{\Gamma} \vdash (x \ltype A) \multimap B : L_{i'}$. By rule \rname{$\lambda$$\multimap$}, the rest of the goal can be proven in a straightforward manner.
  \end{itemize}
\end{proof}

\section{Logical Consistency of CLC}

\subsection{Strong Normalization}

The proof of the logical consistency of CLC proceeds by construction of a reduction preserving erasure from CLC to CC$\omega$. As CC$\omega$ is consistent, CLC must be consistent as well.

The erasure procedure is recursively defined as follows.
\begin{align*}
  \erase{x}                             & = x                                     \\
  \erase{U_i}                           & = Type_i                                \\
  \erase{L_i}                           & = Type_i                                \\
  \erase{(x \stype{s} A) \rightarrow B} & = (x : \erase{A}) \rightarrow \erase{B} \\
  \erase{(x \stype{s} A) \multimap B}   & = (x : \erase{A}) \rightarrow \erase{B} \\
  \erase{\lambda x\stype{s}A.n}         & = \lambda x : \erase{A}.\erase{n}       \\
  \erase{m\ n}                          & = \erase{m}\ \erase{n}
\end{align*}

With slight overloading of notation, we define erasure for CLC contexts recursively.

\begin{align*}
  \erase{\epsilon}              & = \epsilon                      \\
  \erase{\Gamma, x \stype{s} A} & = \erase{\Gamma}, x : \erase{A}
\end{align*}

\begin{lemma}
  For CLC term $m$, map $\sigma$ from variables to CLC terms, map $\tau$ from variables to CC$\omega$ terms, if for all variables $x$ there is $\erase{\sigma\ x} = \tau\ x$, then $\erase{m[\sigma]} = \erase{m}[\tau]$.
\end{lemma}
\begin{proof}
  By induction on the structure of term $m$.
\end{proof}

For the following lemmas, we will index relations and judgments with subscript CLC or CC$\omega$ to emphasize the language it is defined over.

\begin{lemma}\label{erasestep}
  For any CLC terms $m$ and $n$, if there is $m \step_{\scriptscriptstyle \text{CLC}} n$, then there is $\erase{m} \step_{\scriptscriptstyle \text{CC$\omega$}} \erase{n}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \step_{\scriptscriptstyle \text{CLC}} n$.
\end{proof}

\begin{lemma}
  For any CLC terms $m$ and $n$, if there is $m \equiv_{\scriptscriptstyle \text{CLC}} n$, then there is $\erase{m} \equiv_{\scriptscriptstyle \text{CC$\omega$}} \erase{n}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \equiv_{\scriptscriptstyle \text{CLC}} n$ and Lemma \ref{erasestep}.
\end{proof}

\begin{lemma}\label{erasesub1}
  For any CLC terms $m$ and $n$, if there is $m \prec_{\scriptscriptstyle \text{CLC}} n$, then there is $\erase{m} \prec_{\scriptscriptstyle \text{CC$\omega$}} \erase{n}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \prec_{\scriptscriptstyle \text{CLC}} n$.
\end{proof}

\begin{lemma}
  For any CLC terms $m$ and $n$, if there is $m \preceq_{\scriptscriptstyle \text{CLC}} n$, then there is $\erase{m} \preceq_{\scriptscriptstyle \text{CC$\omega$}} \erase{n}$.
\end{lemma}
\begin{proof}
  By case analysis on the derivation of $m \preceq_{\scriptscriptstyle \text{CLC}} n$ and the properties of subtyping proven in Section \ref{subtyping}.
\end{proof}

\begin{theorem}\label{embed}
  Embedding. For any CLC context $\Gamma$ and CLC terms $m, A$, if there is $\Gamma \vdash_{\scriptscriptstyle \text{CLC}} m : A$, then there is $\erase{\Gamma} \vdash_{\scriptscriptstyle \text{CC$\omega$}} \erase{m} : \erase{A}$.
\end{theorem}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash_{\scriptscriptstyle \text{CLC}} m : A$.
\end{proof}

\begin{corollary}\label{embeddingcontext}
  For any CLC context $\Gamma$, if there is $\Gamma \vdash_{\scriptscriptstyle \text{CLC}}$, then there is $\erase{\Gamma} \vdash_{\scriptscriptstyle \text{CC$\omega$}}$.
\end{corollary}
\begin{proof}
  Direct consequence of applying Theorem \ref{embed} to all types in context $\Gamma$.
\end{proof}

\begin{theorem}
  Strong normalization of CLC.
\end{theorem}
\begin{proof}
  Suppose there exists a well-typed CLC term $m$ with an infinite sequence of reductions. Theorem \ref{embed} shows that there must exist some term $\erase{m}$ that is well-typed in CC$\omega$. Additionally, this infinite sequence of reductions on $m$ can be translated in CC$\omega$ step-wise by Lemma \ref{erasestep}. This shows that we have constructed a non-normalizing CC$\omega$ term $\erase{m}$, which a contradiction to the strong normalization property of CC$\omega$, thus CLC must be strongly normalizing as well.
\end{proof}

\subsection{Embedding}
To show that CLC is compatible with the predicative fragment of CC$\omega$, we construct a lifting procedure that lifts CC$\omega$ terms into CLC in a straightforward way.
\begin{align*}
  \lift{x}                     & = x                                        \\
  \lift{Type_i}                & = U_i                                      \\
  \lift{(x : A) \rightarrow B} & = (x \utype \lift{A}) \rightarrow \lift{B} \\
  \lift{\lambda x : A.n}       & = \lambda x\utype\lift{A}.\lift{n}         \\
  \lift{m\ n}                  & = \lift{m}\ \lift{n}
\end{align*}

With slight overloading of notation, we define lifting for CC$\omega$ recursively.
\begin{align*}
  \lift{\epsilon}      & = \epsilon                         \\
  \lift{\Gamma, x : A} & = \lift{\Gamma}, x \utype \lift{A}
\end{align*}

\begin{lemma}
  For CC$\omega$ context $\Gamma$, there is $\pure{\lift{\Gamma}}$.
\end{lemma}
\begin{proof}
  By induction on the structure of $\Gamma$.
\end{proof}

\begin{lemma}
  For CC$\omega$ term $m$, map $\sigma$ from variables to CC$\omega$ terms, map $\tau$ from variables to CLC terms, if for all variables $x$ there is $\lift{\sigma\ x} = \tau\ x$, then $\lift{m[\sigma]} = \lift{m}[\tau]$.
\end{lemma}
\begin{proof}
  By induction on the structure of term $m$.
\end{proof}
For the following lemmas, we will index relations and judgments with subscript CLC or CC$\omega$ to emphasize the language it is defined over.

\begin{lemma}\label{liftstep}
  For any CC$\omega$ terms $m$ and $n$, if there is $m \step_{\scriptscriptstyle \text{CC$\omega$}} n$, then there is $\lift{m} \step_{\scriptscriptstyle \text{CLC}} \lift{n}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \step_{\scriptscriptstyle \text{CC$\omega$}} n$.
\end{proof}

\begin{lemma}
  For any CC$\omega$ terms $m$ and $n$, if there is $m \equiv_{\scriptscriptstyle \text{CC$\omega$}} n$, then there is $\lift{m} \equiv_{\scriptscriptstyle \text{CLC}} \lift{n}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \equiv_{\scriptscriptstyle \text{CC$\omega$}} n$ and Lemma \ref{liftstep}.
\end{proof}

\begin{lemma}\label{liftsub1}
  For any CC$\omega$ terms $m$ and $n$, if there is $m \prec_{\scriptscriptstyle \text{CC$\omega$}} n$, then there is $\lift{m} \prec_{\scriptscriptstyle \text{CLC}} \lift{n}$.
\end{lemma}
\begin{proof}
  By induction on the derivation of $m \prec_{\scriptscriptstyle \text{CC$\omega$}} n$.
\end{proof}

\begin{lemma}
  For any CC$\omega$ terms $m$ and $n$, if there is $m \preceq_{\scriptscriptstyle \text{CC$\omega$}} n$, then there is $\lift{m} \preceq_{\scriptscriptstyle \text{CLC}} \lift{n}$.
\end{lemma}
\begin{proof}
  By case analysis on the derivation of $m \preceq_{\scriptscriptstyle \text{CC$\omega$}} n$ and the properties of subtyping proven in Section \ref{subtyping}.
\end{proof}

\begin{theorem}\label{lifting}
  Lifting. For any CC$\omega$ context $\Gamma$ and CC$\omega$ terms $m, A$, if there is $\Gamma \vdash_{\scriptscriptstyle \text{CC$\omega$}} m : A$, then there is $\lift{\Gamma} \vdash_{\scriptscriptstyle \text{CLC}} \lift{m} : \lift{A}$.
\end{theorem}
\begin{proof}
  By induction on the derivation of $\Gamma \vdash_{\scriptscriptstyle \text{CC$\omega$}} m : A$.
\end{proof}

\end{document}
