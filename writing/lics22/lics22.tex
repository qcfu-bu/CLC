% document layout
\documentclass[sigplan,screen,review,authordraft]{acmart}
%\documentclass[sigplan,screen]{acmart}
\usepackage[utf8]{inputenc}

% packages
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mdwtab}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{listings}
\usepackage{lstlangcoq}
\usepackage{float}
\usepackage{tikz-cd}
\usepackage{enumitem}

\lstset{basicstyle=\small,language=Coq,showstringspaces=false}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\setlist[itemize]{leftmargin=1.6em}
\renewcommand{\syntleft}{}
\renewcommand{\syntright}{}
\setlength{\grammarparsep}{7pt}
\setlength{\grammarindent}{7em}
\newcommand{\indalt}[1][2]{\\\hspace*{-1.2em}\textbar\quad}
\newcommand{\rname}[1]{\textsc{\footnotesize #1}}
\newcommand{\pure}[1]{|#1|}
\newcommand{\refl}{\text{refl}}
\newcommand{\letin}[3]{\ $\text{let }#1\text{ := }#2\text{ in }#3$\ }
\newcommand{\ind}{\ $\text{ind}$\ }
\newcommand{\iter}{\ $\text{iter}$\ }
\newcommand{\unit}{\text{unit}}
\newcommand{\new}{\text{new}}
\newcommand{\free}{\text{free}}
\newcommand{\get}{\text{get}}
\newcommand{\set}{\text{set}}
\newcommand{\session}{\text{session}}
\newcommand{\channel}{\text{channel}}
\newcommand{\open}{\text{open}}
\newcommand{\close}{\text{close}}
\newcommand{\send}{\text{send}}
\newcommand{\recv}{\text{recv}}
\newcommand{\SEND}{\texttt{SEND}}
\newcommand{\RECV}{\texttt{RECV}}
\newcommand{\END}{\texttt{END}}
\newcommand{\utype}{:_{\scriptscriptstyle U}}
\newcommand{\ltype}{:_{\scriptscriptstyle L}}
\newcommand{\stype}[1]{:_#1}
\newcommand{\step}{\leadsto}
\newcommand{\pstep}{\leadsto}
\newcommand{\mrg}[3]{#1\ddagger#2\ddagger#3}
\newcommand{\erase}[1]{\llbracket #1 \rrbracket}
\newcommand{\lift}[1]{\llparenthesis #1 \rrparenthesis}

% title and author
\title{The Calculus of Linear Constructions}
\author{Qiancheng Fu}
\affiliation{
  \institution{Boston University}
  \city{Boston}
  \state{MA}
  \country{USA}
}
\email{qcfu@bu.edu}

% document body
\begin{document}
  \begin{abstract}
    The Calculus of Linear Constructions (CLC) is an extension of the Calculus of Constructions (CC) with linear types. Specifically, CLC extends CC with a hierarchy of linear universes that precisely controls the weakening and contraction of its term level inhabitants. We study the meta-theory of CLC, showing that it is a sound logical framework for reasoning about resource. CLC is backwards compatible with CC, allowing CLC to enjoy the fruits of decades of CC research. We have formalized and proven correct all major results of the core calculus in the Coq Proof Assistant. We extend CLC with linear inductive types, showing that CLC facilitates correct by construction imperative programming.
  \end{abstract}
  \maketitle 

  \section{Introduction}
  The Calculus of Constructions (CC) is a dependent type theory introduced by Coquand and Huet in their landmark work \cite{cc}. In CC types can depend on terms, allowing one to write precise specifications as types. Today, CC and its variations CIC \cite{cic} and ECC \cite{ecc} lie at the core of popular proof assistants such as Coq \cite{coq}, Agda \cite{agda}, Lean \cite{lean} and others. These theorem provers have found great success in the fields of software verification, and constructive mathematics. 
  
  However, due to its origins as a logical framework for constructive mathematics, it is quite difficult for CC to encode and reason about resources. Intuitively, a mathematical theorem can be applied an unrestricted number of times. Comparatively, the usage of resources is more limited. For example, if we encode Girard's classical example \cite{girard95} of purchasing cigarettes literally into CC as a function of type:
  \begin{equation*}
    Money \rightarrow Camels + Marlboro
  \end{equation*}
  If viewed as a propositional implication, the customer will still maintain full ownership of their money after paying the vendor, because implication does not diminish the validity of its antecedent. Unless the vendor is exceedingly generous, we are faced with the crime of counterfeiting. Users of proof assistants based on CC often need to embed external logics such as Separation Logic to provide additional reasoning principles for dealing with resource. The design and embedding of these logics are a difficult problem in their own right, requiring additional proofs to justify their soundness, and effectiveness. We propose an alternative solution: extend CC with linear types.
  
  This paper presents a new linear dependent type system --- The Calculus of Linear Constructions (CLC). CLC extends CC$\omega$ with linear types. CC$\omega$ itself is an extension of CC with a cumulative hierarchy of type universes. We add an extra universe sort $L$ of linear types with cumulativity parallel to the sort $U$ of non-linear types. This ultimately cumulates in the \textit{linearity} theorem, stating that all resources are used exactly once.

  The presence of both linear and dependent types enables CLC to write specifications that faithfully encode the usage of resources. The previous example of monetary transaction can be refined using an indexed linear type family $Money : \mathbb{N} \rightarrow L$ as follows.
  \begin{equation*}
    (x \ltype Money\ 5) \rightarrow (Camels + Marlboro)
  \end{equation*}
  This new specification for the transaction demands a payment of 5 units of money, and the customer be relieved of their ownership after the transaction finishes, effectively preventing the contradiction of having your cake and eating it too.

  Compared to preexisting approaches for integrating linear types and dependent types, CLC offers a ``lightweight'' approach to extending CC$\omega$ with linear types, akin to Mazurak et al.'s work on System F \cite{mazurak}. Prior works have either utilized a literal ! exponential or a pair of adjoint connectives to bridge the gap between linear and non-linear types, adding clutter that greatly hinders their practical usage. Our method requires neither exponential nor adjoint connectives, allowing for a straightforward modeling of CLC in CC$\omega$, and lifting of CC$\omega$ into CLC with minimal annotations, endowing CLC with the fruits of decades of CC research. 
  
  We further extend CLC with inductive types, showing that CLC facilitates correct by construction imperative programming. We have formalized all major results in Coq, and implemented a prototype in OCaml. 

  \noindent \textbf{\textit{Contributions}}: 
  Our contributions can be summarized as follows.
  \begin{itemize}
    \item Fist, we describe the Calculus of Linear Constructions, an extension to the Calculus of Constructions with linear types. The integration of linear types and dependent types allows CLC to directly and precisely reason about resource.
    \item Second, we study the meta-theory of CLC directly, showing that it satisfies the standard properties of confluence, propagation and subject reduction.
    \item Next, we prove the linearity theorem, showing the tangible impact linear types have on the structure of terms. We also show that promotion and dereliction of linear logic are derivable as theorems for canonical types.
    \item Additionally, we observe that CLC is highly backwards compatible with CC$\omega$, allowing us to construct a reduction preserving model of CLC in CC$\omega$, showing that CLC is consistent. We also prove that all valid CC$\omega$ terms after adding minimal amounts of annotation are valid CLC terms.
    \item All major results have been formalized and proven correct in the Coq Proof Assistant with help from the Autosubst \cite{autosubst} library. To the best of our knowledge, our development is the first machine checked formalization of a linear dependent type theory.
    \item Furthermore, we extend CLC with linear inductive data, demonstrating CLC's capabilities for correct by construction imperative programming.
    \item Finally, we give an implementation extended with user definable linear and non-linear inductive types. Algorithmic type checking employed by the implementation streamlines the process of writing CLC.
  \end{itemize}

  \section{The Language of CLC}
  \subsection{Syntax}
  \begin{figure}[h]
    \vspace{-1em}
    \caption{Syntax}
    \vspace{1em}
    \begin{grammar}
      <$k$> := 0 | 1 | 2 ... \phantom{* |} \hspace*{3em} predicative levels

      <$i$> := * | 0 | 1 | 2 ... \hspace*{3em} all levels

      <$s, t$> ::= $U$ | $L$ \phantom{| $x$} \hspace*{4.6em} sorts

      <$m, n, A, B, C$> ::= $U_i$ | $L_k$ | $x$ \hspace*{4em} expressions
      \indalt $(x :_s A) \rightarrow B$
      \indalt $(x :_s A) \multimap B$
      \indalt $\lambda x. n$ | $m\ n$
    \end{grammar}
    \label{syntax}
  \end{figure}
  The syntax of the core type theory is presented in Figure \ref{syntax}. Our type theory contains two sorts of universes $U$ and $L$. We use the meta variable $k$ to specifically quantify over levels $0, 1, 2, ...$ that correspond to the predicative universes. We use the meta variable $i$ to quantify over all levels $*, 0, 1, 2, ...$. Here, $U_*$ is the impredicative universe of propositions, in the same spirit as CC$\omega$'s $Prop$ universe. $U_k$, and $L_k$ are the predicative universes of non-linear and linear types respectively.
  \begin{figure}[h]
    \vspace{-1em}
    \caption{Correspondence of CLC types and MELL implications}
    \Description{}
    \vspace{-1em}
    \begin{align}
      (\_ \utype A) \rightarrow B \quad &\Leftrightarrow \quad !(!A \multimap B) \\
      (\_ \ltype A) \rightarrow B \quad &\Leftrightarrow \quad !(A \multimap B) \\
      (\_ \utype A) \multimap B \quad &\Leftrightarrow \quad !A \multimap B \\
      (\_ \ltype A) \multimap B \quad &\Leftrightarrow \quad A \multimap B
    \end{align}
    \vspace{-1em}
    \label{correspondence}
  \end{figure}

  A clear departure of our language from standard presentations of both linear type theory and dependent type theory is the presence of two function types: $(x :_s A) \rightarrow B$, $(x :_s A) \multimap B$. The reason for these function types is that we have built the ! exponential of linear logic directly into universe sorts. The sort annotation $s$ here records the universe sort of the function domain. The behavior of ! is difficult to account for even in simple linear type theories. Subtle issues arise if !! is not canonically isomorphic to !, which may invalidate the substitution lemma \cite{substitute}. By integrating the exponential directly into universe sorts, we implicitly limit ! to only be canonically usable. This allows us to derive the substitution lemma, and construct a direct modeling of CLC in CC$\omega$ without requiring any additional machinery for manipulating exponential.

  Figure \ref{correspondence} illustrates the correspondence between CLC function types and Multiplicative Exponential Linear Logic (MELL) implications. MELL lacks counterparts for the cases (1), (3) if the co-domain $B$ is dependent on arguments of domain $A$. We will discuss function type formation in Section \ref{tyformation} in greater detail.

  In practice, algorithmic type checking techniques allow users to omit writing sort indices. Our implementation employs bi-directional type checking and users never interact with indices in the surface syntax.

  \subsection{Universes and Cumulativity}
  CLC features two sorts of universes $U$ and $L$ with level indices $*, 0, 1, 2, \cdots$. $U_*$ is the impredicative universe of propositions. $U_k$ and $L_k$ are the predicative universes of non-linear types and linear types respectively. The main mechanism that CLC uses to distinguish between linear and non-linear types is by checking the universe to which they belong. Basically, terms with types that occur within $U_i$ are unrestricted in their usage. Terms with types that occur within $L_k$ are restricted to being used exactly once.

  In order to lift terms from lower universes to higher ones, there exists cumulativity between universe levels of the same sort. We define cumulativity as follows.

  \begin{definition}
    The cumulativity relation ($\preceq$) is the smallest binary relation over terms such that
    \begin{enumerate}
      \item $\preceq$ is a partial order with respect to equality.
        \begin{enumerate}
          \item If $A \equiv B$, then $A \preceq B$.
          \item If $A \preceq B$ and $B \preceq A$, then $A \equiv B$.
          \item If $A \preceq B$ and $B \preceq C$, then $A \preceq B$.
        \end{enumerate}
      \item $U_* \preceq U_0 \preceq U_1 \preceq U_2 \preceq \cdots$
      \item $L_0 \preceq L_1 \preceq L_2 \preceq \cdots$
      \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, \\ then
        $(x \stype{s} A_1) \rightarrow B_1 \preceq (x \stype{s} A_2) \rightarrow B_2$
      \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, \\ then
        $(x \stype{s} A_1) \multimap B_1 \preceq (x \stype{s} A_2) \multimap B_2$
    \end{enumerate}
  \end{definition}

  Figure \ref{universe} illustrates the structure of our universe hierarchy. Each linear universe $L_k$ has $U_{k+1}$ as its type, allowing functions to freely quantify over linear \textit{types}. However, $L_k$ cumulates to $L_{k+1}$. These two parallel threads of cumulativity prevent linear types from being transported to the non-linear universes, and subsequently losing track of linearity.

  \begin{figure}[H]
    \vspace{-1em}
    \caption{The Universe Hierarchy}
    \vspace{0.8em}
    \centering
    \begin{tikzcd}
      U_* \arrow[r, ":"', "\preceq", dash] 
      & U_0 \arrow[r, ":"', "\preceq", dash] 
      & U_1 \arrow[r, ":"', "\preceq", dash] 
      & U_2 \arrow[r, ":"', "\preceq", dash] 
      & \cdots \\
      & L_0 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash] 
      & L_1 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash] 
      & L_2 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash] 
      & \cdots
    \end{tikzcd}
    \vspace{-0.5em}
    \label{universe}
    \Description{}
  \end{figure}

  \subsection{Context and Structural Judgments}
  The context of our language employs a mixed linear/non-linear representation in the style of Luo\cite{luo}. Variables in the context are annotated to indicate whether they are linear or non-linear. A non-linear variable is annotated as $\Gamma, x \utype A$, whereas a linear variable is annotated as $\Gamma, x \ltype A$. 
  
  Next, we define a $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ relation that merges two mixed contexts $\Gamma_1$, and $\Gamma_2$ into $\Gamma$, by performing contraction on shared non-linear variables. For linear variables, the $\mrg{\_}{\_}{\_}$ relation is defined if and only if each variable occurs uniquely in one context and not the other. This definition of $\mrg{\_}{\_}{\_}$ is what allows contraction for unrestricted variables whilst forbidding it for restricted ones.

  An auxiliary judgment $\pure{\Gamma}$ is defined to assert that a context $\Gamma$ does not contain linear variables. In other words, all variables found in $\pure{\Gamma}$ are annotated of the form $x \utype A$. The full rules for structural judgments are presented in Figure \ref{structural}.
  
  \begin{figure}[h]
    \vspace{-1em}
    \caption{Structural Judgments}
    \vspace{-0.5em}
    \begin{mathpar}
      \inferrule
      { }
      { \epsilon \vdash }
      \rname{Wf-$\epsilon$}

      \inferrule
      { \Gamma\ \vdash \\ 
        \overline{\Gamma} \vdash A \utype U_i }
      { \Gamma, x \utype A \vdash }
      \rname{Wf-U}

      \inferrule
      { \Gamma\ \vdash \\ 
        \overline{\Gamma} \vdash A \utype L_k }
      { \Gamma, x \ltype A\ \vdash } 
      \rname{Wf-L}
      \\

      \inferrule
      { }
      { \pure{\epsilon} }
      \rname{Pure-$\epsilon$}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype U }
      { \pure{\Gamma, x \utype A} }
      \rname{Pure-U}
      \\

      \inferrule
      { }
      { \mrg{\epsilon}{\epsilon}{\epsilon} }
      \rname{Merge-$\epsilon$}

      \inferrule
      { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \mrg{\Gamma_1, x \utype A}
            {\Gamma_2, x \utype A}
            {\Gamma, x \utype A} }
      \rname{Merge-U}

      \inferrule
      { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
        x \notin \Gamma_2 }
      { \mrg{\Gamma_1, x \ltype A}
            {\Gamma_2}
            {\Gamma, x \ltype A} }
      \rname{Merge-L1}

      \inferrule
      { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
        x \notin \Gamma_1 }
      { \mrg{\Gamma_1}
            {\Gamma_2, x \ltype A}
            {\Gamma, x \ltype A} }
      \rname{Merge-L2} 
    \end{mathpar}
    \vspace{-1em}
    \label{structural}
    \Description{}
  \end{figure}

  \begin{definition}
    The context restriction function $\overline{\Gamma}$ is defined as a recursive filter over $\Gamma$ as follows. All linear variables are removed from context $\Gamma$. The result of context restriction is the non-linear subset of the original context.
    \begin{align*}
      \overline{\epsilon} = \epsilon
      \hspace*{4em}
      \overline{\Gamma, x \utype A} = \overline{\Gamma}, x \utype A 
      \hspace*{4em}
      \overline{\Gamma, x \ltype A} = \overline{\Gamma}
    \end{align*}
  \end{definition}

  \subsection{Typing Judgment}
  Typing judgments in CLC take on the form of $\Gamma \vdash m : A$. Intuitively, this judgment states that the term $m$ is an inhabitant of type $A$, with free variables typed in $\Gamma$.

  \begin{definition} We formally define the terms \textit{non-linear}, \textit{linear}, \textit{unrestricted} and \textit{restricted}.
    \begin{enumerate}
      \item A \textit{type} $A$ is \textit{non-linear} under context $\Gamma$ if $\Gamma \vdash A : U_i$.
      \item A \textit{type} $A$ is \textit{linear} under context $\Gamma$ if $\Gamma \vdash A : L_k$.
      \item A \textit{term} $m$ is \textit{unrestricted} under context $\Gamma$ if there exists non-linear type $A$, such that $\Gamma \vdash m : A$. A unrestricted term may be used an arbitrary number of times.
      \item A \textit{term} $m$ is \textit{restricted} under context $\Gamma$ if there exists linear type $A$, such that $\Gamma \vdash m : A$. A restricted term must be used exactly once.
    \end{enumerate}
  \end{definition}

  \subsection{Type Formation} \label{tyformation}
  The rules for forming types are presented in Figure \ref{type}. In CLC, we forbid types from depending on linear terms similar to \cite{llf,neel15} for the same reason of avoiding philosophical troubles.

  The axiom rules \rname{Prop-Axiom}, \rname{U-Axiom}, \rname{L-Axiom} are almost standard, the main difference being the extra side-condition of judgment $\pure{\Gamma}$. In most presentations of dependent type theories without linear types, the universe axioms are derivable under any well-formed context $\Gamma$. Variables not pertaining to actual proofs could be introduced this way, thus giving rise to the admissibility of weakening. To support linear types, we must restrict weakening to non-linear variables. This justifies the restriction of $\Gamma$ to contain only non-linear variables for \rname{Prop-Axiom}, \rname{U-Axiom}, \rname{L-Axiom}. From \rname{L-Axiom} we can see that the universe of linear types $L_k$ is an inhabitant of $U_{k+1}$. This is inspired by Krishnaswami et al.'s treatment of linear universes \cite{neel15}, where linear \textit{types} themselves can be used unrestrictedly.

  The \rname{Prop} rule is used for forming propositions. From the judgment $\Gamma \vdash A : U_i$ we can see that \rname{Prop} allows impredicative quantification over non-linear types of arbitrary level $i$. The judgment $\Gamma, x \utype A \vdash B : U_*$ asserts that the co-domain must be in the impredicative universe $U_*$. The final resulting judgment $\Gamma \vdash (x \utype A) \rightarrow B : U_*$ has sort $U$, indicating that terms with type $(x \utype A) \rightarrow B$ enjoy unrestricted usage.

  \begin{figure}[h]
    \caption{Type Formation} 
    \begin{mathpar}
      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash U_* : U_0 } 
      \rname{Prop-Axiom}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash s_k : U_{k+1} } 
      \rname{Sort-Axiom}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : U_i \\ 
        \Gamma, x \utype A \vdash B : U_* }
      { \Gamma \vdash (x \utype A) \rightarrow B : U_* } 
      \rname{Prop}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : U_k \\ 
        \Gamma, x \utype A \vdash B : s_k }
      { \Gamma \vdash (x \utype A) \rightarrow B : U_k } 
      \rname{U-Prod}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : L_k \\ 
        \Gamma \vdash B : s_k \\
        x \notin \Gamma }
      { \Gamma \vdash (x \ltype A) \rightarrow B : U_k } 
      \rname{L-Prod}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : U_k \\ 
        \Gamma, x \utype A \vdash B : s_k }
      { \Gamma \vdash (x \utype A) \multimap B : L_k } 
      \rname{U-Lolli}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : L_k \\ 
        \Gamma \vdash B : s_k \\
        x \notin \Gamma }
      { \Gamma \vdash (x \ltype A) \multimap B : L_k } 
      \rname{L-Lolli}
    \end{mathpar}
    \label{type}
    \Description{}
  \end{figure}

  The \rname{U-Prod} rule is used for forming non-linear function types with non-linear domains. This is evident from the judgment $\Gamma \vdash A : U_k$. Due to the fact that $A$ is in the predicative non-linear universe $U_k$, terms of type $A$ have unrestricted usage. The non-linearity of domain $A$ allows $B$ to depend on terms of type $A$, as seen in judgment $\Gamma, x \utype A \vdash B : s_k$. The domain $B$ itself may be non-linear or linear, since $B$'s universe $s_k$ can vary between $U_k$ and $L_k$. From the resulting judgment $\Gamma \vdash (x \utype A) \rightarrow B : U_k$, we see that the overall type is a non-linear type. The term level $\lambda$-abstractions of these types can be used unrestrictedly.

  The \rname{L-Prod} rule is used for forming non-linear function types with linear domains. From the judgment $\Gamma \vdash A : L_k$, we see that $A$ is a linear type, and terms of type $A$ have restricted usage. Because of this, we forbid co-domain $B$ from depending on terms of type $A$, evident in the judgment $\Gamma \vdash B : s_k$. Like \rname{U-Prod}, co-domain $B$ itself may be non-linear or linear, since $B$'s universe $s_k$ can vary between $U_k$ and $L_k$. The final resulting judgment is $\Gamma \vdash (x \ltype A) \rightarrow B : U_k$. Here, $x$ is a hypocritical unbinding variable whose only purpose is to preserve syntax uniformity. Again, the overall resulting type is non-linear, so the term level $\lambda$-abstractions of these types can be used unrestrictedly.

  The \rname{U-Lolli}, \rname{L-Lolli} rules are similar to \rname{U-Prod}, \rname{L-Prod} in spirit. The dependency considerations for domain $A$ and co-domain $B$ are exactly the same. The main difference between \rname{U-Lolli}, \rname{L-Lolli} and \rname{U-Prod}, \rname{L-Prod} is the universe sort of the resulting type. The sorts of the function types formed by \rname{U-Lolli}, \rname{L-Lolli} are $L$, meaning they are linear function types. The term level $\lambda$-abstractions of these types must be used exactly once.

  \subsection{Term Formation} \label{teformation}
  The rules for term formation are presented in Figure~\ref{term}.

  \begin{figure}[h]
    \caption{Term Formation}
    \begin{mathpar}
      \inferrule
      { \pure{\Gamma_1, \Gamma_2} }
      { \Gamma_1, x \utype A, \Gamma_2 \vdash x : A }
      \rname{U-Var}

      \inferrule
      { \pure{\Gamma_1, \Gamma_2} }
      { \Gamma_1, x \ltype A, \Gamma_2 \vdash x : A } 
      \rname{L-Var}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash (x \stype{s} A) \rightarrow B : t_i \\ 
        \Gamma, x \stype{s} A \vdash n : B }
      { \Gamma \vdash \lambda x . n : (x \stype{s} A) \rightarrow B }
      \rname{Prod-$\lambda$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash (x \stype{s} A) \multimap B : t_i \\ 
        \Gamma, x \stype{s} A \vdash n : B }
      { \Gamma \vdash \lambda x . n : (x \stype{s} A) \multimap B }
      \rname{Lolli-$\lambda$}
      \\

      \inferrule
      { \Gamma_1 \vdash m : (x \utype A) \rightarrow B \\
        \pure{\Gamma_2} \\
        \Gamma_2 \vdash n : A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n : B[n/x] }
      \rname{U-Prod-App}

      \inferrule
      { \Gamma_1 \vdash m : (x \ltype A) \rightarrow B \\
        \Gamma_2 \vdash n : A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n : B[n/x] }
      \rname{L-Prod-App} 
      \\

      \inferrule
      { \Gamma_1 \vdash m : (x \utype A) \multimap B \\
        \pure{\Gamma_2} \\
        \Gamma_2 \vdash n : A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n : B[n/x] }
      \rname{U-Lolli-App}

      \inferrule
      { \Gamma_1 \vdash m : (x \ltype A) \multimap B \\
        \Gamma_2 \vdash n : A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n : B[n/x] }
      \rname{L-Lolli-App} 
      \\

      \inferrule
      { \Gamma \vdash m : A \\
        \overline{\Gamma} \vdash B : s_i \\ A \preceq B }
      { \Gamma \vdash m : B } 
      \rname{Conv}
    \end{mathpar}
    \label{term}
    \Description{}
  \end{figure}

  The rules \rname{U-Var}, and \rname{L-Var} are used for typing free variables. The \rname{U-Var} rule asserts that free variable $x$ occurs within the context $\Gamma_1, x \utype A, \Gamma_2$ with a non-linear type $A$. The \rname{L-Var} rule asserts that free variable $x$ occurs within the context $\Gamma_1, x \ltype A, \Gamma_2$ with linear type $A$. For both rules, the side condition $\pure{\Gamma_1, \Gamma_2}$ forbids irrelevant variables of linear types from occurring within the context. This prevents another vector of weakening variables with linear type.

  In \rname{Prod-$\lambda$}, the function type being addressed has form $(x \stype{s} A) \rightarrow B$. $\lambda$-abstractions of this type can be applied an unrestricted number of times, hence cannot depend on free variables with restricted usage without possibly duplicating them. This consideration is realized by the side condition $\pure{\Gamma}$, asserting all variables in context $\Gamma$ are unrestricted. Next, the body of the abstraction $n$ is typed as $\Gamma, x \stype{s} A \vdash n : B$, where $s$ is the sort of $A$. Finally, the resulting judgment $\Gamma \vdash \lambda x.n : (x \stype{s} A) \rightarrow B$ asserts that the $\lambda$-abstraction can be used unrestrictedly.

  In contrast to \rname{Prod-$\lambda$}, the \rname{Lolli-$\lambda$} rule is used for forming $\lambda$-abstractions that must be used exactly once. Due to the fact these abstractions must be used once, they are allowed access to restricted variables within context $\Gamma$, evident in the judgment $\Gamma, x \stype{s} A \vdash n : B$, and lack of side condition $\pure{\Gamma}$. However, in judgment $\overline{\Gamma} \vdash (x \stype{s} A) \multimap B : L_k$ the context must be filtered, because types are not allowed to depend on restricted variables. The final resulting judgment $\Gamma \vdash \lambda x.n : (x \stype{s} A) \multimap B$ asserts that the $\lambda$-abstraction must be used exactly once.
  
  For \rname{U-Prod-App}, domain $A$ is a non-linear type, as seen by its annotation in $(x \utype A) \rightarrow B$. Intuitively, this tells us that $x$ may be used an arbitrary number of times within the body of $m$. Thus, the supplied argument $n$ must not depend on restricted variables in context $\Gamma_2$. Otherwise, substitution may put multiple copies of $n$ into $m$ during $\beta$-reduction, duplicating variables that should have been restricted. This justifies the side condition of $\pure{\Gamma_2}$. The contexts $\Gamma_1$, and $\Gamma_2$ are finally merged together into $\Gamma$ by the relation $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, contracting all unrestricted variables shared between $\Gamma_1$, and $\Gamma_2$.
  
  Now for \rname{L-Prod-App}, domain $A$ is a linear type, as seen by its annotation in $(x \ltype A) \rightarrow B$. Intuitively, this tells us that $x$ must be used once within the body of $m$. During $\beta$-reduction, substitution will only put a single copy of $n$ into the body of $m$, so $n$ can depend on restricted variables within $\Gamma_2$ without fear of duplicating them. This justifies the lack of side condition $\pure{\Gamma_2}$. The contexts $\Gamma_1$, and $\Gamma_2$ are finally merged together into $\Gamma$ by the relation $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$, contracting all unrestricted variables shared between $\Gamma_1$, and $\Gamma_2$.

  The rules \rname{U-Lolli-App}, \rname{L-Lolli-App} follow the same considerations as \rname{U-Prod-App}, \rname{L-Prod-App}. Additional conditions are not required for these two rules to be sound.

  Finally, the \rname{Conv} rule allows judgment $\Gamma \vdash m : A$ to convert to judgment $\Gamma \vdash m : B$ if $B$ is a valid type in context $\overline{\Gamma}$. Futhermore, $A$ must be a subtype of $B$ satisfying the cumulativity relation $A \preceq B$. This rule gives rise to large eliminations (compute types from terms), as computations embedded at the type level can convert to canonical types.

  \subsection{Equality and Reduction} \label{reduction}
  The operational semantics and definitional $\beta$-equality of CLC are presented in Figure \ref{parallel}, all of which are entirely standard.
  \begin{figure}[h]
    \caption{Equality and Parallel Reduction}
    \begin{mathpar}
      \inferrule
      { m_1 \step^* n \\ m_2 \step^* n }
      { m_1 \equiv m_2 : A }
      \rname{Join}

      \inferrule
      {  }
      { (\lambda x.m)\ n \pstep m[n/x] }
      \rname{P-$\beta$}

      \inferrule
      { m \step m' }
      { \lambda x.m \step \lambda x.m' }
      \rname{Step-$\lambda$}

      \inferrule
      { A \pstep A' }
      { (x \stype{s} A) \rightarrow B \step (x \stype{s} A') \rightarrow B }
      \rname{Step-ProdL}

      \inferrule
      { B \pstep B' }
      { (x \stype{s} A) \rightarrow B \step (x \stype{s} A) \rightarrow B' }
      \rname{Step-ProdR}

      \inferrule
      { A \pstep A' }
      { (x \stype{s} A) \multimap B \step (x \stype{s} A') \multimap B }
      \rname{Step-LolliL}

      \inferrule
      { B \pstep B' }
      { (x \stype{s} A) \multimap B \step (x \stype{s} A) \multimap B' }
      \rname{Step-LolliR}

      \inferrule
      { m \step m' }
      { m\ n \step m'\ n }
      \rname{Step-AppL}

      \inferrule
      { n \step n' }
      { m\ n \step m\ n' }
      \rname{Step-AppR}
    \end{mathpar}
    \label{parallel}
    \Description{}
  \end{figure}
  As we have discussed previously, the elimination of the explicit ! exponential allows CLC to maintain the standard operational semantics of CC$\omega$, whose $\beta$-reductions are very well behaved.

  \subsection{Meta Theory} \label{meta}
  In this section, we focus our discussion on the properties of CLC. First, we show the type soundness of CLC through the \textit{subject reduction} theorem. Next, we show that CLC is a valid linear type theory through the \textit{linearity} theorem. Furthermore, we show that the \textit{promotion} and \textit{dereliction} rules can be encoded as $\eta$-expansions. Finally, we construct a reduction preserving erasure function that maps well-typed CLC terms to well-typed CC$\omega$ terms, showing that CLC is strongly normalizing.
  
  All proofs have been formalized in Coq with help from the Autosubst \cite{autosubst} library. The Coq development is publicly available on the first author's Github repository. To the best of our knowledge, this is the first machined checked formalization of a linear dependently type theory. We give a hand written version of the proof in the appendix as well.

  \subsubsection{Reduction and Confluence}

  The following lemmas and proofs are entirely standard using parallel step technique \cite{takahashi}. The presence of linear types do not pose any complications as reductions are untyped.

  \begin{lemma} 
    Parallel reduction satisfies the diamond property. If $m \pstep_p m_1$ and $m \pstep_p m_2$ then there exists $m'$ such that $m_1 \pstep_p m'$ and $m_2 \pstep_p m'$.
  \end{lemma}

  \begin{lemma} 
    Each $\pstep_p$ is reachable with $\step^*$. If $m \pstep_p m'$ then $m \step^* m'$.
  \end{lemma}

  \begin{theorem} 
    The transitive reflexive closure of reduction is confluent. If $m \step^* m_1$ and $m \step^* m_2$ then there exists $m'$ such that $m_1 \pstep^* m'$ and $m_2 \pstep^* m'$.
  \end{theorem}

  \begin{corollary}
    The definitional equality relation $\equiv$ is an equivalence relation.
  \end{corollary}

  \subsubsection{Weakening} \label{weakening}
  CLC restricts the weakening rule for variables of linear types. However, weakening variables of non-linear types remain admissible.

  \begin{lemma} 
    Weakening. If $\Gamma \vdash m : A$ is a valid judgment, then for any $x \notin \Gamma$, the judgment $\Gamma, x \utype B \vdash m : A$ is derivable.
  \end{lemma}

  \subsubsection{Substitution} \label{subst}
  Though the substitution lemma is regarded as a boring and bureaucratic result, it is surprisingly hard to design linear typed languages where the substitution lemma is admissible. Much of the difficulty arises during the substitution of arguments containing ! exponential. Perhaps the most famous work detailing the issues of substitution is due to Wadler \cite{substitute}. He defines additional syntax and semantics for the intricate unboxing of ! terms, solving the lack of substitute in Abramsky's term calculus.

  Our design of integrating ! into universe sorts removes the need for ! manipulating syntax and semantics. The following substitution lemmas are directly proved by induction on typing derivations.

  \begin{lemma} 
    Non-linear Substitution. For $\Gamma_1, x \utype A \vdash m : B$ and $\Gamma_2 \vdash n : A$, if $\pure{\Gamma_2}$ and $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ are valid for some $\Gamma$, then $\Gamma \vdash m[n/x] : B[n/x]$.
  \end{lemma}

  \begin{lemma} 
    Linear Substitution. For $\Gamma_1, x \ltype A \vdash m : B$ and $\Gamma_2 \vdash n : A$, if $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ is valid for some $\Gamma$, then $\Gamma \vdash m[n/x] : B[n/x]$.
  \end{lemma}

  \subsubsection{Type Soundness}
  In order to prove subject reduction, we first prove the propagation theorem. The main purpose of propagation is to lower types down to the term level, enabling the application of various inversion lemmas.

  \begin{theorem} 
    Propagation. For any context $\Gamma$, term $m$, type $A$, and sort $s$, if $\Gamma \vdash m : A$ is a valid judgment, then there exist some sort $s$ and level $i$ such that $\overline{\Gamma} \vdash A : s_i$.
    \label{propagation}
  \end{theorem}

  With weakening, substitution, propagation and various inversion lemmas proven, subject reduction can now be proved by induction on typing derivation.

  \begin{theorem} 
    Subject Reduction. For $\Gamma \vdash m : A$, if $m \pstep n$ then $\Gamma \vdash n : A$.
  \end{theorem}

  \subsubsection{Linearity}
  At this point, we have proven that CLC is type sound. However, we still need to prove that the removal of weakening and contraction for restricted variables yields tangible impact on the structure of terms. For this purpose, we define a binding aware recursive function $occurs(x, m)$ that counts the number of times variable $x$ appears within term $m$. The linearity theorem asserts that restricted variables are used exactly once within a term, subsuming safe resource usage.

  Before we proceed, we first prove the seemingly obvious narity lemma. 

  \begin{lemma} 
    Narity. If $\Gamma \vdash m : A$ is a valid judgment, for any $x \notin \Gamma$, there is $occurs(x, m) = 0$.
  \end{lemma}

  For cases with branched syntax in the linearity theorem, such as application $(m\ n)$, the $occurs$ function sums up the occurrences of variable $x$ in branches $m$ and $n$. The narity lemma is used to prove that either $occurs(x, m) = 1 \wedge occurs(x, n) = 0$ or $occurs(x, m) = 0 \wedge occurs(x, n) = 1$ is true.

  \begin{theorem} 
    Linearity. If $\Gamma \vdash m : A$ is a valid judgment, for any $(x \ltype B) \in \Gamma$, there is $occurs(x, m) = 1$.
  \end{theorem}

  \subsubsection{Promotion and Dereliction}
  Linear types of CLC are not obtained through packing and unpacking !, so there are no explicit rules for \textit{promotion} and \textit{dereliction} of Linear Logic. Arbitrary computations existing at the type level also muddle the association between which types can be promoted or derelicted to which. Nevertheless, \textit{promotion} and \textit{dereliction} for canonical types are derivable as theorems through $\eta$-expansion.

  \begin{theorem} 
    Promotion. If $\Gamma \vdash m : (x \stype{s} A) \multimap B$ and $\pure{\Gamma}$ are valid judgments, then there exists $n$ such that $\Gamma \vdash n : (x \stype{s} A) \rightarrow B$ is derivable.
  \end{theorem}

  \begin{theorem} 
    Dereliction. If $\Gamma \vdash m : (x \stype{s} A) \rightarrow B$ is a valid judgment, then there exists $n$ such that $\Gamma \vdash n : (x \stype{s} A) \multimap B$ is derivable.
  \end{theorem}

  \subsubsection{Strong Normalization}
  The strong normalization theorem of CLC is proven by construction of a typing and reduction preserving erasure function to CC$\omega$. We assume familiarity with CC$\omega$ syntax here, and define the erasure function as follows.

  \begin{definition}
    \begin{align*}
      \erase{x} &= x \\
      \erase{U_*} &= Prop \\
      \erase{U_k} &= Type_k \\
      \erase{L_k} &= Type_k \\
      \erase{(x \stype{s} A) \rightarrow B} &= (x : \erase{A}) \rightarrow \erase{B} \\
      \erase{(x \stype{s} A) \multimap B} &= (x : \erase{A}) \rightarrow \erase{B} \\
      \erase{\lambda x.n} &= \lambda x.\erase{n} \\
      \erase{m\ n} &= \erase{m}\ \erase{n}
    \end{align*}
  \end{definition}

  With slight overloading of notation, we define erasure for CLC contexts recursively.

  \begin{definition}
    \begin{align*}
      \erase{\epsilon} &= \epsilon \\
      \erase{\Gamma, x \stype{s} A} &= \erase{\Gamma}, x : \erase{A}
    \end{align*}
  \end{definition}

  We prove the following lemma to commute erasure and substitution whenever needed.
  \begin{lemma} 
    Erasure commutes with substitution. For any CLC terms $m$, $n$ and some variable $x$, $\erase{m[n/x]} = \erase{m}[\erase{n}/x]$. 
  \end{lemma}

  For the following lemma, we refer to the reductions in CLC as $\step_{\scriptscriptstyle \text{CLC}}$, and the reductions in CC$\omega$ as $\step_{\scriptscriptstyle \text{CC$\omega$}}$.
  \begin{theorem} \label{preserve} 
    Erasure preserves reduction. For any CLC terms $m$ and $n$, if there is $m \step_{\scriptscriptstyle \text{CLC}} n$, then there is $\erase{m} \step_{\scriptscriptstyle \text{CC$\omega$}} \erase{n}$.
  \end{theorem}

  \begin{theorem} \label{embedding} 
    Embedding. If $\Gamma \vdash m \stype{s} A$ is a valid judgment in CLC, then $\erase{\Gamma} \vdash \erase{m} : \erase{A}$ is a valid judgment in CC$\omega$.
  \end{theorem}

  If there exists some well typed CLC term with an infinite sequence of reductions, erasure will embed this term into a well typed CC$\omega$ term along with its infinite sequence of reductions by virtue of theorems \ref{preserve}, and \ref{embedding}. This is contradictory to the strong normalization property of CC$\omega$ proven through the Girard-Tait method \cite{ecc}, so this hypothetical term does not exist in CLC.

  \begin{theorem}
    Well-typed CLC terms are strongly normalizing.
  \end{theorem}

  \subsubsection{Backwards Compatibility}
  To show that CLC is backwards compatible with CC$\omega$, we construct a function that annotates CC$\omega$ terms with sort $U$, lifting them into the non-linear fragment of CLC.

  \begin{definition}
    \begin{align*}
      \lift{x} &= x \\
      \lift{Prop} &= U_* \\
      \lift{Type_k} &= U_k \\
      \lift{(x : A) \rightarrow B} &= (x \utype \lift{A}) \rightarrow \lift{B} \\
      \lift{\lambda x.n} &= \lambda x.\lift{n} \\
      \lift{m\ n} &= \lift{m}\ \lift{n}
    \end{align*}
  \end{definition}

  With slight overloading of notation, we define lifting for CC$\omega$ recursively.
  \begin{definition}
    \begin{align*}
      \lift{\epsilon} &= \epsilon \\
      \lift{\Gamma, x : A} &= \lift{\Gamma}, x \utype \lift{A}
    \end{align*}
  \end{definition}

  The following lemmas and theorems are all proved following a similar procedure to proving the soundness of erasure.
  \begin{lemma}
    Lift commutes with substitution. For any CC$\omega$ terms $m$, $n$ and some variable $x$, $\lift{m[n/x]} = \lift{m}[\lift{n}/x]$.
  \end{lemma}

  \begin{theorem}
    Lift preserves reduction. For any CC$\omega$ term $m$ and $n$, if there is $m \step_{\scriptscriptstyle \text{CC}\omega} n$, then there is $\lift{m} \step_{\scriptscriptstyle \text{CLC}} \lift{n}$.
  \end{theorem}

  \begin{theorem}
    Lifting. If $\Gamma \vdash m : A$ is a valid judgment in CC$\omega$, then $\lift{\Gamma} \vdash \lift{m} : \lift{A}$ is a valid judgment in CLC.
  \end{theorem}

  The lifting theorem shows that all valid CC$\omega$ terms are valid CLC terms if the domain of function types are annotated with sort $U$. In practice, even these annotations can be omitted if algorithmic type checking is able to infer them from context.

  \section{Extensions}
  Readers familiar with the literature of linear logic or linear type theory will have noticed at this point that CLC does not possess the iconic $\otimes$ connective. Though it is entirely possible to encode $\otimes$ in core CLC through a linear Church encoding, proofs and programs written in this style will be incredibly difficult to maintain.

  \begin{figure}[h]
  \vspace{-1em}
  \caption{Inductive Type Definition and Elimination}
  \begin{lstlisting}
  (* Sigma Definition *)
  Inductive Sigma (A: U) (F: A -> U): U :=
  | pair : (x: A) -> F x -> Sigma A F.

  (* Tensor Definition *)
  Inductive Tensor (A: L) (B: L): L :=
  | tpair: A -> B -> Tensor A B.

  (* FTensor Definition *)
  Inductive FTensor (A: U) (F: A -> L): L :=
  | fpair: (x: A) -> F x -> FTensor A F.

  (* Sigma Elimination *)
  match m with
  | pair x y => (* clause body *)
  end

  (* Tensor Elimination *)
  match m with
  | tpair x y => (* clause body *)
  end

  (* FTensor Elimination *)
  match m with
  | fpair x y => (* clause body *)
  end
  \end{lstlisting}
  \vspace{-1em}
  \label{inductive}
  \Description{}
  \end{figure}

  A major design goal of CLC is to support an ergonomic interface for users to define inductive types \cite{inductive,cic} as an extension to the core theory. The presence of universe sorts $U$ and $L$ allow users to declare inductive types to be non-linear or linear. The lack of ! exponential simplifies the construction and elimination of inductive terms through direct use of constructors and pattern-matching. The $\otimes$ connective becomes definable as an inductive type.
  
  Figure \ref{inductive} is an excerpt taken from our implementation's prelude, with syntax heavily inspired by Coq.

  \begin{itemize}
    \item \texttt{Sigma} defines the standard dependent sum type. Since first component of the pair constructor is of non-linear type, the type of the second component is allowed to depend on the first component.
    \item \texttt{Tensor} defines the $\otimes$ connective for CLC. Both components of the \texttt{tpair} constructor are of linear types. When a \texttt{Tensor} term is eliminated through pattern-matching, its first and second components must be used exactly once in the body of its pattern clause.
    \item \texttt{FTensor} fulfills a role similar to Krishnaswami et al.'s $F$ adjoint connective \cite{neel15}. The type of \texttt{FTensor}'s first component is non-linear. The linear type of its second component is allowed to depend on the first component. Due to the fact that \texttt{FTensor}'s second component is linear, the entire \texttt{FTensor} must be linear as well, otherwise duplication of restricted variables may occur.
  \end{itemize}
  
  Due to the complexity of checking soundness for dependent linear type definitions (such as \texttt{FTensor}) and pattern-matching based elimination, we have not verified the algorithm employed by our implementation. 
  
  Figure \ref{formation}, Figure \ref{introduction} and Figure \ref{elimination} presents the formation, introduction and elimination rules for select inductive types respectively. We will use these inductive types during the construction of examples.

  \begin{figure}[H]
    \caption{Select Formation Rules}
    \begin{mathpar}
      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash \unit : U_0 }
      \rname{Unit-Form}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash \mathbb{N} : U_0 }
      \rname{$\mathbb{N}$-Form}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : U_i \\
        \Gamma \vdash m : A \\
        \Gamma \vdash n : A }
      { \Gamma \vdash m =_A n : U_* }
      \rname{=-Form}
      
      \inferrule
      { \pure{\Gamma} \\ 
        \Gamma \vdash A : U_k \\ 
        \Gamma x \utype A \vdash B : U_k  }
      { \Gamma \vdash \Sigma x:A.B : U_k }
      \rname{$\Sigma$-Form}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : L_k \\
        \Gamma \vdash B : L_k }
      { \Gamma \vdash A \otimes B : L_k }
      \rname{$\otimes$-Form}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A : U_k \\ 
        \Gamma x \utype A \vdash B : L_k }
      { \Gamma \vdash F x:A.B : L_k }
      \rname{$F$-Form}
    \end{mathpar}
    \label{formation}
    \Description{}
  \end{figure}

  \begin{figure}[H]
    \vspace{-0.8em}
    \caption{Select Introduction Rules}
    \begin{mathpar}
      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash () : \unit }
      \rname{Unit-Intro}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash O : \mathbb{N} }
      \rname{O-Intro}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash n : \mathbb{N} }
      { \Gamma \vdash S\ n : \mathbb{N} }
      \rname{S-Intro}

      \inferrule
      { \pure{\Gamma} \\ 
        \Gamma \vdash A : U_i \\
        \Gamma \vdash m : A }
      { \Gamma \vdash \refl_A m : m =_A m }
      \rname{=-Intro}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash m : A \\
        \Gamma \vdash n : B[m/x] \\\\
        \Gamma \vdash \Sigma x:A.B : U_k }
      { \Gamma \vdash (m, n) : \Sigma x:A.B }
      \rname{$\Sigma$-Intro}

      \inferrule
      { \Gamma_1 \vdash m : A \\
        \Gamma_2 \vdash n : B \\ 
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\\\
        \Gamma \vdash A \otimes B : L_k }
      { \Gamma \vdash [m, n] : A \otimes B }
      \rname{$\otimes$-Intro}

      \inferrule
      { \pure{\Gamma_1} \\
        \Gamma_1 \vdash m : A \\
        \Gamma_2 \vdash n : B[m/x] \\\\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
        \Gamma \vdash F x:A.B : L_k }
      { \Gamma \vdash \{m, n\} : F x:A.B }
      \rname{$F$-Intro}
    \end{mathpar}
    \vspace{-1em}
    \label{introduction}
    \Description{}
  \end{figure}

  \begin{figure}[h]
    \vspace{-1em}
    \caption{Select Elimination Rules}
    \begin{mathpar}
      \inferrule
      { \Gamma_1 \vdash m : \unit \\ 
        \Gamma_2 \vdash n : A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash \letin{()}{m}{n} : A }
      \rname{Unit-Elim}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash \iter_\mathbb{N}^U :
        (C \utype \mathbb{N} \rightarrow U_i) \rightarrow C\ O \rightarrow \\
        ((n \utype \mathbb{N}) \rightarrow C\ n \rightarrow C\ (S\ n)) \rightarrow
        (n \utype \mathbb{N}) \rightarrow C\ n }
      \rname{$\mathbb{N}$-U-Elim}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash \iter_\mathbb{N}^L :
        (C \utype \mathbb{N} \rightarrow L_k) \rightarrow C\ O \multimap \\
        ((n \utype \mathbb{N}) \rightarrow C\ n \rightarrow C\ (S\ n)) \multimap
        (n \utype \mathbb{N}) \multimap C\ n }
      \rname{$\mathbb{N}$-L-Elim}

      \inferrule
      { \Gamma_1 \vdash m : \Sigma x:A.B \\ 
        \Gamma_2, x \utype A, y \utype B \vdash n : C \\\\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash \letin{$(x, y)$}{$m$}{$n$} \vdash C }
      \rname{$\Sigma$-Elim}

      \inferrule
      { \Gamma_1 \vdash m : A \otimes B \\ 
        \Gamma_2, x \ltype A, y \ltype B \vdash n : C \\\\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash \letin{$[x, y]$}{$m$}{$n$} \vdash C }
      \rname{$\otimes$-Elim}

      \inferrule
      { \Gamma_1 \vdash m : F x:A.B \\
        \Gamma_2, x \utype A, y \ltype B \vdash n : C \\\\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash \letin{$\{x, y\}$}{$m$}{$n$} \vdash C }
      \rname{$F$-Elim}
    \end{mathpar}
    \vspace{-0.8em}
    \label{elimination}
    \Description{}
  \end{figure}

  Of all the rules presented here, perhaps the most surprising to readers familiar with linear types or dependent types is the \rname{$\mathbb{N}$-L-Elim} rule. This rule constructs a term with linear type through a primitive recursion principle. The $\multimap$ arrows protect the O-case element of linear type $C\ O$ from duplication by currying. The S-case function is of non-linear type $(n : \mathbb{N}) \rightarrow C\ n \rightarrow C\ (S\ n)$ because it must be applied repeatedly during iteration.
  
  \section{Applications}
  In this section, we demonstrate some of the possible applications of CLC through examples. We collapse the sort annotations on arrows $(x \utype A) \rightarrow B$ and $(x \ltype A) \rightarrow B$ into $(x : A) \rightarrow B$ whenever $A$'s sort is inferable from context. We also omit writing universe levels for the sake of clarity.

  \subsection{Stateful Reasoning}
  We first postulate five state axioms. These axioms could be viewed as an interface to a trusted memory allocator.
  \begin{definition}
    State axioms.
    \begin{itemize}
      \item $l \mapsto_A m : \mathbb{N} \rightarrow (A : U) \rightarrow A \rightarrow L$ \\
      The $\mapsto$ is a linear type constructor. It fulfills a role similar to L3's \cite{l3} memory access capability, or Separation Logic's \cite{reynolds02} points-to assertion. Intuitively, it is a proof that a term $m$ of non-linear type $A$ is currently stored at address $l$.
      \item $\textbf{new} : (A : U) \rightarrow (m : A) \rightarrow F l:\mathbb{N}.(l \mapsto_A m)$ \\
      $\new$ is a function that allocates a new memory cell for term $m$ of non-linear type $A$. It results in an address $l$ paired with an assertion $(l \mapsto_A m)$.
      \item $\textbf{free} : (A : U) \rightarrow F l:\mathbb{N}.F m:A.(l \mapsto_A m) \rightarrow \unit$ \\
      $\free$ is a function that de-allocates the memory cell at location $l$ which is currently in use. This can be seen in its input $F l:\mathbb{N}.F m:A.(l \mapsto_A m)$, where the assertion component $(l \mapsto_A m)$ is a proof that location $l$ is currently allocated.
      \item $\textbf{get} : (A : U) \rightarrow (l : \mathbb{N}) \rightarrow (m : A) \rightarrow (l \mapsto_A m) \rightarrow F \_: (\Sigma x. x =_A m). (l \mapsto_A m)$ \\
      $\get$ is a function that retrieves the term stored at address $l$ when given a proof $(l \mapsto_A m)$ that there is indeed a term $m$ currently stored there. The type of $\get$'s output is the rather complicated $F \_: (\Sigma x. x =_A m). (l \mapsto_A m)$. This not only returns the term stored at $l$, but also a proof that the returned term is exactly the same as what $(l \mapsto_A m)$ claimed to have stored. The proof $(l \mapsto_A m)$ is returned unchanged as well.
      \item $\textbf{set} : (A\ B : U) \rightarrow (l : \mathbb{N}) \rightarrow (m : A) \rightarrow (l \mapsto_A m) \multimap (n : B) \multimap (l \mapsto_B n)$ \\
      $\set$ has the most complicated type of all the axioms presented here. Intuitively, if address $l$ is allocated and storing some term $m$ of type $A$, $\set$ may put term $n$ of type $B$ into the the store at address $l$, overwriting the original term. This is the so called "strong update" operation. The consumption of $(l \mapsto_A m)$ and return of $(l \mapsto_B n)$ accurately characterize this update process.
    \end{itemize}
  \end{definition}
  Due to the fact that $(l \mapsto_A m)$ is a linear type, proofs of this type can not be duplicated and may only be consumed by other state axioms. This is the same non-sharing principle that empowers Separation Logic. Unlike Separation Logic, $(l \mapsto_A m)$ itself is a first-class object in CLC, meaning that it can be the result of computation (large eliminations), input to computations, stored in data structures, etc.

  \subsection{Internalization of Effect Laws}
  The combination of linear types and dependent types within the state axioms enable the internalization of the so called "effect laws" for state, where these laws are now provable theorems within the CLC framework.

  \begin{enumerate}
    \item Performing $\get$ twice on the same address will produce two terms that are provably equal.
    \item After using $\set$ to update the store at an address $l$ to term $m$, performing $\get$ again on the same address will retrieve $m$.
  \end{enumerate}

  Figure \ref{law1} is an excerpt taken from our implementation. It demonstrates the internalization of Law 1. The usage of implicit parameters allows one to omit writing much of the redundant arguments that could be inferred from context. Here, $\new$ allocates a store for natural number 1, creating a proof $c$ of the form $(l \mapsto_\mathbb{N} 1)$. When $\get$ is applied to $c$ twice, the equality proofs \textit{pf1} $: (1 =_\mathbb{N} x)$ and \textit{pf2} $: (1 =_\mathbb{N} y)$ generated by $\get$ allow one to create proof \textit{pf} $: (x =_\mathbb{N} y)$ that the retrieved values $x$ and $y$ are equal. Finally, due to $c$ having linear type, it is required for it to be freed at the very end.

  \begin{figure}[h]
  \vspace{-0.6em}
  \caption{Law 1}
  \begin{lstlisting}
  let [ _, c ] := new _ 1 in
  let [ xeq, c ] := get _ _ _ c in
  let [ yeq, c ] := get _ _ _ c in
  let ( x, pf1 ) := xeq in
  let ( y, pf2 ) := yeq in
  let pf1 := Eq_sym _ _ _ pf1 in
  let pf : Eq _ x y := 
    Eq_trans _ _ _ _ pf1 pf2 
  in free _ _ _ c.
  \end{lstlisting}
  \vspace{-0.6em}
  \label{law1}
  \Description{}
  \end{figure}

  Figure \ref{law2} demonstrates the internalization of Law 2. Again, implicit parameters fill in the annoying bureaucratic arguments when they can be inferred. Here, a store is allocated by $\new$ for natural number 1, creating a proof $c$ of the form $(l \mapsto_\mathbb{N} 1)$. After using $\set$ to update the store at $l$ to 2 and then performing $\get$ on $l$, one can create proof \textit{pf} $: (2 =_\mathbb{N} z)$ that the value $z$ retrieved by $\get$ is exactly equal to 2.

  \begin{figure}[h]
  \vspace{-0.6em}
  \caption{Law 2}
  \begin{lstlisting}
  let [ _, c ] := new _ 1 in
  let c := set _ _ _ _ c 2 in
  let [ zeq, c ] := get _ _ _ c in
  let ( z, pf1 ) := zeq in
  let pf : Eq _ 2 z := pf1 in
  free _ _ _ c.
  \end{lstlisting}
  \vspace{-0.6em}
  \label{law2}
  \Description{}
  \end{figure}

  Though we have not implemented program extraction for CLC yet, our preliminary experiments show the feasibility of compiling the state axioms to constant time imperative operations after proof erasure. This can greatly improve the runtime efficiency of CLC over pure functional languages when used for programming. More complex examples such as safe array indexing are available in the first author's Github repository.

  \subsection{Session Reasoning}
  The inclusion of dependent types and linear types in CLC makes it extremely expressive when encoding communication protocols. By indexing each channel with a protocol, CLC can enforce communication on a channel to strictly adhere to its specified protocol.
  
  In Figure \ref{session}, we declare an inductive \texttt{session} type for specifying protocols. Intuitively, the \texttt{session}  forms a stack of possible operations executed in a protocol. The $\SEND$ constructor takes in a non-linear type $A$ and a session $ss$ as its argument, indicating that after sending a message of type $A$, the protocol progresses to stage $ss$. Likewise, the $\RECV$ constructor takes in a non-linear type $A$ and a session $ss$ as its argument, indicating that after receiving a message of type $A$, the protocol progresses to stage $ss$. Finally, the $\END$ constructor indicates that the protocol has finished and communication is over.

  \begin{figure}[h]
  \caption{Inductive Session Type}
  \begin{lstlisting}
  Inductive session : U :=
  | SEND : U -> session -> session
  | RECV : U -> session -> session
  | END : session.
  \end{lstlisting}
  \label{session}
  \Description{}
  \end{figure}

  In Definition \ref{comm}, we postulate five axioms for communication using the $\session$ type. These axioms could be viewed as an interface to trusted communication libraries.

  \begin{definition}
    Communication axioms.
    \begin{itemize}
      \item $\textbf{channel} : \session \rightarrow L$ \\
      The $\channel$ axiom is a type constructor. It is used to form the types of communication channels that obey the protocol specified by its session.
      \item $\textbf{open} : (ss : \session) \rightarrow \channel\ ss$ \\
      When given a protocol, $\open$ creates a channel indexed by this protocol.
      \item $\textbf{close} : \channel\ \END \rightarrow \unit$ \\
      Once all communications specified on a given channel has finished, $\close$ will close and reclaim the channel.
      \item $\textbf{send} : (A : U) \rightarrow A \rightarrow (ss : \session) \rightarrow$ \\
      \phantom{send : (A :)}
      $\channel\ (\SEND\ A\ ss) \rightarrow \channel\ ss$ \\
      After a channel has reached the point in its protocol where a message of type $A$ should be sent, $\send$ may send a term of type $A$ on this channel, causing the channel to progress to the next stage of its protocol.
      \item $\textbf{recv} : (A : U) \rightarrow (ss : \session) \rightarrow $ \\
      \phantom{recv : (A :)}
      $\channel\ (\RECV\ A\ ss) \rightarrow F \_:A.\channel\ ss$
      After a channel has reached the point in its protocol where a message of type $A$ should be received, $\recv$ may receive such a term of type $A$ from the channel, causing the channel to progress to the next stage of its protocol.
    \end{itemize}
    \label{comm}
  \end{definition}

  The important detail to notice here is that each channel created by $\open$ is of linear type $(\channel\ ss)$ where $ss$ is some arbitrary protocol, hence must be used exactly once. However, the $\send$ and $\recv$ operations return back channels after consuming them, progressing their protocols one stage forward. Coupled with the fact that the $\close$ operation is only able to close channels whose protocols have ended, this forces channels to communicate strictly by their specified protocols.

  Dependent types also allows for more precise specifications of protocols themselves. A simple example would be the specification of message sizes. Figure \ref{communication} shows such an example. The inductive type \texttt{ilist} is a length indexed list. Using \texttt{ilist}, we construct a protocol \texttt{ss} that first sends two natural numbers, then receives eight natural numbers and finally sends back a boolean acknowledgement.

  \begin{figure}[h]
  \caption{Sized Communication}
  \begin{lstlisting}
  Inductive ilist (A : U) : Nat -> U :=
  | nil  : ilist A 0
  | cons : A -> (n : Nat) -> 
              ilist A n -> ilist A (S n).

  let ss := 
    SEND (ilist Nat 2) 
      (RECV (ilist Nat 8) (SEND Bool END)) 
  in
  let send_msg : ilist Nat 2 := 
    (cons 1 _ (cons 2 _ nil)) 
  in
  let ch := open ss in
  let ch := send _ send_msg _ ch in
  let [ recv_msg, ch ] := recv _ _ ch in
  let ch := send _ true _ ch in
  close ch            
  \end{lstlisting}
  \label{communication}
  \Description{}
  \end{figure}

  \subsection{Mutable Data}
  Immutable data in functional programming languages are easy to reason about due their values staying constant over their lifespan. However, this convenience comes at the price of efficiency when attempting to perform "updates" on existing data. In order to update immutable data, an entirely new copy must be created with new entries substituted in for the original ones. So after update, there are two data structures in memory, the original one and the updated one. A garbage collector is necessary to reclaim memory allocated for the original copy.

  Due to the non-sharing property of linear types, it is possible to safely update linear data in-place without encountering synchronization issues. Garbage collection is no longer necessary as extra copies of data are not created. Languages such as ATS that implement mutable linear data have tiny runtimes when compared to immutable garbage collector based ones such as OCaml or Haskell, making them suitable for programming in computationally constrained settings such as embedded programming.

  \begin{figure}[h]
  \caption{Linear Lists}
  \begin{lstlisting}
  Inductive list (A : U) : L :=
  | nil : list A
  | cons : A -> list A -> list A.
  
  Fixpoint append (A : U) : list A -o 
    list A -o (list A -o list A) -o list A 
  :=
    fun ls1 ls2 k =>
      match ls1 with
      | nil => k ls2
      | (cons h t) as _cons_ =>
        append _ t ls2 
          (fun res => k (_cons_ h res))
      end.
  \end{lstlisting}
  \label{list}
  \Description{}
  \end{figure}

  Figure \ref{list} presents a CPS append function for linear lists. In the \texttt{cons} case, the constructor is opened, exposing its data element \texttt{h} and tail list \texttt{t}. Instead of de-allocating the memory of \texttt{cons}, it is bound to the variable \texttt{_cons_} of linear type $A \multimap list\ A \multimap list\ A$. Basically, each \texttt{_cons_} must be applied exactly once to reconstruct a list using the memory of the original, thus mutating the original list in-place. Also notice that the continuation $k$ is of linear type $(list\ A \multimap list\ A)$, indicating that $k$ must be applied exactly once. Using linear types for continuations is surprisingly accurate as control-flow itself is a linear concept.

  \section{Related Work}
  Linear types are a class of type systems inspired by Girard' substructural Linear Logic \cite{girard}. Girard notices that the weakening and contraction rules of Classical Logic when restricted carefully, give rise to a new logical foundation for reasoning about resource. Wadler \cite{wadler1990,wadler1991} then applies an analogous restriction to variable usage in simple type theory, leading to the development of linear type theory where terms respect resources. A term calculus for linear type theory was later realized by Abramsky \cite{abramsky1993}. Benton \cite{benton1994} investigates the ramifications of the ! exponential in linear term calculi, decomposing it to adjoint connectives $F$ and $G$ that map between linear and non-linear judgments. Programming languages \cite{l3,ats,linear-haskell} featuring linear types have also been implemented, allowing programmers to write resource safe software in practical applications.
  
  Over the years, work has been done to enrich linear type theories with dependent types. Cervesato and Pfenning extend the Edinburgh Logical Framework with linear types \cite{lf,llf}, being the first to demonstrate that dependent types and linear types can coexist within a type theory. V\'{a}k\'{a}r \cite{vakar14} presents a linear dependent type theory, with syntax and semantics drawing inspiration from DILL \cite{dill}.  Krishnaswami et al. present a dependent linear type theory \cite{neel15} based on Benton's earlier work on mixed linear and non-linear calculus, demonstrating the ability to internalize imperative programming in the style of Hoare Type Theory \cite{htt}. Luo et al. \cite{luo} introduce the property of essential linearity and a mixed linear/non-linear context, describing the first type theory that allows types to depend on linear terms. Based on initial ideas of McBride \cite{nothing}, Atkey's Quantitative Type Theory (QTT) \cite{qtt} uses semi-ring annotations to track variable occurrence, simulating irrelevance, linear and affine types within a unified framework. The Idris 2 programming language \cite{idris2} implements QTT as its core type system.
  
  \section{Future Work}
  The integration of linear types and dependent types opens the door to many topics for research, both in theory and in its applications.

  On the theoretical side, we intend to investigate the semantic models of CLC, with the goal of explaining the natural cohesion between its rules. The impredicative nature of the \textit{Prop}-like universe $U_*$ hints at the possibility of extending dependency to terms of linear types in a philosophically satisfying way. Linear types also appear to augment parametricity, which can produce stronger free theorems.

  On the application side, we intend to bolster our implementation with more features, making it a full-featured theorem prover/programming language. We aim to fully verify the typechecking algorithms and extensions employed by the current implementation. The unification algorithm used to resolve implicit parameters is extremely ad-hoc, as the problem of unification for linear types has not thoroughly studied, we hope to improve this situation.

\bibliographystyle{acm}
\bibliography{../ref}

\end{document}