% document layout
\documentclass{article}
\usepackage[margin=1.3in]{geometry}
\usepackage[utf8]{inputenc}

% packages
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mdwtab}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{listings}
\usepackage{float}

\floatstyle{boxed} 
\restylefloat{figure}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\renewcommand{\syntleft}{}
\renewcommand{\syntright}{}
\setlength{\grammarparsep}{10pt}
\setlength{\grammarindent}{10em}
\newcommand{\indalt}[1][2]{\\\hspace*{-1.2em}\textbar\quad}
\newcommand{\rname}[1]{\textsc{\footnotesize #1}}
\newcommand{\LNLD}{\text{LNL}_\text{D}}
\newcommand{\ok}{\textbf{ok}}
\newcommand{\pure}{\textbf{pure}}
\newcommand{\sort}{\textbf{sort}}
\newcommand{\type}{\textbf{type}}
\newcommand{\refl}{\text{refl}}
\newcommand{\letin}[3]{$\text{let }#1\text{ := }#2\text{ in }#3$}
\newcommand{\new}{\text{new}}
\newcommand{\free}{\text{free}}
\newcommand{\get}{\text{get}}
\newcommand{\set}{\text{set}}
\newcommand{\subst}{\text{subst}}
\newcommand{\utype}{\overset{U}{:}}
\newcommand{\ltype}{\overset{L}{:}}
\newcommand{\stype}[1]{\overset{#1}{:}}
\newcommand{\step}{\leadsto}
\newcommand{\pstep}{\leadsto_p}

% title and author
\title{Dependent Linear Type Theory for Resource Aware Certified Programming}
\author{Qiancheng Fu}

% document body
\begin{document}
  \maketitle 
  \begin{abstract}
    TBD
  \end{abstract}

  \section{Introduction}
  In the field of certified programming, it is of paramount importance for the specification language to precisely characterize the behavior of programs. For this reason, dependent type theory enjoys great success as the type level language of specifications is exactly the same as the term level programming language, giving tremendous power and control to specification writing. The verification achievements\cite{compcert,deepspec,everest} carried out by proof assistants such as Coq\cite{coq} or F*\cite{fstar} is a testament how much dependent type theory has accomplished. 
  
  Dependent type theory is however, not without its flaws. Due to its origins as a logical foundation for mathematics\cite{martinlof,cc}, dependent type theory lacks facilities to reason about resource, a concept that is largely absent from mathematics but ever present in computer science. Objects in dependent type theory can be freely duplicated or deleted by appealing to the contraction and weakening rules, this goes against the conservation principle of resource. Users of dependent type theories are often required to laboriously embed memory models and program logics into type theory to effectively reason about resource. As language designers, we hope to alleviate this shortcoming of dependent type theory.

  In the disparate world of substructural logic, Girard introduces Linear Logic in his seminal work\cite{girard}. Linear Logic restricts weakening and contraction rules of classical logic, giving rise to an elegant formal foundation for reasoning about resource. Wadler\cite{wadler1990,wadler1991} and Abramsky\cite{abramsky1993} notice the opportunities presented by Linear Logic for resource aware programming, pioneering the development of simple linear type theory as a programming language. Linear type theory enforces safe variable usage, which conservatively subsumes resource usage. This reduces the problem of resource reasoning to linear type checking. Languages based on linear type systems have shown the capacity to safely manipulate imperative data structures\cite{l3,ats}. The successful extraction of type theory from Linear Logic offers a tantalizing hint to overcoming the challenges of resource reasoning in dependent type theory: integrate linear types.

  The earliest work on integrating dependent type theory and linear type theory was carried out by Cervesato and Pfenning\cite{llf}, extending the Edinburgh LF with linear types. Xi extends DML dependent types with linear types in the ATS programming language\cite{ats}. Krishnaswami et al. develop $\LNLD$\cite{neel15} based on Benton's LNL\cite{benton1994} calculus for simple linear types, allowing term dependency on its non-linear fragment. The authors of $\LNLD$ demonstrate its capacity for certified imperative programming in the style of L3\cite{l3} and Hoare Type Theory\cite{htt}.  Luo et al. introduce the notion of essential linearity\cite{luo}, developing the first type theory that allows types to depend on linear terms. Atkey's QTT\cite{qtt}, based on initial ideas of McBride\cite{nothing}, neatly reduces dependency and linearity checking to checking constraints defined on semi-rings. Idris 2\cite{idris2} is a full featured programming language that implements QTT as its core type system.

  The lack of weakening and contraction rules for linear types present unique difficulties when integrating dependent types, often making dependent linear types challenging for practical use. $\LNLD$ requires use of explicit modality maps F and G to alternate between its linear and non-linear fragment. Computation requiring back and forth applications of F and G quickly explode in complexity. Terms in Luo's type theory are not intrinsically linear, linearity is solely determined by annotations. The unfortunate side-effect of this design choice is that linear computations never return non-linear values, eliminating the common pattern of retrieving a non-linear values from a linear references. QTT faces similar drawbacks to Luo due to linearity being determined by semi-ring annotations.
  
  We present a dependent linear type theory that provides a more direct approach to enforce linearity, eschewing the use of modality operators. We believe that linearity is an intrinsic property that can be determined by the type of a term. To accomplish this, our type system uses two sorts of types in the style of Krishnaswami, $L$ for linear and $U$ for non-linear. Due to the abandonment of modalities, we use two distinct functions types $(x : A) \rightarrow_s B$ for non-linear functions and $(x : A) \multimap_s B$ for linear functions. We formalize a call-by-value operational semantics and prove the type soundness of our system. To further demonstrate the applications of dependent linear types, we extend our type system with imperative programming features, leveraging both dependency and linearity for certified imperative programming. We have implemented a prototype of our language extended with other features for practicality and ergonomics.

  \section{Core Type Theory}
  In the efforts of integrating dependency and linearity, there are two predominant schools of thought: \textit{Types can only depended on non-linear terms} and \textit{Types can depend on all terms}. 
  
  Advocates of restricted dependency argue that the restriction is both intuitive and a necessity. A natural example of linear types depending on a non-linear terms is that of the length indexed random access array. Term dependency on array length statically prevents out-of-bounds array access whilst linearity ensures proper memory management. In the converse situation of types depending on linear terms, one immediately faces a dilemma: \textit{Do linear terms at the type level possess weakening and contraction?}.
  
  If one answers yes, then the linear terms at the type level are defacto non-linear. In this case, a language with restricted dependency can simulate linear dependency by depending on non-linear terms that reflect the shape of linear terms\cite{ldqt}, erasing the advantage of increased type level expressivity. All prior works featuring linear dependency fall into this category, for good reason: \textit{the alternative is worse}.
  
  If type level linear terms do not possess weakening and contraction, types with linear dependencies themselves are linear. This breaks the very notion of the typing judgment as even $\alpha$-equivalent terms are not allowed to possess the same type. Though the idea of such a type system is deeply interesting, the philosophical burden is prohibitive.
  
  Our language falls firmly in the former category. Besides the reasons listed above, restricted dependency gives a clear distinction between linear and non-linear terms, a property we believe will aid in the compilation to high performance code.
  
  \subsection{Syntax}
  The syntax of the core type theory is presented in Figure \ref{syntax}. Our type theory contains two sorts, $U$ and $L$ for denoting the sort of non-linear types and linear types respectively. An important fact to note is that our language possess the ``Type-in-Type" axiom in the form of $\Gamma \vdash U \utype U$ which is well known to be logically unsound. We chose this design deliberately as we are willing to sacrifice logical soundness for increased expressivity and convenience. We forsee no issue in extending the core language with a hierarchy of sorts to enforce logical soundness.

  \begin{figure}[H]
    \caption{Syntax}
    \centering
    \begin{minipage}{0.8\linewidth}
    \begin{grammar}
      <$s, t$> ::= $U$ | $L$ \phantom{| $x$} \hspace*{8em} sorts

      <$m, n, A, B, C$> ::= $U$ | $L$ | $x$  \hspace*{8em} expressions
      \indalt $(x : A) \rightarrow_s B$ | $A \rightarrow_s B$
      \indalt $(x : A) \multimap_s B$ | $A \multimap_s B$
      \indalt $\lambda x. n$ | $m\ n$

      <$v$> ::= $U$ | $L$ | $x$ \hspace*{8em} values
      \indalt $(x : A) \rightarrow_s B$ | $A \rightarrow_s B$
      \indalt $(x : A) \multimap_s B$ | $A \multimap_s B$
      \indalt $\lambda x. n$
    \end{grammar}
    \end{minipage}
    \label{syntax}
  \end{figure}

  A clear departure of our language from standard presentations of type theory is the presence of four function types: $(x : A) \rightarrow_s B$, $A \rightarrow_s B$, $(x : A) \multimap_s B$, $A \multimap_s B$. The reason for these variants is the decoupling of function linearity from the linearity of function domain and co-domain. Instead, the linearity of functions is determined by the linearity of the closure it forms. For example, a function with linear input and output type can itself be non-linear if its free variables have non-linear type, indicating this function can be applied repeatedly without duplication of linear variables. In practice, these function types can be consolidated to just $(x : A) \rightarrow_s B$ and $(x : A) \multimap_s B$ by treating $A \rightarrow_s B$ and $A \multimap_s B$ as non-binding special cases. For the sake of clarity, we leave them as four.

  \subsection{Context and Structural Judgments}
  The context of our language employs a mixed linear/non-linear representation in the style of Luo\cite{luo}. Variables in the context are annotated to indicate whether they are linear or non-linear. A non-linear variable is annotated as $\Gamma, x \utype A$, whereas a linear variable is annotated as $\Gamma, x \ltype A$. 
  
  We define a $merge$ relation to combine two mixed contexts $\Gamma_1$ and $\Gamma_2$ by performing contraction on shared non-linear variables. For linear variables, the $merge$ relation is defined if and only if each variable occurs uniquely in one context and not the other. The definition of $merge$ allows contraction for non-linear variables whilst forbidding it for linear ones.

  An auxiliary judgment $\pure$ is defined to assert that a context $\Gamma$ does not contain linear variables. In other words, all variables found in a pure context are of the form $\Gamma, x \utype A$. A restriction function $\overline{\Gamma}$ is defined that removes all linear variables from context $\Gamma$. The result of restriction is a pure subset of the original context.
  
  \begin{figure}[H]
    \caption{Structural Judgments}
    \begin{mathpar}
      \inferrule
      { }
      { \epsilon \ \ok }
      \rname{Ok-$\epsilon$}

      \inferrule
      { \Gamma\ \ok \\ 
        \overline{\Gamma} \vdash A \utype U }
      { \Gamma, x \utype A\ \ok }
      \rname{Ok-U}

      \inferrule
      { \Gamma\ \ok \\ 
        \overline{\Gamma} \vdash A \utype L }
      { \Gamma, x \ltype A\ \ok } 
      \rname{Ok-L}
      \\

      \inferrule
      { }
      { \epsilon\ \pure }
      \rname{Pure-$\epsilon$}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U }
      { \Gamma, x \utype A\ \pure }
      \rname{Pure-U}
      \\

      \inferrule
      { }
      { merge\ \epsilon\ \epsilon\ \epsilon }
      \rname{Merge-$\epsilon$}

      \inferrule
      { merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { merge\ (\Gamma_1, x \utype A)
             \ (\Gamma_2, x \utype A)
             \ (\Gamma, x \utype A) }
      \rname{Merge-U}

      \inferrule
      { merge\ \Gamma_1\ \Gamma_2\ \Gamma \\
        x \notin \Gamma_2 }
      { merge\ (\Gamma_1, x \ltype A)
             \ \Gamma_2
             \ (\Gamma, x \ltype A) }
      \rname{Merge-L1}

      \inferrule
      { merge\ \Gamma_1\ \Gamma_2\ \Gamma \\
        x \notin \Gamma_1 }
      { merge\ \Gamma_1
             \ (\Gamma_2, x \ltype A)
             \ (\Gamma, x \ltype A) }
      \rname{Merge-L2} 
    \end{mathpar}
    \begin{align*}
      \overline{\epsilon} = \epsilon
      \hspace*{4em}
      \overline{\Gamma, x \utype A} = \overline{\Gamma}, x \utype A 
      \hspace*{4em}
      \overline{\Gamma, x \ltype A} = \overline{\Gamma}
    \end{align*}
    \label{structural}
  \end{figure}

  \subsection{Type Formation} \label{tyformation}
  Typing judgments in our language take on the form $\Gamma \vdash m \stype{s} A$ where $s$ is an indexing sort that is either $U$ or $L$. Intuitively, this judgment states that expression $m$ has type $A$ and sort $s$ under context $\Gamma$. An expression of sort $L$ is linear, and sort $U$ is non-linear. Surprisingly, duplication of non-linear expression is not immediately allowed, only non-linear \textit{values} can be safely duplicated. We will discuss this subtlety later in Section \ref{subst}.
  
  Type formation rules are presented in Figure \ref{type}. Rules worth discussing in detail are the \rname{L-Axiom} and the rules for constructing various function types. For \rname{L-Axiom}, the sort of all linear types $L$ itself is of non-linear sort $U$. This means that a linear type can be freely used, avoiding the philosophical trappings discussed earlier.

  The function types $(x : A) \rightarrow_s B$ and $A \rightarrow_s B$ represent non-linear functions, where the subscript $s$ is the sort of co-domain $B$. Functions of these types contain no linear free variables, thus can be applied repeatedly without duplication of linear resources. The difference between the two is that $(x : A) \rightarrow_s B$ allows co-domain $B$ to depended on input $x$ of non-linear domain $A$. For $A \rightarrow_s B$, the domain $A$ is linear so $B$ is not allowed to depend on the function input.

  The variants $(x : A) \multimap_s B$ and $A \multimap_s B$ represent linear functions. Functions of these types may contain linear free variables, thus cannot be applied repeated without duplication of linear variables. Similar to the non-linear versions, the difference between $(x : A) \multimap_s B$ and $A \multimap_s B$ lies in the allowance of dependency on function input for non-linear domain types.

  \begin{figure}[H]
    \caption{Type Formation} 
    \begin{mathpar}
      \inferrule
      { \Gamma\ \pure }
      { \Gamma \vdash U \utype U } 
      \rname{U-Axiom}

      \inferrule
      { \Gamma\ \pure }
      { \Gamma \vdash L \utype U } 
      \rname{L-Axiom}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B \utype s }
      { \Gamma \vdash (x : A) \rightarrow_s B \utype U } 
      \rname{U-Prod}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype L \\ 
        \Gamma \vdash B \utype s }
      { \Gamma \vdash A \rightarrow_s B \utype U } 
      \rname{Arrow}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B\ \utype s }
      { \Gamma \vdash (x : A) \multimap_s B \utype L } 
      \rname{L-Prod}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype L \\ 
        \Gamma \vdash B \utype s }
      { \Gamma \vdash A \multimap_s B \utype L } 
      \rname{Lolli}
    \end{mathpar}
    \label{type}
  \end{figure}

  \subsection{Term Formation} \label{teformation}
  The term formations rules are presented in Figure \ref{term}. 

  The rules \rname{U-Var} and \rname{L-Var} state that a variable's type is determined by its context. In the case of \rname{L-Var}, the linear variable $x$ must be the only linear variable within its context. This enforcement of uniqueness eliminates the weakening rule for linear variables as redundant linear variables in the context will prevent the usage of \rname{L-Var}.

  The \rname{Conv} rule is standard with regards to prior dependent type theory literature. Two types $A$ and $B$ are treated equivalently if they are $\beta\eta$-convertible. Our treatment of the convertibility relation $A \equiv B$ differs from standard due to our call-by-value semantics. We give a detailed account of this in the next section.

  For the non-linear function formation rules \rname{U-$\lambda_1$} and \rname{U-$\lambda_2$}, the context $\Gamma$ is asserted to be pure. The purity of $\Gamma$ ensures that no linear variables occur within function body $n$, allowing the function to be freely used without duplication of linear variables. For the linear function formation rules \rname{L-$\lambda_1$} and \rname{L-$\lambda_2$}, the restriction on $\Gamma$'s purity is lifted. Linear variables within $\Gamma$ are allowed to occur freely within function body $n$. However, the tradeoff is that these linear functions may only be applied once, as multiple uses may result in duplication of its linear free variables.

  In the application rules $\rname{U-App-1}$ and $\rname{L-App-1}$, the argument $n$ is a non-linear expression that may contain linear free variables. If reduction is performed naively, substitution of $n$ into the function body may cause duplication of these variables. Our operational semantics and value soundness lemma guarantee that substitution will not duplicate linear variables.

  Furthermore, in the \rname{U-App-1} and \rname{L-App-1} rules, the input expression $n$ is not directly substituted into the dependent co-domain $B$ as this may introduce linear variables into types. Instead, a $\lambda$-abstraction is formed around $B$ and applied to $n$. This delays $\beta$-reduction until $n$ can be evaluated into a value.

  \begin{figure}[H]
    \caption{Term Formation}
    \begin{mathpar}
      \inferrule
      { \Gamma\ \pure}
      { \Gamma, x \utype A \vdash x \utype A } 
      \rname{U-Var}

      \inferrule
      { \Gamma\ \pure }
      { \Gamma, x \ltype A \vdash x \ltype A } 
      \rname{L-Var}

      \inferrule
      { \Gamma \vdash m \stype{s} A \\ A \equiv B }
      { \Gamma \vdash m \stype{s} B } 
      \rname{Conv}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash (x : A) \rightarrow_s B \utype U \\ 
        \Gamma, x \utype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \utype (x : A) \rightarrow_s B }
      \rname{U-$\lambda_1$}
      \\

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \rightarrow_s B \utype U \\
        \Gamma, x \ltype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \utype A \rightarrow_s B }
      \rname{U-$\lambda_2$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash (x : A) \multimap_s B \utype L \\ 
        \Gamma, x \utype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \ltype (x : A) \multimap_s B }
      \rname{L-$\lambda_1$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash A \multimap_s B \utype L \\ 
        \Gamma, x \ltype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \ltype A \multimap_s B }
      \rname{L-$\lambda_2$}
      \\

      \inferrule
      { \Gamma_1 \vdash m \utype (x : A) \rightarrow_s B \\
        \Gamma_2 \vdash n \utype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} (\lambda x.B)\ n }
      \rname{U-App-1}
      \\

      \inferrule
      { \Gamma_1 \vdash m \utype A \rightarrow_s B \\
        \Gamma_2 \vdash n \ltype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} B }
      \rname{U-App-2}
      \\

      \inferrule
      { \Gamma_1 \vdash m \ltype (x : A) \multimap_s B \\
        \Gamma_2 \vdash n \utype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} (\lambda x.B)\ n }
      \rname{L-App-1}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \multimap_s B \\
        \Gamma_2 \vdash n \ltype A \\
        merge\ \Gamma_1\ \Gamma_2\ \Gamma }
      { \Gamma \vdash m\ n \stype{s} B }
      \rname{L-App-2}
    \end{mathpar}
    \label{term}
  \end{figure}

  \subsection{Reduction and Equality} \label{reduction}
  Figure \ref{single} presents the call-by-value operational semantics that we have eluded to. The rules defining the single step relation $\step$ are completely standard.

  For dependently typed languages, terms can appear at the type level. A definitional equality judgment is required to identify types beyond simple $\alpha$-equivalence. This is usually accomplished by normalization and comparing normal forms. Due to the complications brought on by linearity and substitution hinted at in \ref{teformation}, standard normalization techniques cannot be directly applied. Unfortunately, the single step relation $\step$ defined previously is not sufficient either as binders block evaluation. Following the footsteps of the Trellys project\cite{trellys}, we define a call-by-value parallel step relation $\pstep$ that evaluates under binders. We use the transitive reflexive closure of $\pstep$ to define definitional equality.

  \begin{figure}[H]
    \caption{Single Step Reduction}
    \begin{mathpar}
      \inferrule
      { }
      { (\lambda x.n)\ v \step [v/x]n }
      \rname{S-U-$\beta$}

      \inferrule
      { }
      { (\lambda x.n)\ v \step [v/x]n }
      \rname{S-L-$\beta$}

      \inferrule
      { m \step m' }
      { m\ n \step m'\ n }
      \rname{S-App-L}

      \inferrule
      { n \step n' }
      { v\ n \step v\ n' }
      \rname{S-App-R}
    \end{mathpar}
    \label{single}
  \end{figure}

  \begin{figure}[H]
    \caption{Equality and Parallel Reduction}
    \begin{mathpar}
      \inferrule
      { m_1 \pstep^* n \\ m_2 \pstep^* n }
      { m_1 \equiv m_2 : A }
      \rname{Join}

      \inferrule
      { }
      { x \pstep x }
      \rname{P-Var}

      \inferrule
      { }
      { U \pstep U }
      \rname{P-U}

      \inferrule
      { }
      { L \pstep L }
      \rname{P-L}

      \inferrule
      { n \pstep n' }
      { \lambda x.n \pstep \lambda x.n' }
      \rname{P-$\lambda$}

      \inferrule
      { n \pstep n' }
      { \lambda x.n \pstep \lambda x.n' }
      \rname{P-$\lambda$}

      \inferrule
      { m \pstep m' \\ n \pstep n' }
      { m\ n \pstep m'\ n' }
      \rname{P-App}

      \inferrule
      { n \pstep n' \\ v \pstep v' }
      { (\lambda x.n)\ v \pstep [v'/x]n' }
      \rname{P-U-$\beta$}

      \inferrule
      { n \pstep n' \\ v \pstep v' }
      { (\lambda x.n)\ v \pstep [v'/x]n' }
      \rname{P-L-$\beta$}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { (x : A) \rightarrow_s B \pstep (x : A') \rightarrow_s B' }
      \rname{P-U-Prod}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { A \rightarrow_s B \pstep A' \rightarrow_s B' }
      \rname{P-Arrow}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { (x : A) \multimap_s B \pstep (x : A') \multimap_s B' }
      \rname{P-L-Prod}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { A \multimap_s B \pstep A' \multimap_s B' }
      \rname{P-Lolli}
    \end{mathpar}
    \label{parallel}
  \end{figure}

  \subsection{Meta Theory}
  We have proven the type soundness of our language in the form of \textit{progress} and \textit{preservation} theorems. The proofs have been formalized in Coq with help from the Autosubst\cite{autosubst} library.

  \subsubsection{Step and Parallel Step}

  The following lemmas and proofs are entirely standard. The restriction to value-form arguments for $\beta$-reduction does not pose any complications.

  \begin{lemma}
    Single step reduction implies parallel step reduction. If $m \step m'$, then $m \pstep m'$.
  \end{lemma}

  \begin{lemma}
    Parallel reduction satisfies the diamond property. If $m \pstep m_1$ and $m \pstep m_2$ then there exists $m'$ such that $m_1 \pstep m'$ and $m_2 \pstep m'$.
  \end{lemma}

  \begin{corollary}
    The transitive reflexive closure of parallel reduction is confluent. If $m \pstep^* m_1$ and $m \pstep^* m_2$ then there exists $m'$ such that $m_1 \pstep^* m'$ and $m_2 \pstep^* m'$.
  \end{corollary}

  \begin{corollary}
    The definitional equality relation is an equivalence relation.
  \end{corollary}

  \subsubsection{Substitution} \label{subst}
  Though the \textit{substitution} lemma is widely considered a boring and bureaucratic theorem, it is surprisingly hard to design linear typed languages where the \textit{substitution} lemma is admissible. Much of this difficulty arise during the substitution of non-linear expressions. Perhaps the most famous work detailing the issues of substitution is due to Wadler\cite{substitute}. Since computation arise as a consequence of substitution, it is imperative to get it right.

  Generally, the application rule looks similar to the following for languages with linear types.
  \begin{mathpar}
    \inferrule
    { \Gamma \vdash m : A \multimap B \\ 
      \Delta \vdash n : A }
    { \Gamma, \Delta \vdash m\ n : B } 
  \end{mathpar}

  If type $A$ is a non-linear type, then $n$ ought to be used freely. However, it is possible for $n$ to contain linear variables present in $\Delta$. If $m$ is a lambda abstraction $\lambda x.m'$ where $x$ occurs multiple times within $m'$, substitution of $n$ for $x$ will cause duplication of linear variables. One approach for solving this issue is to wrap non-linear values in an explicit modality, unpacking the internal value only when needed\cite{substitute,neel15}. Another is to ban non-linear expressions from containing linear variables\cite{llf,luo,qtt}.

  Our call-by-value semantics resolves the substitution problem without imposing any of the modifications mentioned previously to the typing of application. The crucial realization is the following \textit{value soundness} lemma: non-linear \textit{values} contain no linear variables.

  \begin{lemma}
    Value soundness. If $\Gamma \vdash v \utype A$ then $\Gamma\ \pure$.
  \end{lemma}

  From the \textit{value soundness} lemma, the standard rule for application is admissible. Intuitively, a single copy of each linear resource is used to create a single non-linear value. This value can then be freely duplicated without needing the original resources to generate fresh copies. This is consistent with the common practice of retrieving non-linear values from linear references.

  \begin{lemma}
    Substitution. For $\Gamma_1, x \stype{s} A \vdash m \stype{t} B$ and $\Gamma_2 \vdash v \stype{s} A$, if there exists $\Gamma$ such that $merge\ \Gamma_1\ \Gamma_2\ \Gamma$ is defined, then $\Gamma \vdash [v/x]m \stype{t} [v/x]B$.
  \end{lemma}

  \subsubsection{Type Soundness}
  The following theorems are a direct result of the \textit{substitution} lemma and various canonical-form lemmas. 

  \begin{theorem}
    Progress. For $\epsilon \vdash m \stype{s} A$, either $m$ is a value or there exists $n$ such that $m \step n$.
  \end{theorem}

  \begin{theorem}
    Preservation. For $\Gamma \vdash m \stype{s} A$, if $m \pstep n$ then $\Gamma \vdash n \stype{s} A$.
  \end{theorem}

  \section{Extensions}

  \subsection{Data Types}
  Though it is possible to encode data and propositions directly in the core language using Church-encodings, it is incredibly inconvenient. To address this, our implementation allows users to define inductive data types\cite{inductive} similar to Coq or Agda\cite{agda}. A pattern matching construct\cite{pattern} is defined on inductive types for data elimination. Checking is performed to ensure that non-linear inductive types do not carry linear terms and linear types cannot be used as type indices or parameters.

  Commonly used inductive types are formalized in Figures \ref{dataform} with their Introduction and Elimination rules formalized in Figure \ref{dataintro} and Figure \ref{dataelim} respectively. Reduction for data types obey the same call-by-value semantics as outlined in \ref{reduction}. Other standard data types that are not covered here are $\mathbb{N}$ for natural numbers and $\top$ for the unit type.

  \begin{figure}[H]
    \caption{Data Formation}
    \begin{mathpar}
      \inferrule
      { \Gamma\ \pure \\ 
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B \utype U }
      { \Gamma \vdash \Sigma x:A.B \utype U }
      \rname{$\Sigma$}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B \utype L }
      { \Gamma \vdash F x:A.B \utype L }
      \rname{$F$}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype L \\ 
        \Gamma \vdash B \utype L }
      { \Gamma \vdash A \otimes B \utype L }
      \rname{$\otimes$}

      \inferrule
      { \Gamma\ \pure \\ 
        \Gamma \vdash m \utype A \\
        \Gamma \vdash n \utype A }
      { \Gamma \vdash m =_A n \utype U }
    \end{mathpar}
    \label{dataform}
  \end{figure}

  \begin{figure}[H]
    \caption{Data Introduction}
    \begin{mathpar}
      \inferrule
      { \Gamma_1 \vdash m \utype A \\
        \Gamma_2 \vdash n \utype (\lambda x.B)\ m \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash (m, n) \utype \Sigma x:A.B }
      \rname{$\Sigma$-intro}

      \inferrule
      { \Gamma_1 \vdash m \utype A \\
        \Gamma_2 \vdash n \ltype (\lambda x.B)\ m \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash [m, n] \ltype F x:A.B }
      \rname{$F$-intro}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \\
        \Gamma_2 \vdash n \ltype B \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \langle m, n \rangle \ltype A \otimes B }
      \rname{$\otimes$-intro}

      \inferrule
      { \Gamma\ \pure \\ \Gamma \vdash n \utype A }
      { \Gamma \vdash \refl\ n \utype n =_A n }
    \end{mathpar}
    \label{dataintro}
  \end{figure}

  \begin{figure}[H]
    \caption{Data Elimination}
    \begin{mathpar}
      \inferrule
      { \Gamma_1 \vdash m \utype \Sigma x.A.B \\
        \Gamma_2, x \utype A, y \utype B \vdash n \stype{s} C \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \letin{(x , y)}{m}{n} \stype{s} C }
      \rname{$\Sigma$-elim}

      \inferrule
      { \Gamma_1 \vdash m \ltype F x.A.B \\
        \Gamma_2, x \utype A, y \ltype B \vdash n \stype{s} C \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \letin{[x , y]}{m}{n} \stype{s} C }
      \rname{$F$-elim}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \otimes B \\
        \Gamma_2, x \ltype A, y \ltype B \vdash n \stype{s} C \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \letin{$\langle x , y\rangle$}{m}{n} \stype{s} C }
      \rname{$\otimes$-elim}

      \inferrule
      { \Gamma_1 \vdash p \utype m =_A n \\
        \Gamma_2 \vdash q \stype{s} B[m] \\
        \overline{\Gamma}, x \utype A \vdash B[x] \utype s \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \subst(\lambda x.B, p, q) \stype{s} B[n] }
    \end{mathpar}
    \label{dataelim}
  \end{figure}

  \subsection{Imperative Programming}
  With the addition of data types, axioms for imperative programming can be added to the language. In Figure \ref{state} we give a set of axioms for stateful programs. Note that these axioms are not associated with any reductions. This unsurprisingly breaks the \textit{Progress Theorem} as axioms are neither values nor can they reduce. Despite this obvious shortcoming, the axiomatic treatment of state provides an interface for extraction of imperative code with safe manual memory management.

  \subsubsection{State Programs}
  \begin{figure}[H]
    \caption{State Programs}
    \begin{mathpar}
      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash A \utype U \\ 
        \Gamma \vdash m \utype A \\
        \Gamma \vdash l \utype \mathbb{N} }
      { \Gamma \vdash l \mapsto_A m \utype L }
      \rname{Capability}

      \inferrule
      { \Gamma\ \pure \\ 
        \Gamma \vdash A \utype U \\ 
        \Gamma \vdash m \utype A }
      { \Gamma \vdash \new(m) \ltype F l:\mathbb{N}. l \mapsto_A m }
      \rname{New}

      \inferrule
      { \Gamma\ \pure \\
        \Gamma \vdash c \ltype l \mapsto_A m }
      { \Gamma \vdash \free(c) \utype \top }
      \rname{Free}

      \inferrule
      { \Gamma \vdash c \ltype l \mapsto_A m }
      { \Gamma \vdash \get(l, c) \ltype
        F x:A. F e: (x =_A m). l \mapsto_A m }
      \rname{Get}

      \inferrule
      { \Gamma \vdash c \ltype l \mapsto_A m \\
        \overline{\Gamma} \vdash n \utype A }
      { \Gamma \vdash \set(l, c, n) \ltype l \mapsto_A n }
      \rname{Set}
    \end{mathpar}
    \label{state}
  \end{figure}

  \subsubsection{Laws for Free}

  \section{Future Work}
  All of the theorems we have developed so far are purely syntactic in nature. But the natural correspondence between linear types and call-by-value semantics seem to hint at a deeper connection. Indeed, past works\cite{cbvsemantics} have provided insight for the simply typed case. We would like to extend these results our dependent linear type theory.

  \section{Conclusion}

\bibliographystyle{acm}
\bibliography{../ref}

\end{document}