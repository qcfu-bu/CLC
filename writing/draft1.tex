% document layout
\documentclass{article}
\usepackage[margin=1.2in]{geometry}
\usepackage[utf8]{inputenc}

% packages
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mdwtab}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathtools}
\usepackage{mathpartir}
\usepackage{listings}
\usepackage{float}
\usepackage{tikz-cd}

\floatstyle{plain} 
\restylefloat{figure}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\renewcommand{\syntleft}{}
\renewcommand{\syntright}{}
\setlength{\grammarparsep}{10pt}
\setlength{\grammarindent}{10em}
\newcommand{\indalt}[1][2]{\\\hspace*{-1.2em}\textbar\quad}
\newcommand{\rname}[1]{\textsc{\footnotesize #1}}
\newcommand{\LNLD}{\text{LNL}_\text{D}}
\newcommand{\ok}{\textbf{ok}}
\newcommand{\pure}[1]{|#1|}
\newcommand{\sort}{\textbf{sort}}
\newcommand{\type}{\textbf{type}}
\newcommand{\refl}{\text{refl}}
\newcommand{\letin}[3]{$\text{let }#1\text{ := }#2\text{ in }#3$}
\newcommand{\new}{\text{new}}
\newcommand{\free}{\text{free}}
\newcommand{\get}{\text{get}}
\newcommand{\set}{\text{set}}
\newcommand{\subst}{\text{subst}}
\newcommand{\utype}{:_U}
\newcommand{\ltype}{:_L}
\newcommand{\stype}[1]{:_#1}
\newcommand{\step}{\leadsto}
\newcommand{\pstep}{\leadsto}
\newcommand{\mrg}[3]{#1\ddagger#2\ddagger#3}

% title and author
\title{The Calculus of Linear Constructions}
\author{Qiancheng Fu}

% document body
\begin{document}
  \maketitle 
  \begin{abstract}
    The Calculus of Linear Constructions (CLC) is an extension of the Calculus of Constructions (CC) with linear types. Specifically, CLC extends CC with a hierarchy of linear universes, and an indexed typing judgment that precisely controls the weakening and contraction of its term level inhabitants. We study the meta-theory of CLC, showing that it is a sound logical framework for reasoning about resource. CLC is backwards compatible with CC, allowing CLC to enjoy the fruits of decades of CC research. We have formalized and proven correct all major results of the core calculus in the Coq Proof Assistant. We extend CLC with linear inductive types and show that CLC as a programming language enables the manipulation of mutable data structures in a principled way.
  \end{abstract}

  \section{Introduction}
  The Calculus of Constructions (CC) is a dependent type theory introduced by Coquand, and Huet in their landmark work \cite{cc}. In CC types can depend on terms, allowing one to write precise specifications as types. Today, CC and its variations CIC \cite{cic} and ECC \cite{ecc} lie at the core of popular proof assistants such as Coq \cite{coq}, Agda \cite{agda}, Lean \cite{lean}, and others. These theorem provers have found great success in the fields of software verification \cite{compcert,deepspec}, and constructive mathematics \cite{four-color,schemes}. 
  
  However, due to its origins as a logical framework for constructive mathematics, it is quite difficult for CC to encode and reason about resources. Intuitively, a mathematical theorem can be applied an unrestricted number of times. Comparatively, the usage of resources is more limited. For example, if we encode Girard's classical example \cite{girard95} of purchasing cigarettes literally into CC as a function of type:
  \begin{equation*}
    Money \rightarrow Camels + Marlboro
  \end{equation*}
  If viewed as an propositional implication, the customer will still maintain full ownership of their money after paying the vendor, because implication does not diminish the validity of its antecedent. Unless the vendor is exceedingly generous, we are faced with the crime of counterfeiting. Users of proof assistants based on CC often need to embed external logics \cite{bedrock} to provide additional reasoning principles for dealing with resource. The design and embedding of these logics is a difficult problem in its own right, requiring additional proofs to justify its soundness. We propose an alternative solution: extend CC with linear types.

  Linear Logic is a substructural logic introduced by Girard in his seminal work \cite{girard}. Girard notice that the weakening and contraction rules of Classical Logic when restricted carefully, gives rise to a new logical foundation for reasoning about resource. Wadler \cite{wadler1990,wadler1991} first notice that an analogous restriction to variable usage in simple type theory leads to a linear type theory, where terms respect resources. A term calculus for linear type theory was later realized by Abramsky \cite{abramsky1993}. Benton \cite{benton1994} investigates the ramifications of the ! exponential in linear term calculi, decomposing it to adjoint connectives $F$ and $G$ that map between linear and non-linear judgments. Programming languages \cite{l3,ats,linear-haskell} featuring linear types have also been implemented, allowing programmers to write resource safe software in practical applications. The success of integrating Linear Logic with simple type theory exposes a tantalizing new frontier of integrating linearity with richer type theories.

  Work have been done to extend dependent type theories with linear types. Cervesato and Pfenning extends the Edinburgh Logical Framework with linear types \cite{lf,llf}, being the first to demonstrate that dependent types and linear types can coexist within a type theory. V\'{a}k\'{a}r \cite{vakar14} gives a categorical semantics for linear dependent types.  Krishnaswami et al. present a dependent linear type theory \cite{neel15} based on Benton's early work of mixed linear and non-linear calculus, demonstrating the ability to internalize imperative programming the style of Hoare Type Theory \cite{htt}. Luo et al. introduce the property of essential linearity, and a mixed linear/non-linear context, describing the first type theory that allows types to depend on linear terms. Based on initial ideas of McBride \cite{nothing}, Atkey's Quantitative Type Theory (QTT) \cite{qtt} uses semi-ring annotations to track variable occurrence, simulating irrelevance, linear, and affine types within a unified framework. The Idris 2 programming language \cite{idris2} implements QTT as its core type system.

  We propose a new linear dependent type system - The Calculus of Linear Constructions (CLC). CLC extends CC$\omega$ with linear types. CC$\omega$ itself is an extension of CC with a cumulative hierarchy of type universes. We add extra universes $L$ of linear types with cumulativity parallel to the universes $U$ of non-linear types. Universe information is propagated by an indexed typing judgment down to the term level, controlling the usage of weakening and contraction rules. This ultimately results in the \textit{linearity} theorem, stating that all resources are used exactly once.

  The presence of both linear and dependent types enables CLC to write specifications that faithfully encodes the usage of resource. The previous example of monetary transaction can be refined using an indexed linear type family $Money : \mathbb{N} \rightarrow L$, and a linear arrow $\multimap_L$ as follows.
  \begin{equation*}
    Money\ 5 \multimap_L Camels + Marlboro
  \end{equation*}
  This new specification for transaction states that it requires a payment of 5 units of money, the customer is relieved of their ownership after the transaction finishes, effectively preventing the contradiction of having your cake and eating it too.

  Compared to preexisting approaches for integrating linear types and dependent types, CLC offers a ``lightweight'' approach to extending CC$\omega$ with linear types, akin to Mazurak et al.'s work on System F \cite{mazurak}. This allows for a straightforward modeling of CLC in CC$\omega$, and lifting of CC$\omega$ into CLC, endowing CLC with the fruits of decades of CC research. We further extend CLC with inductive types, showing that as a programming language it can manipulate mutable data structures in a principled way. We have formalized all major results in Coq, and implemented a prototype in OCaml. 

  \medskip

  \noindent \textbf{\textit{Contributions}}: 
  Our contributions can be summarized as follows.
  \begin{itemize}
    \item Fist, we describe the Calculus of Linear Constructions, an extension to the Calculus of Constructions with linear types. The integration of linear types and dependent types allows CLC to directly and precisely reason about resource.
    \item Next, we study the meta-theory of CLC directly, showing that it satisfies the standard properties of confluence, regularity, and subject reduction. 
    \item We observe that CLC is highly backwards compatible with CC$\omega$. We construct a reduction preserving model of CLC in CC$\omega$, showing that CLC is consistent. 
    \item All major results have been formalized and proven correct in the Coq Proof Assistant with help from the Autosubst \cite{autosubst} library. To the best of our knowledge, our development is the first machine checked formalization of a linear dependent type theory.
    \item Furthermore, we extend CLC with linear inductive data, demonstrating that as a programming language, CLC can safely manipulate mutable data structures.
    \item Finally, we give an implementation extended with user definable linear and non-linear inductive types. Algorithmic type checking employed by the implementation streamlines the process of writing CLC.
  \end{itemize}

  \section{The Language of CLC}
  \subsection{Syntax}
  The syntax of the core type theory is presented in Figure \ref{syntax}. Our type theory contains two sorts of predicative universes $U$ and $L$, being the types of non-linear types and linear types respectively. An additional impredicative universe $U_*$ is the type of propositions, in the same spirit as CC$\omega$'s $Prop$ universe. We use the meta variable $k$ to specifically quantify over levels $0, 1, 2, ...$ that correspond to the predicative universes. We use the meta variable $i$ to quantify over all levels $*, 0, 1, 2, ...$.

  \begin{figure}[H]
    \caption{Syntax}
    \centering
    \begin{minipage}{0.8\linewidth}
    \begin{grammar}
      <$k$> := 0 | 1 | 2 ... | \phantom{*} \hspace*{5.8em} predicative levels

      <$i$> := * | 0 | 1 | 2 ... \hspace*{5.8em} all levels

      <$s, t$> ::= $U$ | $L$ \phantom{| $x$} \hspace*{8em} sorts

      <$m, n, A, B, C$> ::= $U_i$ | $L_k$ | $x$ \hspace*{7.3em} expressions
      \indalt $(x : A) \rightarrow_s B$ | $A \rightarrow_s B$
      \indalt $(x : A) \multimap_s B$ | $A \multimap_s B$
      \indalt $\lambda x. n$ | $m\ n$
    \end{grammar}
    \end{minipage}
    \label{syntax}
  \end{figure}
  A clear departure of our language from standard presentations of both linear type theory, and dependent type theory is the presence of four function types: $(x : A) \rightarrow_s B$, $A \rightarrow_s B$, $(x : A) \multimap_s B$, $A \multimap_s B$. The reason for these variants is that we have built the ! exponential of linear logic directly into the syntax of function types. The behavior of ! is difficult to account for even in simple linear type theory. Subtle issues arise if !! is not canonically isomorphic to !, which may invalidate the substitution lemma \cite{substitute}. By integrating the exponential directly into function syntax, we implicitly limit ! to only be used canonically. This allows us to derive the substitution lemma, and construct a direct modeling of CLC in CC$\omega$ without needing extra machinery for manipulating exponential.
  \begin{figure}[H]
    \caption{Correspondence of CLC types and MELL implications}
    \begin{align}
      (\_ : A) \rightarrow_U B \quad &\equiv \quad !(!A \multimap !B) \\
      (\_ : A) \rightarrow_L B \quad &\equiv \quad !(!A \multimap B) \\
      A \rightarrow_U B \quad &\equiv \quad !(A \multimap !B) \\
      A \rightarrow_L B \quad &\equiv \quad !(A \multimap B) \\
      (\_ : A) \multimap_U B \quad &\equiv \quad !A \multimap !B \\
      (\_ : A) \multimap_L B \quad &\equiv \quad !A \multimap B \\
      A \multimap_U B \quad &\equiv \quad A \multimap !B \\
      A \multimap_L B \quad &\equiv \quad A \multimap B
    \end{align}
    \label{correspondence}
  \end{figure}
  Figure \ref{correspondence} illustrates the correspondence between CLC function types and Multiplicative Exponential Linear Logic (MELL) implications. MELL lacks counterparts for the cases (1), (2), (5), (6) if the co-domain $B$ is dependent on arguments of the domain $A$. We will discuss the detail of these function types in Section \ref{tyformation}.

  \subsection{Universes and Cumulativity}
  CLC features two sorts of universes $U$, and $L$ with level indices $*, 0, 1, 2, \cdots$. $U_*$ is the impredicative universe of propositions. $U_k$, and $L_k$ are the predicative universe of non-linear types, and linear types respectively. The main mechanism that CLC uses to distinguish between linear and non-linear types is by checking the universe to which they belong. Basically, terms with types that occur within $U_i$ are unrestricted in their usage. Terms with types that occur within $L_k$ are restricted to being used exactly once.

  In order to lift terms from lower universes to higher ones, there exists cumulativity between universe levels of the same sort. We define cumulativity as follows.

  \begin{definition}
    The cumulativity relation ($\preceq$) is the smallest binary relation over terms such that
    \begin{enumerate}
      \item $\preceq$ is a partial order with respect to definitional equality.
        \begin{enumerate}
          \item If $A \equiv B$, then $A \preceq B$.
          \item If $A \preceq B$ and $B \preceq A$, then $A \equiv B$.
          \item If $A \preceq B$ and $B \preceq C$, then $A \preceq B$.
        \end{enumerate}
      \item $U_* \preceq U_0 \preceq U_1 \preceq U_2 \preceq \cdots$
      \item $L_0 \preceq L_1 \preceq L_2 \preceq \cdots$
      \item If $A_1 \equiv A_2$ and $B_1 \preceq B_2$, then
        \begin{enumerate}
          \item $(x : A_1) \rightarrow B_1 \preceq (x : A_2) \rightarrow B_2$
          \item $(x : A_1) \multimap B_1 \preceq (x : A_2) \multimap B_2$
          \item $A_1 \rightarrow B_1 \preceq A_2 \rightarrow B_2$
          \item $A_1 \multimap B_1 \preceq A_2 \multimap B_2$
        \end{enumerate}
    \end{enumerate}
  \end{definition}

  Figure \ref{universe} illustrates the structure of our universe hierarchy. Each linear universe $L_k$ has $U_{k+1}$ as its type, allowing functions to dependently quantify over linear \textit{types}. However, $L_k$ cumulates to $L_{k+1}$. These two parallel threads of cumulativity prevent linear types from being transported to the non-linear universe, and subsequently losing track of its occupants' linearity.

  \begin{figure}[H]
    \caption{The Universe Hierarchy}
    \centering
    \begin{tikzcd}
      U_* \arrow[r, ":"', "\preceq", dash] 
      & U_0 \arrow[r, ":"', "\preceq", dash] 
      & U_1 \arrow[r, ":"', "\preceq", dash] 
      & U_2 \arrow[r, ":"', "\preceq", dash] 
      & \cdots \\
      & L_0 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash] 
      & L_1 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash] 
      & L_2 \arrow[r, "\preceq" description, dash] \arrow[ru, ":" description, dash] 
      & \cdots
    \end{tikzcd}
    \label{universe}
  \end{figure}

  \subsection{Context and Structural Judgments}
  The context of our language employs a mixed linear/non-linear representation in the style of Luo\cite{luo}. Variables in the context are annotated to indicate whether they are linear or non-linear. A non-linear variable is annotated as $\Gamma, x \utype A$, whereas a linear variable is annotated as $\Gamma, x \ltype A$. 
  
  Next, we define a $\mrg{\Gamma_1}{\Gamma_2}{\Gamma}$ relation that merges two mixed contexts $\Gamma_1$, and $\Gamma_2$ into $\Gamma$, by performing contraction on shared non-linear variables. For linear variables, the $\mrg{\_}{\_}{\_}$ relation is defined if and only if each variable occurs uniquely in one context and not the other. This definition of $\mrg{\_}{\_}{\_}$ is what allows contraction for non-linear variables whilst forbidding it for linear ones.

  An auxiliary judgment $\pure{\Gamma}$ is defined to assert that a context $\Gamma$ does not contain linear variables. In other words, all variables found in $\pure{\Gamma}$ are annotated of the form $x \utype A$. The full rules for structural judgments are presented in Figure \ref{structural}.
  
  \begin{figure}[H]
    \caption{Structural Judgments}
    \begin{mathpar}
      \inferrule
      { }
      { \epsilon \vdash }
      \rname{Wf-$\epsilon$}

      \inferrule
      { \Gamma\ \vdash \\ 
        \overline{\Gamma} \vdash A \utype U_i }
      { \Gamma, x \utype A \vdash }
      \rname{Wf-U}

      \inferrule
      { \Gamma\ \vdash \\ 
        \overline{\Gamma} \vdash A \utype L_k }
      { \Gamma, x \ltype A\ \vdash } 
      \rname{Wf-L}
      \\

      \inferrule
      { }
      { \pure{\epsilon} }
      \rname{Pure-$\epsilon$}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype U }
      { \pure{\Gamma, x \utype A} }
      \rname{Pure-U}
      \\

      \inferrule
      { }
      { \mrg{\epsilon}{\epsilon}{\epsilon} }
      \rname{Merge-$\epsilon$}

      \inferrule
      { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \mrg{\Gamma_1, x \utype A}
            {\Gamma_2, x \utype A}
            {\Gamma, x \utype A} }
      \rname{Merge-U}

      \inferrule
      { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
        x \notin \Gamma_2 }
      { \mrg{\Gamma_1, x \ltype A}
            {\Gamma_2}
            {\Gamma, x \ltype A} }
      \rname{Merge-L1}

      \inferrule
      { \mrg{\Gamma_1}{\Gamma_2}{\Gamma} \\
        x \notin \Gamma_1 }
      { \mrg{\Gamma_1}
            {\Gamma_2, x \ltype A}
            {\Gamma, x \ltype A} }
      \rname{Merge-L2} 
    \end{mathpar}
    \label{structural}
  \end{figure}

  \begin{definition}
    The context restriction function $\overline{\Gamma}$ is defined as a recursive filter over $\Gamma$ as follows. All linear variables are removed from context $\Gamma$. The result of context restriction is the non-linear subset of the original context.
    \begin{align*}
      \overline{\epsilon} = \epsilon
      \hspace*{4em}
      \overline{\Gamma, x \utype A} = \overline{\Gamma}, x \utype A 
      \hspace*{4em}
      \overline{\Gamma, x \ltype A} = \overline{\Gamma}
    \end{align*}
  \end{definition}

  \subsection{Typing Judgment}
  Typing judgments in CLC take on the form of $\Gamma \vdash m \stype{s} A$. Intuitively, this judgment states that the term $m$ is an inhabitant of type $A$, with free variables typed in $\Gamma$. The sort index $s$ tells us the linearity of $m$. Specifically, if $s = U$, then $m$ has unrestricted usage. Conversely, if $s = L$, then $m$ must be used exactly once. In Section \ref{meta}, we show through the regularity theorem that $s$ corresponds exactly to the sort of type $A$'s universe.

  \subsection{Type Formation} \label{tyformation}
  The rules for forming types are presented in Figure \ref{type}. In CLC, we forbid types from depending on linear terms similar to \cite{llf,neel15} for the same reason of avoiding philosophical pitfalls.

  \begin{figure}[H]
    \caption{Type Formation} 
    \begin{mathpar}
      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash U_* \utype U_0 } 
      \rname{Prop-Axiom}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash U_k \utype U_{k+1} } 
      \rname{U-Axiom}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma \vdash L_k \utype U_{k+1} } 
      \rname{L-Axiom}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype U_i \\ 
        \Gamma, x \utype A \vdash B \utype U_* }
      { \Gamma \vdash (x : A) \rightarrow_U B \utype U_* } 
      \rname{U-Prop}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype U_k \\ 
        \Gamma, x \utype A \vdash B \utype s_k }
      { \Gamma \vdash (x : A) \rightarrow_s B \utype U_k } 
      \rname{U-Prod}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype L_k \\ 
        \Gamma \vdash B \utype s_k }
      { \Gamma \vdash A \rightarrow_s B \utype U_k } 
      \rname{Arrow}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype U_k \\ 
        \Gamma, x \utype A \vdash B \utype s_k }
      { \Gamma \vdash (x : A) \multimap_s B \utype L_k } 
      \rname{L-Prod}

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \utype L_k \\ 
        \Gamma \vdash B \utype s_k }
      { \Gamma \vdash A \multimap_s B \utype L_k } 
      \rname{Lolli}
    \end{mathpar}
    \label{type}
  \end{figure}

  The axiom rules \rname{Prop-Axiom}, \rname{U-Axiom}, \rname{L-Axiom} are almost standard, the main difference being the extra side-condition of judgment $\pure{\Gamma}$. In most presentations of dependent type theories without linear types, the universe axioms are derivable under any well-formed context $\Gamma$. Variables not pertaining to actual proofs could be introduced this way, thus giving rise to the admissibility of weakening. To support linear types, we must restrict weakening to non-linear variables. This justifies the restriction of $\Gamma$ to contain only non-linear variables for \rname{Prop-Axiom}, \rname{U-Axiom}, \rname{L-Axiom}. From \rname{L-Axiom} we can see that the universe of linear types $L_k$ is an inhabitant of $U_{k+1}$. This is reminiscent of Krishnaswami et al.'s treatment of linear universes \cite{neel15}, where linear \textit{types} themselves can be used unrestrictedly.

  Recall from Figure \ref{correspondence} where we presented the correspondence between CLC function types and MELL implications. There exists 8 canonical combinations of ! and $\multimap$ that we must encode. Note that the function types $(x : A) \rightarrow_s B$, and $A \rightarrow_s B$ are intrinsically different entities, even if the variable $x$ is unbinding in the former. So $A \rightarrow_s B$ should not be viewed as a shorthand for $(\_ : A) \rightarrow_s B$. Likewise for the linear variants, $A \multimap_s B$ is not a shorthand for $(\_ : A) \multimap_s B$.

  The \rname{U-Prod} rule is used for forming non-linear dependent function types. $\lambda$-abstractions of this type could be applied an unrestricted number of times, with the argument being allowed unrestricted usage within the function body as well. Notice that the domain $A$ must be of type $U_k$, this entails that the co-domain $B$ may depend on an unrestricted term of type $A$. However, $B$ itself may chose to be of any universe sort with an appropriate predicative level. The sort of $B$'s universe is used to annotate the function arrow. The side-condition $\pure{\Gamma}$ ensures that all components used to form $(x : A)\rightarrow_s B$ do not dependent on linear variables, thus allowing the \textit{type} itself to used as an unrestricted \textit{term}.

  The \rname{Arrow} rule is also used for forming non-linear function types. However, as we have alluded to previously, the formation rule \rname{Arrow} differs from \rname{U-Prod}. Namely, the domain $A$ must be of type $L_k$. This means that if the co-domain $B$ is dependent on a term of type $A$, $B$ will depend on a linear term. To prevent this situation from ever occurring, we explicitly forbid the binding of a dependent variable $x$ within $B$. This leaves us with a type of the shape $A \rightarrow_s B$, where $s$ is the sort of $B$'s universe. $\lambda$-abstractions of this type could be applied an unrestricted number of times, but the argument must be used within the body of the function once.

  The \rname{L-Prod} rule is used for forming linear function types. $\lambda$-abstractions of this type must be applied exactly once, with the argument being allowed unrestricted usage within the function. \rname{L-Prod} shares the same 


  \subsection{Term Formation} \label{teformation}

  \begin{figure}[H]
    \caption{Term Formation}
    \begin{mathpar}
      \inferrule
      { \pure{\Gamma} }
      { \Gamma, x \utype A \vdash x \utype A } 
      \rname{U-Var}

      \inferrule
      { \pure{\Gamma} }
      { \Gamma, x \ltype A \vdash x \ltype A } 
      \rname{L-Var}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash (x : A) \rightarrow_s B \utype U_i \\ 
        \Gamma, x \utype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \utype (x : A) \rightarrow_s B }
      \rname{U-$\lambda_1$}
      \\

      \inferrule
      { \pure{\Gamma} \\
        \Gamma \vdash A \rightarrow_s B \utype U_k \\
        \Gamma, x \ltype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \utype A \rightarrow_s B }
      \rname{U-$\lambda_2$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash (x : A) \multimap_s B \utype L_k \\ 
        \Gamma, x \utype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \ltype (x : A) \multimap_s B }
      \rname{L-$\lambda_1$}
      \\

      \inferrule
      { \overline{\Gamma} \vdash A \multimap_s B \utype L_k \\ 
        \Gamma, x \ltype A \vdash n \stype{s} B }
      { \Gamma \vdash \lambda x . n \ltype A \multimap_s B }
      \rname{L-$\lambda_2$}
      \\

      \inferrule
      { \Gamma_1 \vdash m \utype (x : A) \rightarrow_s B \\
        \overline{\Gamma_2} \vdash n \utype A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n \stype{s} B[n/x] }
      \rname{U-App-1}
      \\

      \inferrule
      { \Gamma_1 \vdash m \utype A \rightarrow_s B \\
        \Gamma_2 \vdash n \ltype A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n \stype{s} B }
      \rname{U-App-2}
      \\

      \inferrule
      { \Gamma_1 \vdash m \ltype (x : A) \multimap_s B \\
        \overline{\Gamma_2} \vdash n \utype A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n \stype{s} B[n/x] }
      \rname{L-App-1}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \multimap_s B \\
        \Gamma_2 \vdash n \ltype A \\
        \mrg{\Gamma_1}{\Gamma_2}{\Gamma} }
      { \Gamma \vdash m\ n \stype{s} B }
      \rname{L-App-2} 
      \\

      \inferrule
      { \Gamma \vdash m \stype{s} A \\
        \overline{\Gamma} \vdash B \utype s_i \\ A \preceq B }
      { \Gamma \vdash m \stype{s} B } 
      \rname{Conv}
    \end{mathpar}
    \label{term}
  \end{figure}

  \subsection{Reduction and Equality} \label{reduction}

  \begin{figure}[H]
    \caption{Equality and Parallel Reduction}
    \begin{mathpar}
      \inferrule
      { m_1 \pstep^* n \\ m_2 \pstep^* n }
      { m_1 \equiv m_2 : A }
      \rname{Join}

      \inferrule
      { }
      { x \pstep x }
      \rname{P-Var}

      \inferrule
      { }
      { U \pstep U }
      \rname{P-U}

      \inferrule
      { }
      { L \pstep L }
      \rname{P-L}

      \inferrule
      { n \pstep n' }
      { \lambda x.n \pstep \lambda x.n' }
      \rname{P-$\lambda$}

      \inferrule
      { n \pstep n' }
      { \lambda x.n \pstep \lambda x.n' }
      \rname{P-$\lambda$}

      \inferrule
      { m \pstep m' \\ n \pstep n' }
      { m\ n \pstep m'\ n' }
      \rname{P-App}

      \inferrule
      { m \pstep m' \\ n \pstep n' }
      { (\lambda x.m)\ n \pstep m'[n'/x] }
      \rname{P-$\beta$}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { (x : A) \rightarrow_s B \pstep (x : A') \rightarrow_s B' }
      \rname{P-U-Prod}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { A \rightarrow_s B \pstep A' \rightarrow_s B' }
      \rname{P-Arrow}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { (x : A) \multimap_s B \pstep (x : A') \multimap_s B' }
      \rname{P-L-Prod}

      \inferrule
      { A \pstep A' \\ B \pstep B' }
      { A \multimap_s B \pstep A' \multimap_s B' }
      \rname{P-Lolli}
    \end{mathpar}
    \label{parallel}
  \end{figure}

  \subsection{Meta Theory} \label{meta}
  We have proven the type soundness of our language in the form of \textit{progress} and \textit{preservation} theorems. The proofs have been formalized in Coq with help from the Autosubst\cite{autosubst} library.

  \subsubsection{Step and Parallel Step}

  The following lemmas and proofs are entirely standard. The restriction to value-form arguments for $\beta$-reduction does not pose any complications.

  \begin{lemma}
    Single step reduction implies parallel step reduction. If $m \step m'$, then $m \pstep m'$.
  \end{lemma}

  \begin{lemma}
    Parallel reduction satisfies the diamond property. If $m \pstep m_1$ and $m \pstep m_2$ then there exists $m'$ such that $m_1 \pstep m'$ and $m_2 \pstep m'$.
  \end{lemma}

  \begin{corollary}
    The transitive reflexive closure of parallel reduction is confluent. If $m \pstep^* m_1$ and $m \pstep^* m_2$ then there exists $m'$ such that $m_1 \pstep^* m'$ and $m_2 \pstep^* m'$.
  \end{corollary}

  \begin{corollary}
    The definitional equality relation is an equivalence relation.
  \end{corollary}

  \subsubsection{Substitution} \label{subst}
  Though the \textit{substitution} lemma is widely considered a boring and bureaucratic theorem, it is surprisingly hard to design linear typed languages where the \textit{substitution} lemma is admissible. Much of this difficulty arise during the substitution of non-linear expressions. Perhaps the most famous work detailing the issues of substitution is due to Wadler\cite{substitute}. Since computation arise as a consequence of substitution, it is imperative to get it right.

  Generally, the application rule looks similar to the following for languages with linear types.
  \begin{mathpar}
    \inferrule
    { \Gamma \vdash m : A \multimap B \\ 
      \Delta \vdash n : A }
    { \Gamma, \Delta \vdash m\ n : B } 
  \end{mathpar}

  If type $A$ is a non-linear type, then $n$ ought to be used freely. However, it is possible for $n$ to contain linear variables present in $\Delta$. If $m$ is a lambda abstraction $\lambda x.m'$ where $x$ occurs multiple times within $m'$, substitution of $n$ for $x$ will cause duplication of linear variables. One approach for solving this issue is to wrap non-linear values in an explicit modality, unpacking the internal value only when needed\cite{substitute,neel15}. Another is to ban non-linear expressions from containing linear variables\cite{llf,luo,qtt}.

  Our call-by-value semantics resolves the substitution problem without imposing any of the modifications mentioned previously to the typing of application. The crucial realization is the following \textit{value soundness} lemma: non-linear \textit{values} contain no linear variables.

  \begin{lemma}
    Value soundness. If $\Gamma \vdash v \utype A$ then $\Gamma$.
  \end{lemma}

  From the \textit{value soundness} lemma, the standard rule for application is admissible. Intuitively, a single copy of each linear resource is used to create a single non-linear value. This value can then be freely duplicated without needing the original resources to generate fresh copies. This is consistent with the common practice of retrieving non-linear values from linear references.

  \begin{lemma}
    Substitution. For $\Gamma_1, x \stype{s} A \vdash m \stype{t} B$ and $\Gamma_2 \vdash v \stype{s} A$, if there exists $\Gamma$ such that $merge\ \Gamma_1\ \Gamma_2\ \Gamma$ is defined, then $\Gamma \vdash [v/x]m \stype{t} [v/x]B$.
  \end{lemma}

  \subsubsection{Type Soundness}
  The following theorems are a direct result of the \textit{substitution} lemma and various canonical-form lemmas. 

  \begin{theorem}
    Progress. For $\epsilon \vdash m \stype{s} A$, either $m$ is a value or there exists $n$ such that $m \step n$.
  \end{theorem}

  \begin{theorem}
    Preservation. For $\Gamma \vdash m \stype{s} A$, if $m \pstep n$ then $\Gamma \vdash n \stype{s} A$.
  \end{theorem}

  \section{Extensions}

  \subsection{Data Types}
  Though it is possible to encode data and propositions directly in the core language using Church-encodings, it is incredibly inconvenient. To address this, our implementation allows users to define inductive data types\cite{inductive} similar to Coq or Agda\cite{agda}. A pattern matching construct\cite{pattern} is defined on inductive types for data elimination. Checking is performed to ensure that non-linear inductive types do not carry linear terms and linear types cannot be used as type indices or parameters.

  Commonly used inductive types are formalized in Figures \ref{dataform} with their Introduction and Elimination rules formalized in Figure \ref{dataintro} and Figure \ref{dataelim} respectively. Reduction for data types obey the same call-by-value semantics as outlined in \ref{reduction}. Other standard data types that are not covered here are $\mathbb{N}$ for natural numbers and $\top$ for the unit type.

  \begin{figure}[H]
    \caption{Data Formation}
    \begin{mathpar}
      \inferrule
      { \Gamma \\ 
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B \utype U }
      { \Gamma \vdash \Sigma x:A.B \utype U }
      \rname{$\Sigma$}

      \inferrule
      { \Gamma \\
        \Gamma \vdash A \utype U \\ 
        \Gamma, x \utype A \vdash B \utype L }
      { \Gamma \vdash F x:A.B \utype L }
      \rname{$F$}

      \inferrule
      { \Gamma \\
        \Gamma \vdash A \utype L \\ 
        \Gamma \vdash B \utype L }
      { \Gamma \vdash A \otimes B \utype L }
      \rname{$\otimes$}

      \inferrule
      { \Gamma \\ 
        \Gamma \vdash m \utype A \\
        \Gamma \vdash n \utype A }
      { \Gamma \vdash m =_A n \utype U }
    \end{mathpar}
    \label{dataform}
  \end{figure}

  \begin{figure}[H]
    \caption{Data Introduction}
    \begin{mathpar}
      \inferrule
      { \Gamma_1 \vdash m \utype A \\
        \Gamma_2 \vdash n \utype (\lambda x.B)\ m \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash (m, n) \utype \Sigma x:A.B }
      \rname{$\Sigma$-intro}

      \inferrule
      { \Gamma_1 \vdash m \utype A \\
        \Gamma_2 \vdash n \ltype (\lambda x.B)\ m \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash [m, n] \ltype F x:A.B }
      \rname{$F$-intro}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \\
        \Gamma_2 \vdash n \ltype B \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \langle m, n \rangle \ltype A \otimes B }
      \rname{$\otimes$-intro}

      \inferrule
      { \Gamma \\ \Gamma \vdash n \utype A }
      { \Gamma \vdash \refl\ n \utype n =_A n }
    \end{mathpar}
    \label{dataintro}
  \end{figure}

  \begin{figure}[H]
    \caption{Data Elimination}
    \begin{mathpar}
      \inferrule
      { \Gamma_1 \vdash m \utype \Sigma x.A.B \\
        \Gamma_2, x \utype A, y \utype B \vdash n \stype{s} C \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \letin{(x , y)}{m}{n} \stype{s} C }
      \rname{$\Sigma$-elim}

      \inferrule
      { \Gamma_1 \vdash m \ltype F x.A.B \\
        \Gamma_2, x \utype A, y \ltype B \vdash n \stype{s} C \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \letin{[x , y]}{m}{n} \stype{s} C }
      \rname{$F$-elim}

      \inferrule
      { \Gamma_1 \vdash m \ltype A \otimes B \\
        \Gamma_2, x \ltype A, y \ltype B \vdash n \stype{s} C \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \letin{$\langle x , y\rangle$}{m}{n} \stype{s} C }
      \rname{$\otimes$-elim}

      \inferrule
      { \Gamma_1 \vdash p \utype m =_A n \\
        \Gamma_2 \vdash q \stype{s} B[m] \\
        \overline{\Gamma}, x \utype A \vdash B[x] \utype s \\
        merge\ \Gamma_1 \Gamma_2 \Gamma }
      { \Gamma \vdash \subst(\lambda x.B, p, q) \stype{s} B[n] }
    \end{mathpar}
    \label{dataelim}
  \end{figure}

  \subsection{Imperative Programming}
  With the addition of data types, axioms for imperative programming can be added to the language. In Figure \ref{state} we give a set of axioms for stateful programs. Note that these axioms are not associated with any reductions. This unsurprisingly breaks the \textit{Progress Theorem} as axioms are neither values nor can they reduce. Despite this obvious shortcoming, the axiomatic treatment of state provides an interface for extraction of imperative code with safe manual memory management.

  \subsubsection{State Programs}
  \begin{figure}[H]
    \caption{State Programs}
    \begin{mathpar}
      \inferrule
      { \Gamma \\
        \Gamma \vdash A \utype U \\ 
        \Gamma \vdash m \utype A \\
        \Gamma \vdash l \utype \mathbb{N} }
      { \Gamma \vdash l \mapsto_A m \utype L }
      \rname{Capability}

      \inferrule
      { \Gamma \\ 
        \Gamma \vdash A \utype U \\ 
        \Gamma \vdash m \utype A }
      { \Gamma \vdash \new(m) \ltype F l:\mathbb{N}. l \mapsto_A m }
      \rname{New}

      \inferrule
      { \Gamma \\
        \Gamma \vdash c \ltype l \mapsto_A m }
      { \Gamma \vdash \free(c) \utype \top }
      \rname{Free}

      \inferrule
      { \Gamma \vdash c \ltype l \mapsto_A m }
      { \Gamma \vdash \get(l, c) \ltype
        F x:A. F e: (x =_A m). l \mapsto_A m }
      \rname{Get}

      \inferrule
      { \Gamma \vdash c \ltype l \mapsto_A m \\
        \overline{\Gamma} \vdash n \utype A }
      { \Gamma \vdash \set(l, c, n) \ltype l \mapsto_A n }
      \rname{Set}
    \end{mathpar}
    \label{state}
  \end{figure}

  \subsubsection{Laws for Free}

  \section{Future Work}
  All of the theorems we have developed so far are purely syntactic in nature. But the natural correspondence between linear types and call-by-value semantics seem to hint at a deeper connection. Indeed, past works\cite{cbvsemantics} have provided insight for the simply typed case. We would like to extend these results our dependent linear type theory.

  \section{Conclusion}

\bibliographystyle{acm}
\bibliography{ref}

\end{document}